16/10/30 23:19:32 INFO SparkContext: Running Spark version 2.0.0

logInfo(s"Running Spark version $SPARK_VERSION")

16/10/30 23:19:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/10/30 23:19:33 INFO SecurityManager: Changing view acls to: spiderdt
16/10/30 23:19:33 INFO SecurityManager: Changing modify acls to: spiderdt
16/10/30 23:19:33 INFO SecurityManager: Changing view acls groups to: 
16/10/30 23:19:33 INFO SecurityManager: Changing modify acls groups to: 
16/10/30 23:19:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spiderdt); groups with view permissions: Set(); users  with modify permissions: Set(spiderdt); groups with modify permissions: Set()
16/10/30 23:19:33 INFO Utils: Successfully started service 'sparkDriver' on port 33905.
16/10/30 23:19:33 INFO SparkEnv: Registering MapOutputTracker
16/10/30 23:19:33 INFO SparkEnv: Registering BlockManagerMaster
16/10/30 23:19:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a2249a4b-a986-488d-9d5e-acdd8fe6ae69
16/10/30 23:19:33 INFO MemoryStore: MemoryStore started with capacity 1938.6 MB
16/10/30 23:19:33 INFO SparkEnv: Registering OutputCommitCoordinator
16/10/30 23:19:33 INFO log: Logging initialized @16757ms
16/10/30 23:19:33 INFO Server: jetty-9.2.z-SNAPSHOT
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1f7c53ea{/jobs,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@2efc70df{/jobs/json,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4426b017{/jobs/job,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1f0485e3{/jobs/job/json,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@629a76ea{/stages,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@2fad98ee{/stages/json,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5efa2304{/stages/stage,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@656a9ea5{/stages/stage/json,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@547689c4{/stages/pool,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@17df114c{/stages/pool/json,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@18b2f2b0{/storage,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@299cc8b5{/storage/json,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@49c45ceb{/storage/rdd,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@267e71ee{/storage/rdd/json,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@295630e3{/environment,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@66409c1c{/environment/json,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@d08b73b{/executors,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@58ac4675{/executors/json,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4065b4ab{/executors/threadDump,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@22a760c7{/executors/threadDump/json,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6a5ebac7{/static,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@50fbc617{/,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3d56e04f{/api,null,AVAILABLE}
16/10/30 23:19:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@24ee1e7a{/stages/stage/kill,null,AVAILABLE}
16/10/30 23:19:33 INFO ServerConnector: Started ServerConnector@2281e0eb{HTTP/1.1}{0.0.0.0:4040}
16/10/30 23:19:33 INFO Server: Started @16838ms
16/10/30 23:19:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/10/30 23:19:33 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.2:4040
16/10/30 23:19:33 INFO SparkContext: Added JAR file:/home/spiderdt/work/git/spiderdt-release/var/jar/spark_etl_expr.jar at spark://192.168.1.2:33905/jars/spark_etl_expr.jar with timestamp 1477840773777

   // Add each JAR given through the constructor
    if (jars != null) {
      jars.foreach(addJar)
    }


16/10/30 23:19:34 INFO RMProxy: Connecting to ResourceManager at /192.168.1.3:8032
16/10/30 23:19:34 INFO Client: Requesting a new application from cluster with 4 NodeManagers
16/10/30 23:19:34 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (16384 MB per container)
16/10/30 23:19:34 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
16/10/30 23:19:34 INFO Client: Setting up container launch context for our AM
16/10/30 23:19:34 INFO Client: Setting up the launch environment for our AM container
16/10/30 23:19:34 INFO Client: Preparing resources for our AM container
16/10/30 23:19:34 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
16/10/30 23:19:35 INFO Client: Uploading resource file:/tmp/spark-b6bed7cd-1a0f-4aa4-a424-556ba82d56d7/__spark_libs__9143566257056696320.zip -> hdfs://192.168.1.3:9000/user/spiderdt/.sparkStaging/application_1473739536361_0484/__spark_libs__9143566257056696320.zip
16/10/30 23:19:37 INFO Client: Uploading resource file:/home/spiderdt/work/git/spiderdt-release/data-platform/target/groovy-all-2.4.7.jar -> hdfs://192.168.1.3:9000/user/spiderdt/.sparkStaging/application_1473739536361_0484/groovy-all-2.4.7.jar
16/10/30 23:19:37 INFO Client: Uploading resource file:/tmp/spark-b6bed7cd-1a0f-4aa4-a424-556ba82d56d7/__spark_conf__3836341324529471906.zip -> hdfs://192.168.1.3:9000/user/spiderdt/.sparkStaging/application_1473739536361_0484/__spark_conf__.zip
16/10/30 23:19:37 INFO SecurityManager: Changing view acls to: spiderdt
16/10/30 23:19:37 INFO SecurityManager: Changing modify acls to: spiderdt
16/10/30 23:19:37 INFO SecurityManager: Changing view acls groups to: 
16/10/30 23:19:37 INFO SecurityManager: Changing modify acls groups to: 
16/10/30 23:19:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spiderdt); groups with view permissions: Set(); users  with modify permissions: Set(spiderdt); groups with modify permissions: Set()
16/10/30 23:19:37 INFO Client: Submitting application application_1473739536361_0484 to ResourceManager
16/10/30 23:19:37 INFO YarnClientImpl: Submitted application application_1473739536361_0484
16/10/30 23:19:37 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1473739536361_0484 and attemptId None
16/10/30 23:19:38 INFO Client: Application report for application_1473739536361_0484 (state: ACCEPTED)
16/10/30 23:19:38 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1477840860229
	 final status: UNDEFINED
	 tracking URL: http://node3:8088/proxy/application_1473739536361_0484/
	 user: spiderdt
16/10/30 23:19:39 INFO Client: Application report for application_1473739536361_0484 (state: ACCEPTED)
16/10/30 23:19:40 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null)
16/10/30 23:19:40 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> node3, PROXY_URI_BASES -> http://node3:8088/proxy/application_1473739536361_0484), /proxy/application_1473739536361_0484
16/10/30 23:19:40 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
16/10/30 23:19:40 INFO Client: Application report for application_1473739536361_0484 (state: RUNNING)
16/10/30 23:19:40 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 192.168.1.6
	 ApplicationMaster RPC port: 0
	 queue: default
	 start time: 1477840860229
	 final status: UNDEFINED
	 tracking URL: http://node3:8088/proxy/application_1473739536361_0484/
	 user: spiderdt
16/10/30 23:19:40 INFO YarnClientSchedulerBackend: Application application_1473739536361_0484 has started running.
16/10/30 23:19:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38023.
16/10/30 23:19:40 INFO NettyBlockTransferService: Server created on 192.168.1.2:38023
16/10/30 23:19:40 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.1.2, 38023)
16/10/30 23:19:40 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.2:38023 with 1938.6 MB RAM, BlockManagerId(driver, 192.168.1.2, 38023)
16/10/30 23:19:40 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.1.2, 38023)
16/10/30 23:19:41 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@54fef2c8{/metrics/json,null,AVAILABLE}
16/10/30 23:19:43 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.1.6:59164) with ID 2
16/10/30 23:19:43 INFO BlockManagerMasterEndpoint: Registering block manager node6:44946 with 2004.6 MB RAM, BlockManagerId(2, node6, 44946)
16/10/30 23:19:44 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.1.5:49744) with ID 1
16/10/30 23:19:44 INFO BlockManagerMasterEndpoint: Registering block manager node5:44089 with 2004.6 MB RAM, BlockManagerId(1, node5, 44089)
16/10/30 23:19:44 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
16/10/30 23:19:44 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 218.0 KB, free 1938.4 MB)
16/10/30 23:19:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.7 KB, free 1938.4 MB)
16/10/30 23:19:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.1.2:38023 (size: 20.7 KB, free: 1938.6 MB)
16/10/30 23:19:44 INFO SparkContext: Created broadcast 0 from wholeTextFiles at NativeMethodAccessorImpl.java:-2
16/10/30 23:19:45 INFO FileInputFormat: Total input paths to process : 366
16/10/30 23:19:45 INFO FileInputFormat: Total input paths to process : 366
16/10/30 23:19:45 INFO CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 4, size left: 191591058
16/10/30 23:19:45 INFO SparkContext: Starting job: foreachPartition at NativeMethodAccessorImpl.java:-2
16/10/30 23:19:45 INFO DAGScheduler: Got job 0 (foreachPartition at NativeMethodAccessorImpl.java:-2) with 2 output partitions
16/10/30 23:19:45 INFO DAGScheduler: Final stage: ResultStage 0 (foreachPartition at NativeMethodAccessorImpl.java:-2)
16/10/30 23:19:45 INFO DAGScheduler: Parents of final stage: List()
16/10/30 23:19:45 INFO DAGScheduler: Missing parents: List()
16/10/30 23:19:45 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at mapPartitions at NativeMethodAccessorImpl.java:-2), which has no missing parents
16/10/30 23:19:45 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.3 KB, free 1938.4 MB)
16/10/30 23:19:45 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.5 KB, free 1938.4 MB)
16/10/30 23:19:45 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.1.2:38023 (size: 3.5 KB, free: 1938.6 MB)
16/10/30 23:19:45 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1012
16/10/30 23:19:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at mapPartitions at NativeMethodAccessorImpl.java:-2)
16/10/30 23:19:45 INFO YarnScheduler: Adding task set 0.0 with 2 tasks
16/10/30 23:19:45 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 0, node5, partition 1, PROCESS_LOCAL, 23109 bytes)
16/10/30 23:19:45 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 1, node6, partition 0, RACK_LOCAL, 29751 bytes)
16/10/30 23:19:45 INFO YarnSchedulerBackend$YarnDriverEndpoint: Launching task 0 on executor id: 1 hostname: node5.
16/10/30 23:19:45 INFO YarnSchedulerBackend$YarnDriverEndpoint: Launching task 1 on executor id: 2 hostname: node6.
16/10/30 23:19:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on node5:44089 (size: 3.5 KB, free: 2004.6 MB)
16/10/30 23:19:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on node6:44946 (size: 3.5 KB, free: 2004.6 MB)
16/10/30 23:19:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on node6:44946 (size: 20.7 KB, free: 2004.6 MB)
16/10/30 23:19:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on node5:44089 (size: 20.7 KB, free: 2004.6 MB)
16/10/30 23:21:31 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 0) in 105628 ms on node5 (1/2)
16/10/30 23:21:31 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 1) in 105780 ms on node6 (2/2)
16/10/30 23:21:31 INFO DAGScheduler: ResultStage 0 (foreachPartition at NativeMethodAccessorImpl.java:-2) finished in 105.801 s
16/10/30 23:21:31 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/10/30 23:21:31 INFO DAGScheduler: Job 0 finished: foreachPartition at NativeMethodAccessorImpl.java:-2, took 105.865900 s
16/10/30 23:21:40 INFO Client: persist to directory: /user/hive/warehouse/4ml.db/larluo/d_bolome_orders/p_date=2016-06-30
16/10/30 23:21:40 INFO SparkContext: Invoking stop() from shutdown hook
16/10/30 23:21:40 INFO ServerConnector: Stopped ServerConnector@2281e0eb{HTTP/1.1}{0.0.0.0:4040}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@24ee1e7a{/stages/stage/kill,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@3d56e04f{/api,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@50fbc617{/,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@6a5ebac7{/static,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@22a760c7{/executors/threadDump/json,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@4065b4ab{/executors/threadDump,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@58ac4675{/executors/json,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@d08b73b{/executors,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@66409c1c{/environment/json,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@295630e3{/environment,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@267e71ee{/storage/rdd/json,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@49c45ceb{/storage/rdd,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@299cc8b5{/storage/json,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@18b2f2b0{/storage,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@17df114c{/stages/pool/json,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@547689c4{/stages/pool,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@656a9ea5{/stages/stage/json,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@5efa2304{/stages/stage,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@2fad98ee{/stages/json,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@629a76ea{/stages,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@1f0485e3{/jobs/job/json,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@4426b017{/jobs/job,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@2efc70df{/jobs/json,null,UNAVAILABLE}
16/10/30 23:21:40 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@1f7c53ea{/jobs,null,UNAVAILABLE}
16/10/30 23:21:40 INFO SparkUI: Stopped Spark web UI at http://192.168.1.2:4040
16/10/30 23:21:40 INFO YarnClientSchedulerBackend: Interrupting monitor thread
16/10/30 23:21:40 INFO YarnClientSchedulerBackend: Shutting down all executors
16/10/30 23:21:40 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
16/10/30 23:21:40 INFO SchedulerExtensionServices: Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
16/10/30 23:21:40 INFO YarnClientSchedulerBackend: Stopped
16/10/30 23:21:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/10/30 23:21:40 INFO MemoryStore: MemoryStore cleared
16/10/30 23:21:40 INFO BlockManager: BlockManager stopped
16/10/30 23:21:40 INFO BlockManagerMaster: BlockManagerMaster stopped
16/10/30 23:21:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/10/30 23:21:40 INFO SparkContext: Successfully stopped SparkContext
16/10/30 23:21:40 INFO ShutdownHookManager: Shutdown hook called
16/10/30 23:21:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-b6bed7cd-1a0f-4aa4-a424-556ba82d56d7
