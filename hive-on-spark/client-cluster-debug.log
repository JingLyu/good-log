spiderdt@client:~/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin$ bin/hive --hiveconf hive.root.logger=DEBUG,console

find SPARK_HOME
 SPARK_HOME is not exists
SPARK_HOME: /home/spiderdt/work/git/spiderdt-env/cluster/tarball/spark-2.0.0-bin-hadoop2.7
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/log4j-slf4j-impl-2.4.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop-2.7.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-common-2.1.0.jar!/hive-log4j2.properties Async: true
16/08/16 09:48:09 [main]: INFO SessionState: 
Logging initialized using configuration in jar:file:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-common-2.1.0.jar!/hive-log4j2.properties Async: true
16/08/16 09:48:09 [main]: DEBUG conf.VariableSubstitution: Substitution is on: hive
16/08/16 09:48:09 [main]: DEBUG lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
16/08/16 09:48:09 [main]: DEBUG lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
16/08/16 09:48:09 [main]: DEBUG lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
16/08/16 09:48:09 [main]: DEBUG impl.MetricsSystemImpl: UgiMetrics, User and group related metrics
16/08/16 09:48:09 [main]: DEBUG util.KerberosName: Kerberos krb5 configuration not found, setting default realm to empty
16/08/16 09:48:09 [main]: DEBUG security.Groups:  Creating new Groups object
16/08/16 09:48:09 [main]: DEBUG util.NativeCodeLoader: Trying to load the custom-built native-hadoop library...
16/08/16 09:48:09 [main]: DEBUG util.NativeCodeLoader: Loaded the native-hadoop library
16/08/16 09:48:09 [main]: DEBUG security.JniBasedUnixGroupsMapping: Using JniBasedUnixGroupsMapping for Group resolution
16/08/16 09:48:09 [main]: DEBUG security.JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
16/08/16 09:48:09 [main]: DEBUG security.Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
16/08/16 09:48:09 [main]: DEBUG security.UserGroupInformation: hadoop login
16/08/16 09:48:09 [main]: DEBUG security.UserGroupInformation: hadoop login commit
16/08/16 09:48:09 [main]: DEBUG security.UserGroupInformation: using local user:UnixPrincipal: spiderdt
16/08/16 09:48:09 [main]: DEBUG security.UserGroupInformation: Using user: "UnixPrincipal: spiderdt" with name spiderdt
16/08/16 09:48:09 [main]: DEBUG security.UserGroupInformation: User entry: "spiderdt"
16/08/16 09:48:09 [main]: DEBUG security.UserGroupInformation: UGI loginUser:spiderdt (auth:SIMPLE)
16/08/16 09:48:09 [main]: INFO metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.storeManagerType value null from  jpox.properties with rdbms
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.schema.validateConstraints value null from  jpox.properties with false
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.autoStartMechanismMode value null from  jpox.properties with checked
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.schema.validateTables value null from  jpox.properties with false
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding javax.jdo.option.Multithreaded value null from  jpox.properties with true
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.cache.level2.type value null from  jpox.properties with none
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.connectionPoolingType value null from  jpox.properties with BONECP
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding javax.jdo.option.ConnectionUserName value null from  jpox.properties with hive
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.schema.autoCreateAll value null from  jpox.properties with false
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding javax.jdo.option.NonTransactionalRead value null from  jpox.properties with true
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.transactionIsolation value null from  jpox.properties with read-committed
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding javax.jdo.option.ConnectionURL value null from  jpox.properties with jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.schema.validateColumns value null from  jpox.properties with false
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.identifierFactory value null from  jpox.properties with datanucleus1
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding javax.jdo.PersistenceManagerFactoryClass value null from  jpox.properties with org.datanucleus.api.jdo.JDOPersistenceManagerFactory
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.cache.level2 value null from  jpox.properties with false
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.rdbms.useLegacyNativeValueStrategy value null from  jpox.properties with true
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding hive.metastore.integral.jdo.pushdown value null from  jpox.properties with false
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding javax.jdo.option.DetachAllOnCommit value null from  jpox.properties with true
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding javax.jdo.option.ConnectionDriverName value null from  jpox.properties with org.apache.derby.jdbc.EmbeddedDriver
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.plugin.pluginRegistryBundleCheck value null from  jpox.properties with LOG
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: datanucleus.schema.autoCreateAll = false
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: datanucleus.schema.validateTables = false
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: datanucleus.rdbms.useLegacyNativeValueStrategy = true
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: datanucleus.schema.validateColumns = false
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: hive.metastore.integral.jdo.pushdown = false
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: datanucleus.autoStartMechanismMode = checked
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: javax.jdo.option.Multithreaded = true
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: datanucleus.identifierFactory = datanucleus1
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: datanucleus.transactionIsolation = read-committed
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: javax.jdo.option.ConnectionURL = jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: javax.jdo.option.DetachAllOnCommit = true
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: javax.jdo.option.NonTransactionalRead = true
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: javax.jdo.option.ConnectionDriverName = org.apache.derby.jdbc.EmbeddedDriver
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: datanucleus.schema.validateConstraints = false
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: javax.jdo.option.ConnectionUserName = hive
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: datanucleus.cache.level2 = false
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: datanucleus.plugin.pluginRegistryBundleCheck = LOG
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: datanucleus.cache.level2.type = none
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: javax.jdo.PersistenceManagerFactoryClass = org.datanucleus.api.jdo.JDOPersistenceManagerFactory
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: datanucleus.storeManagerType = rdbms
16/08/16 09:48:09 [main]: DEBUG metastore.ObjectStore: datanucleus.connectionPoolingType = BONECP
16/08/16 09:48:09 [main]: INFO metastore.ObjectStore: ObjectStore, initialize called
16/08/16 09:48:09 [main]: DEBUG bonecp.BoneCPDataSource: JDBC URL = jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true, Username = hive, partitions = 1, max (per partition) = 10, min (per partition) = 0, idle max age = 60 min, idle test period = 240 min, strategy = DEFAULT
Tue Aug 16 09:48:09 CST 2016 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
Tue Aug 16 09:48:09 CST 2016 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
Tue Aug 16 09:48:09 CST 2016 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
Tue Aug 16 09:48:09 CST 2016 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
16/08/16 09:48:10 [main]: INFO metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
16/08/16 09:48:10 [main]: DEBUG bonecp.BoneCPDataSource: JDBC URL = jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true, Username = hive, partitions = 1, max (per partition) = 10, min (per partition) = 0, idle max age = 60 min, idle test period = 240 min, strategy = DEFAULT
Tue Aug 16 09:48:10 CST 2016 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
Tue Aug 16 09:48:10 CST 2016 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
Tue Aug 16 09:48:10 CST 2016 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
Tue Aug 16 09:48:10 CST 2016 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
16/08/16 09:48:10 [main]: DEBUG metastore.MetaStoreDirectSql: Direct SQL query in 0.207852ms + 0.042396ms, the query is [SET @@session.sql_mode=ANSI_QUOTES]
16/08/16 09:48:10 [main]: INFO metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is MYSQL
16/08/16 09:48:10 [main]: DEBUG metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@629ae7e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@20d11153 created in the thread with id: 1
16/08/16 09:48:10 [main]: INFO metastore.ObjectStore: Initialized ObjectStore
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Open transaction: count = 1, isActive = true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getMSchemaVersion(ObjectStore.java:7703)
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Commit transaction: count = 0, isactive true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getMSchemaVersion(ObjectStore.java:7716)
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Found expected HMS version of 2.1.0
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Open transaction: count = 1, isActive = true at:
	org.apache.hadoop.hive.metastore.ObjectStore$GetHelper.start(ObjectStore.java:2687)
16/08/16 09:48:11 [main]: DEBUG metastore.MetaStoreDirectSql: Direct SQL query in 0.125338ms + 0.01474ms, the query is [SET @@session.sql_mode=ANSI_QUOTES]
16/08/16 09:48:11 [main]: DEBUG metastore.MetaStoreDirectSql: getDatabase: directsql returning db default locn[hdfs://192.168.1.3:9000/user/hive/warehouse] desc [Default Hive database] owner [public] ownertype [ROLE]
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Commit transaction: count = 0, isactive true at:
	org.apache.hadoop.hive.metastore.ObjectStore$GetHelper.commit(ObjectStore.java:2747)
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: db details for db default retrieved using SQL in 9.025251ms
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Open transaction: count = 1, isActive = true at:
	org.apache.hadoop.hive.metastore.ObjectStore.addRole(ObjectStore.java:3730)
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Open transaction: count = 2, isActive = true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getMRole(ObjectStore.java:4087)
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Commit transaction: count = 1, isactive true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getMRole(ObjectStore.java:4093)
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Rollback transaction, isActive: true at:
	org.apache.hadoop.hive.metastore.ObjectStore.addRole(ObjectStore.java:3742)
16/08/16 09:48:11 [main]: DEBUG metastore.HiveMetaStore: admin role already exists
InvalidObjectException(message:Role admin already exists.)
	at org.apache.hadoop.hive.metastore.ObjectStore.addRole(ObjectStore.java:3733)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:101)
	at com.sun.proxy.$Proxy21.addRole(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultRoles_core(HiveMetaStore.java:644)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultRoles(HiveMetaStore.java:633)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:399)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:78)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:84)
	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6396)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:236)
	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1625)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:80)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:130)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:101)
	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3317)
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3356)
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3336)
	at org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3590)
	at org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:236)
	at org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:221)
	at org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:366)
	at org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:310)
	at org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:290)
	at org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:266)
	at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:545)
	at org.apache.hadoop.hive.ql.session.SessionState.beginStart(SessionState.java:518)
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:705)
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:641)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
16/08/16 09:48:11 [main]: INFO metastore.HiveMetaStore: Added admin role in metastore
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Open transaction: count = 1, isActive = true at:
	org.apache.hadoop.hive.metastore.ObjectStore.addRole(ObjectStore.java:3730)
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Open transaction: count = 2, isActive = true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getMRole(ObjectStore.java:4087)
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Commit transaction: count = 1, isactive true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getMRole(ObjectStore.java:4093)
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Rollback transaction, isActive: true at:
	org.apache.hadoop.hive.metastore.ObjectStore.addRole(ObjectStore.java:3742)
16/08/16 09:48:11 [main]: DEBUG metastore.HiveMetaStore: public role already exists
InvalidObjectException(message:Role public already exists.)
	at org.apache.hadoop.hive.metastore.ObjectStore.addRole(ObjectStore.java:3733)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:101)
	at com.sun.proxy.$Proxy21.addRole(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultRoles_core(HiveMetaStore.java:653)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultRoles(HiveMetaStore.java:633)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:399)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:78)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:84)
	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6396)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:236)
	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1625)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:80)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:130)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:101)
	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3317)
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3356)
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3336)
	at org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3590)
	at org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:236)
	at org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:221)
	at org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:366)
	at org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:310)
	at org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:290)
	at org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:266)
	at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:545)
	at org.apache.hadoop.hive.ql.session.SessionState.beginStart(SessionState.java:518)
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:705)
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:641)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
16/08/16 09:48:11 [main]: INFO metastore.HiveMetaStore: Added public role in metastore
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Open transaction: count = 1, isActive = true at:
	org.apache.hadoop.hive.metastore.ObjectStore.grantPrivileges(ObjectStore.java:4480)
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Open transaction: count = 2, isActive = true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getMRole(ObjectStore.java:4087)
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Commit transaction: count = 1, isactive true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getMRole(ObjectStore.java:4093)
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Open transaction: count = 2, isActive = true at:
	org.apache.hadoop.hive.metastore.ObjectStore.listPrincipalMGlobalGrants(ObjectStore.java:4996)
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Commit transaction: count = 1, isactive true at:
	org.apache.hadoop.hive.metastore.ObjectStore.listPrincipalMGlobalGrants(ObjectStore.java:5004)
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Rollback transaction, isActive: true at:
	org.apache.hadoop.hive.metastore.ObjectStore.grantPrivileges(ObjectStore.java:4683)
16/08/16 09:48:11 [main]: DEBUG metastore.HiveMetaStore: Failed while granting global privs to admin
InvalidObjectException(message:All is already granted by admin)
	at org.apache.hadoop.hive.metastore.ObjectStore.grantPrivileges(ObjectStore.java:4516)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:101)
	at com.sun.proxy.$Proxy21.grantPrivileges(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultRoles_core(HiveMetaStore.java:667)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultRoles(HiveMetaStore.java:633)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:399)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:78)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:84)
	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6396)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:236)
	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1625)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:80)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:130)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:101)
	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3317)
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3356)
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3336)
	at org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3590)
	at org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:236)
	at org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:221)
	at org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:366)
	at org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:310)
	at org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:290)
	at org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:266)
	at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:545)
	at org.apache.hadoop.hive.ql.session.SessionState.beginStart(SessionState.java:518)
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:705)
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:641)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
16/08/16 09:48:11 [main]: INFO metastore.HiveMetaStore: No user is added in admin role, since config is empty
16/08/16 09:48:11 [main]: INFO metastore.HiveMetaStore: 0: get_all_functions
16/08/16 09:48:11 [main]: INFO HiveMetaStore.audit: ugi=spiderdt	ip=unknown-ip-addr	cmd=get_all_functions	
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Open transaction: count = 1, isActive = true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getAllFunctions(ObjectStore.java:7991)
16/08/16 09:48:11 [main]: DEBUG metastore.ObjectStore: Commit transaction: count = 0, isactive true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getAllFunctions(ObjectStore.java:7995)
16/08/16 09:48:11 [main]: DEBUG : address: client/192.168.1.2 isLoopbackAddress: false, with host 192.168.1.2 client
16/08/16 09:48:11 [main]: DEBUG logging.InternalLoggerFactory: Using SLF4J as the default logging framework
16/08/16 09:48:11 [main]: DEBUG internal.PlatformDependent0: java.nio.Buffer.address: available
16/08/16 09:48:11 [main]: DEBUG internal.PlatformDependent0: sun.misc.Unsafe.theUnsafe: available
16/08/16 09:48:11 [main]: DEBUG internal.PlatformDependent0: sun.misc.Unsafe.copyMemory: available
16/08/16 09:48:11 [main]: DEBUG internal.PlatformDependent0: java.nio.Bits.unaligned: true
16/08/16 09:48:11 [main]: DEBUG internal.PlatformDependent: UID: 1000
16/08/16 09:48:11 [main]: DEBUG internal.PlatformDependent: Java version: 8
16/08/16 09:48:11 [main]: DEBUG internal.PlatformDependent: -Dio.netty.noUnsafe: false
16/08/16 09:48:11 [main]: DEBUG internal.PlatformDependent: sun.misc.Unsafe: available
16/08/16 09:48:11 [main]: DEBUG internal.PlatformDependent: -Dio.netty.noJavassist: false
16/08/16 09:48:11 [main]: DEBUG internal.PlatformDependent: Javassist: unavailable
16/08/16 09:48:11 [main]: DEBUG internal.PlatformDependent: You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
16/08/16 09:48:11 [main]: DEBUG internal.PlatformDependent: -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
16/08/16 09:48:11 [main]: DEBUG internal.PlatformDependent: -Dio.netty.bitMode: 64 (sun.arch.data.model)
16/08/16 09:48:11 [main]: DEBUG internal.PlatformDependent: -Dio.netty.noPreferDirect: false
16/08/16 09:48:11 [main]: DEBUG internal.NativeLibraryLoader: -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
16/08/16 09:48:11 [main]: DEBUG internal.NativeLibraryLoader: -Dio.netty.netty.workdir: /tmp (io.netty.tmpdir)
16/08/16 09:48:11 [main]: DEBUG hdfs.BlockReaderLocal: dfs.client.use.legacy.blockreader.local = false
16/08/16 09:48:11 [main]: DEBUG hdfs.BlockReaderLocal: dfs.client.read.shortcircuit = false
16/08/16 09:48:11 [main]: DEBUG hdfs.BlockReaderLocal: dfs.client.domain.socket.data.traffic = false
16/08/16 09:48:11 [main]: DEBUG hdfs.BlockReaderLocal: dfs.domain.socket.path = 
16/08/16 09:48:11 [main]: DEBUG retry.RetryUtils: multipleLinearRandomRetry = null
16/08/16 09:48:11 [main]: DEBUG ipc.Server: rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@3b4d50b
16/08/16 09:48:11 [main]: DEBUG ipc.Client: getting client out of cache: org.apache.hadoop.ipc.Client@14fa92af
16/08/16 09:48:11 [client DomainSocketWatcher]: DEBUG unix.DomainSocketWatcher: org.apache.hadoop.net.unix.DomainSocketWatcher$2@29c1d7b9: starting with interruptCheckPeriodMs = 60000
16/08/16 09:48:11 [main]: DEBUG util.PerformanceAdvisory: Both short-circuit local reads and UNIX domain socket are disabled.
16/08/16 09:48:11 [main]: DEBUG sasl.DataTransferSaslUtil: DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
16/08/16 09:48:11 [main]: DEBUG ipc.Client: The ping interval is 60000 ms.
16/08/16 09:48:11 [main]: DEBUG ipc.Client: Connecting to /192.168.1.3:9000
16/08/16 09:48:11 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt: starting, having connections 1
16/08/16 09:48:11 [IPC Parameter Sending Thread #0]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #0
16/08/16 09:48:11 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #0
16/08/16 09:48:11 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 45ms
16/08/16 09:48:11 [IPC Parameter Sending Thread #0]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #1
16/08/16 09:48:11 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #1
16/08/16 09:48:11 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 3ms
16/08/16 09:48:11 [IPC Parameter Sending Thread #0]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #2
16/08/16 09:48:11 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #2
16/08/16 09:48:11 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 1ms
16/08/16 09:48:11 [IPC Parameter Sending Thread #0]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #3
16/08/16 09:48:11 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #3
16/08/16 09:48:11 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 1ms
16/08/16 09:48:11 [main]: DEBUG hdfs.DFSClient: /tmp/hive/spiderdt/51225d5e-db54-49c7-ac07-21870a695009: masked=rwx------
16/08/16 09:48:11 [IPC Parameter Sending Thread #0]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #4
16/08/16 09:48:11 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #4
16/08/16 09:48:11 [main]: DEBUG ipc.ProtobufRpcEngine: Call: mkdirs took 22ms
16/08/16 09:48:11 [IPC Parameter Sending Thread #0]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #5
16/08/16 09:48:11 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #5
16/08/16 09:48:11 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 2ms
16/08/16 09:48:11 [main]: DEBUG nativeio.NativeIO: Initialized cache for IDs to User/Group mapping with a  cache timeout of 14400 seconds.
16/08/16 09:48:11 [IPC Parameter Sending Thread #0]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #6
16/08/16 09:48:11 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #6
16/08/16 09:48:11 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 1ms
16/08/16 09:48:11 [main]: DEBUG hdfs.DFSClient: /tmp/hive/spiderdt/51225d5e-db54-49c7-ac07-21870a695009/_tmp_space.db: masked=rwx------
16/08/16 09:48:11 [IPC Parameter Sending Thread #0]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #7
16/08/16 09:48:11 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #7
16/08/16 09:48:11 [main]: DEBUG ipc.ProtobufRpcEngine: Call: mkdirs took 3ms
16/08/16 09:48:11 [IPC Parameter Sending Thread #0]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #8
16/08/16 09:48:11 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #8
16/08/16 09:48:11 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 1ms
16/08/16 09:48:11 [main]: DEBUG CliDriver: CliDriver inited with classpath /home/chong/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/spark-assembly-1.6.2-hadoop2.6.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/conf:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/accumulo-core-1.6.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/accumulo-fate-1.6.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/accumulo-start-1.6.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/accumulo-trace-1.6.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/activation-1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/ant-1.6.5.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/ant-1.9.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/ant-launcher-1.9.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/antlr-2.7.7.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/antlr4-runtime-4.5.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/antlr-runtime-3.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/aopalliance-1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/asm-3.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/asm-commons-3.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/asm-tree-3.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/avro-1.7.7.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/bonecp-0.8.0.RELEASE.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/calcite-avatica-1.6.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/calcite-core-1.6.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/calcite-linq4j-1.6.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/commons-cli-1.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/commons-codec-1.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/commons-collections-3.2.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/commons-compiler-2.7.6.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/commons-compress-1.9.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/commons-dbcp-1.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/commons-el-1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/commons-httpclient-3.0.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/commons-io-2.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/commons-lang-2.6.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/commons-lang3-3.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/commons-logging-1.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/commons-math-2.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/commons-pool-1.5.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/commons-vfs2-2.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/curator-client-2.6.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/curator-framework-2.6.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/curator-recipes-2.6.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/datanucleus-api-jdo-4.2.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/datanucleus-core-4.1.6.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/datanucleus-rdbms-4.1.7.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/derby-10.10.2.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/disruptor-3.3.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/eigenbase-properties-1.1.5.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/fastutil-6.5.6.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/findbugs-annotations-1.3.9-1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/geronimo-annotation_1.0_spec-1.1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/geronimo-jaspic_1.0_spec-1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/geronimo-jta_1.1_spec-1.1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/groovy-all-2.4.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/gson-2.2.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/guava-14.0.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/guice-3.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/guice-assistedinject-3.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/guice-servlet-3.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hamcrest-core-1.3.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hbase-annotations-1.1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hbase-client-1.1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hbase-common-1.1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hbase-common-1.1.1-tests.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hbase-hadoop2-compat-1.1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hbase-hadoop2-compat-1.1.1-tests.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hbase-hadoop-compat-1.1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hbase-prefix-tree-1.1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hbase-procedure-1.1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hbase-protocol-1.1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hbase-server-1.1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-accumulo-handler-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-ant-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-beeline-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-cli-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-common-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-contrib-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-exec-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-hbase-handler-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-hplsql-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-hwi-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-jdbc-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-llap-client-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-llap-common-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-llap-ext-client-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-llap-server-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-llap-tez-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-metastore-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-orc-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-serde-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-service-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-service-rpc-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-shims-0.23-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-shims-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-shims-common-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-shims-scheduler-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-storage-api-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-testutils-2.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/htrace-core-3.1.0-incubating.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/httpclient-4.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/httpcore-4.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/ivy-2.4.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jackson-annotations-2.4.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jackson-core-2.4.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jackson-databind-2.4.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jackson-jaxrs-1.9.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jackson-xc-1.9.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jamon-runtime-2.3.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/janino-2.7.6.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jasper-compiler-5.5.23.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jasper-runtime-5.5.23.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/javax.inject-1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/javax.jdo-3.2.0-m3.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/javax.servlet-3.0.0.v201112011016.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/javolution-5.5.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jcodings-1.0.8.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jcommander-1.32.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jdo-api-3.0.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jersey-client-1.9.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jersey-server-1.14.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jetty-6.1.26.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jetty-all-7.6.0.v20120127.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jetty-all-server-7.6.0.v20120127.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jetty-sslengine-6.1.26.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jetty-util-6.1.26.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jline-2.12.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/joda-time-2.5.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/joni-2.1.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jpam-1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/json-20090211.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jsp-2.1-6.1.14.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jsp-api-2.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jsp-api-2.1-6.1.14.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jsp-api-2.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jsr305-3.0.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/jta-1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/junit-4.11.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/libfb303-0.9.3.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/libthrift-0.9.3.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/log4j-1.2-api-2.4.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/log4j-api-2.4.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/log4j-core-2.4.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/log4j-slf4j-impl-2.4.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/log4j-web-2.4.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/mail-1.4.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/maven-scm-api-1.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/maven-scm-provider-svn-commons-1.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/maven-scm-provider-svnexe-1.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/metrics-core-2.2.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/metrics-core-3.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/metrics-json-3.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/metrics-jvm-3.1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/mysql-connector-java-5.1.39.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/netty-3.7.0.Final.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/netty-all-4.0.23.Final.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/opencsv-2.3.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/org.abego.treelayout.core-1.0.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/paranamer-2.3.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/parquet-hadoop-bundle-1.8.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/pentaho-aggdesigner-algorithm-5.1.5-jhyde.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/plexus-utils-1.5.6.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/protobuf-java-2.5.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/regexp-1.3.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/servlet-api-2.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/servlet-api-2.5-6.1.14.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/slider-core-0.90.2-incubating.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/snappy-0.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/snappy-java-1.0.5.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/spark-assembly-1.6.2-hadoop2.6.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/ST4-4.0.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/stax-api-1.0.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/stringtemplate-3.2.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/super-csv-2.2.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/tempus-fugit-1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/tephra-api-0.6.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/tephra-core-0.6.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/tephra-hbase-compat-1.0-0.6.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/transaction-api-1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/twill-api-0.6.0-incubating.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/twill-common-0.6.0-incubating.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/twill-core-0.6.0-incubating.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/twill-discovery-api-0.6.0-incubating.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/twill-discovery-core-0.6.0-incubating.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/twill-zookeeper-0.6.0-incubating.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/velocity-1.5.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/zookeeper-3.4.6.jar::/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hbase/conf:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hbase-1.2.2/lib/netty-all-4.0.23.Final.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hbase-1.2.2/lib/hbase-client-1.2.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hbase-1.2.2/lib/hbase-server-1.2.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hbase-1.2.2/lib/hbase-common-1.2.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hbase-1.2.2/lib/htrace-core-3.1.0-incubating.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hbase-1.2.2/lib/metrics-core-2.2.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hbase-1.2.2/lib/hbase-protocol-1.2.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hbase-1.2.2/lib/hbase-hadoop-compat-1.2.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/conf/hdfs:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar
hive> 16/08/16 09:48:21 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt: closed
16/08/16 09:48:21 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt: stopped, remaining connections 0

    > select count(*) from ods.d_sample_data where p_date = '2012-09-18' ;
16/08/16 09:55:22 [main]: DEBUG ql.Driver: Acquired the compile lock
16/08/16 09:55:22 [main]: DEBUG conf.VariableSubstitution: Substitution is on: select count(*) from ods.d_sample_data where p_date = '2012-09-18' 
16/08/16 09:55:22 [main]: INFO ql.Driver: Compiling command(queryId=spiderdt_20160816095522_18717c8b-3f00-49a6-8b7f-a80488d76090): select count(*) from ods.d_sample_data where p_date = '2012-09-18' 
16/08/16 09:55:22 [main]: DEBUG parse.ParseDriver: Parsing command: select count(*) from ods.d_sample_data where p_date = '2012-09-18' 
16/08/16 09:55:23 [main]: DEBUG parse.ParseDriver: Parse Completed
16/08/16 09:55:23 [main]: INFO parse.CalcitePlanner: Starting Semantic Analysis
16/08/16 09:55:23 [main]: INFO sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=51225d5e-db54-49c7-ac07-21870a695009, clientType=HIVECLI]
16/08/16 09:55:23 [main]: INFO hive.metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
16/08/16 09:55:23 [main]: DEBUG metadata.Hive: Creating new db. db = org.apache.hadoop.hive.ql.metadata.Hive@58833798, needsRefresh = false, db.isCurrentUserOwner = true
16/08/16 09:55:23 [main]: DEBUG metadata.Hive: Closing current thread's connection to Hive Metastore.
16/08/16 09:55:23 [main]: INFO metastore.HiveMetaStore: 0: Metastore shutdown started...
16/08/16 09:55:23 [main]: INFO HiveMetaStore.audit: ugi=spiderdt	ip=unknown-ip-addr	cmd=Metastore shutdown started...	
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@629ae7e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@20d11153 will be shutdown
16/08/16 09:55:23 [main]: INFO metastore.HiveMetaStore: 0: Metastore shutdown complete.
16/08/16 09:55:23 [main]: INFO HiveMetaStore.audit: ugi=spiderdt	ip=unknown-ip-addr	cmd=Metastore shutdown complete.	
16/08/16 09:55:23 [main]: DEBUG metadata.Hive: Closing current thread's connection to Hive Metastore.
16/08/16 09:55:23 [main]: DEBUG exec.FunctionRegistry: Looking up GenericUDAF: count
16/08/16 09:55:23 [main]: INFO parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
16/08/16 09:55:23 [main]: INFO parse.CalcitePlanner: Get metadata for source tables
16/08/16 09:55:23 [main]: INFO metastore.HiveMetaStore: 0: get_table : db=ods tbl=d_sample_data
16/08/16 09:55:23 [main]: INFO HiveMetaStore.audit: ugi=spiderdt	ip=unknown-ip-addr	cmd=get_table : db=ods tbl=d_sample_data	
16/08/16 09:55:23 [main]: INFO metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.storeManagerType value null from  jpox.properties with rdbms
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.schema.validateConstraints value null from  jpox.properties with false
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.autoStartMechanismMode value null from  jpox.properties with checked
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.schema.validateTables value null from  jpox.properties with false
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding javax.jdo.option.Multithreaded value null from  jpox.properties with true
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.cache.level2.type value null from  jpox.properties with none
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.connectionPoolingType value null from  jpox.properties with BONECP
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding javax.jdo.option.ConnectionUserName value null from  jpox.properties with hive
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.schema.autoCreateAll value null from  jpox.properties with false
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding javax.jdo.option.NonTransactionalRead value null from  jpox.properties with true
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.transactionIsolation value null from  jpox.properties with read-committed
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding javax.jdo.option.ConnectionURL value null from  jpox.properties with jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.schema.validateColumns value null from  jpox.properties with false
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.identifierFactory value null from  jpox.properties with datanucleus1
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding javax.jdo.PersistenceManagerFactoryClass value null from  jpox.properties with org.datanucleus.api.jdo.JDOPersistenceManagerFactory
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.cache.level2 value null from  jpox.properties with false
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.rdbms.useLegacyNativeValueStrategy value null from  jpox.properties with true
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding hive.metastore.integral.jdo.pushdown value null from  jpox.properties with false
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding javax.jdo.option.DetachAllOnCommit value null from  jpox.properties with true
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding javax.jdo.option.ConnectionDriverName value null from  jpox.properties with org.apache.derby.jdbc.EmbeddedDriver
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Overriding datanucleus.plugin.pluginRegistryBundleCheck value null from  jpox.properties with LOG
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: datanucleus.schema.autoCreateAll = false
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: datanucleus.schema.validateTables = false
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: datanucleus.rdbms.useLegacyNativeValueStrategy = true
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: datanucleus.schema.validateColumns = false
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: hive.metastore.integral.jdo.pushdown = false
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: datanucleus.autoStartMechanismMode = checked
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: javax.jdo.option.Multithreaded = true
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: datanucleus.identifierFactory = datanucleus1
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: datanucleus.transactionIsolation = read-committed
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: javax.jdo.option.ConnectionURL = jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: javax.jdo.option.DetachAllOnCommit = true
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: javax.jdo.option.NonTransactionalRead = true
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: javax.jdo.option.ConnectionDriverName = org.apache.derby.jdbc.EmbeddedDriver
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: datanucleus.schema.validateConstraints = false
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: javax.jdo.option.ConnectionUserName = hive
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: datanucleus.cache.level2 = false
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: datanucleus.plugin.pluginRegistryBundleCheck = LOG
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: datanucleus.cache.level2.type = none
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: javax.jdo.PersistenceManagerFactoryClass = org.datanucleus.api.jdo.JDOPersistenceManagerFactory
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: datanucleus.storeManagerType = rdbms
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: datanucleus.connectionPoolingType = BONECP
16/08/16 09:55:23 [main]: INFO metastore.ObjectStore: ObjectStore, initialize called
16/08/16 09:55:23 [main]: DEBUG metastore.MetaStoreDirectSql: Direct SQL query in 0.116977ms + 0.016731ms, the query is [SET @@session.sql_mode=ANSI_QUOTES]
16/08/16 09:55:23 [main]: INFO metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is MYSQL
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8054fe2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@28cd2c2 created in the thread with id: 1
16/08/16 09:55:23 [main]: INFO metastore.ObjectStore: Initialized ObjectStore
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Open transaction: count = 1, isActive = true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getTable(ObjectStore.java:1096)
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Open transaction: count = 2, isActive = true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getMTable(ObjectStore.java:1290)
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Commit transaction: count = 1, isactive true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getMTable(ObjectStore.java:1304)
16/08/16 09:55:23 [main]: DEBUG metastore.ObjectStore: Commit transaction: count = 0, isactive true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getTable(ObjectStore.java:1098)
16/08/16 09:55:23 [main]: INFO parse.CalcitePlanner: Get metadata for subqueries
16/08/16 09:55:23 [main]: INFO parse.CalcitePlanner: Get metadata for destination tables
16/08/16 09:55:23 [main]: ERROR hdfs.KeyProviderCache: Could not find uri with key [dfs.encryption.key.provider.uri] to create a keyProvider !!
16/08/16 09:55:23 [main]: DEBUG ipc.Client: The ping interval is 60000 ms.
16/08/16 09:55:23 [main]: DEBUG ipc.Client: Connecting to /192.168.1.3:9000
16/08/16 09:55:23 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt: starting, having connections 1
16/08/16 09:55:23 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #9
16/08/16 09:55:23 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #9
16/08/16 09:55:23 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getEZForPath took 4ms
16/08/16 09:55:23 [main]: DEBUG hdfs.DFSClient: /tmp/hive/spiderdt/51225d5e-db54-49c7-ac07-21870a695009/hive_2016-08-16_09-55-22_736_9092508509176823623-1: masked=rwx------
16/08/16 09:55:23 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #10
16/08/16 09:55:23 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #10
16/08/16 09:55:23 [main]: DEBUG ipc.ProtobufRpcEngine: Call: mkdirs took 25ms
16/08/16 09:55:23 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #11
16/08/16 09:55:23 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #11
16/08/16 09:55:23 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 1ms
16/08/16 09:55:23 [main]: INFO ql.Context: New scratch dir is hdfs://192.168.1.3:9000/tmp/hive/spiderdt/51225d5e-db54-49c7-ac07-21870a695009/hive_2016-08-16_09-55-22_736_9092508509176823623-1
16/08/16 09:55:23 [main]: INFO parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
16/08/16 09:55:23 [main]: DEBUG hive.log: DDL: struct d_sample_data { i32 inventory_id, i32 biblio_id, i32 order_id, i32 line_id, date date, date source_date, date pub_date, string catalog_type, double source_lcp, i32 current_lcp, double list_price, double rental_units, double rental_price, double rental_bookings, double site_liq_units, double site_liq_price, double site_liq_bookings, double real_price, string bisac_code, string bic_code, string literal, string literal_root, string audience, i32 biblio_series, string bisac_code_series, string literal_root_series}
16/08/16 09:55:23 [main]: DEBUG lazy.LazySerDeParameters: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe initialized with: columnNames=[inventory_id, biblio_id, order_id, line_id, date, source_date, pub_date, catalog_type, source_lcp, current_lcp, list_price, rental_units, rental_price, rental_bookings, site_liq_units, site_liq_price, site_liq_bookings, real_price, bisac_code, bic_code, literal, literal_root, audience, biblio_series, bisac_code_series, literal_root_series] columnTypes=[int, int, int, int, date, date, date, string, double, int, double, double, double, double, double, double, double, double, string, string, string, string, string, int, string, string] separator=[[B@39f42d0e] nullstring=\N lastColumnTakesRest=false timestampFormats=null
16/08/16 09:55:24 [main]: DEBUG exec.FunctionRegistry: Looking up GenericUDAF: count
16/08/16 09:55:24 [main]: DEBUG parse.CalcitePlanner: Created Plan for Query Block null
16/08/16 09:55:24 [main]: DEBUG ppr.PartitionPruner: Filter w/ compacting: (p_date = '2012-09-18'); filter w/o compacting: (p_date = '2012-09-18')
16/08/16 09:55:24 [main]: INFO metastore.HiveMetaStore: 0: get_partitions_by_expr : db=ods tbl=d_sample_data
16/08/16 09:55:24 [main]: INFO HiveMetaStore.audit: ugi=spiderdt	ip=unknown-ip-addr	cmd=get_partitions_by_expr : db=ods tbl=d_sample_data	
16/08/16 09:55:24 [main]: DEBUG metastore.ObjectStore: Open transaction: count = 1, isActive = true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getTable(ObjectStore.java:1096)
16/08/16 09:55:24 [main]: DEBUG metastore.ObjectStore: Open transaction: count = 2, isActive = true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getMTable(ObjectStore.java:1290)
16/08/16 09:55:24 [main]: DEBUG metastore.ObjectStore: Commit transaction: count = 1, isactive true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getMTable(ObjectStore.java:1304)
16/08/16 09:55:24 [main]: DEBUG metastore.ObjectStore: Commit transaction: count = 0, isactive true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getTable(ObjectStore.java:1098)
16/08/16 09:55:24 [main]: DEBUG metastore.PartFilterExprUtil: Filter specified is (p_date = '2012-09-18')
16/08/16 09:55:24 [main]: DEBUG metastore.ObjectStore: Open transaction: count = 1, isActive = true at:
	org.apache.hadoop.hive.metastore.ObjectStore$GetHelper.start(ObjectStore.java:2687)
16/08/16 09:55:24 [main]: DEBUG metastore.ObjectStore: Open transaction: count = 2, isActive = true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getMTable(ObjectStore.java:1290)
16/08/16 09:55:24 [main]: DEBUG metastore.ObjectStore: Commit transaction: count = 1, isactive true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getMTable(ObjectStore.java:1304)
16/08/16 09:55:24 [main]: DEBUG metastore.MetaStoreDirectSql: Direct SQL query in 0.136972ms + 0.014391ms, the query is [SET @@session.sql_mode=ANSI_QUOTES]
16/08/16 09:55:24 [main]: DEBUG metastore.MetaStoreDirectSql: Direct SQL query in 4.098559ms + 0.023905ms, the query is [select "PARTITIONS"."PART_ID" from "PARTITIONS"  inner join "TBLS" on "PARTITIONS"."TBL_ID" = "TBLS"."TBL_ID"     and "TBLS"."TBL_NAME" = ?   inner join "DBS" on "TBLS"."DB_ID" = "DBS"."DB_ID"      and "DBS"."NAME" = ? inner join "PARTITION_KEY_VALS" "FILTER0" on "FILTER0"."PART_ID" = "PARTITIONS"."PART_ID" and "FILTER0"."INTEGER_IDX" = 0 where (("FILTER0"."PART_KEY_VAL" = ?))]
16/08/16 09:55:24 [main]: DEBUG metastore.MetaStoreDirectSql: Direct SQL query in 0.692801ms + 0.433944ms, the query is [select "PARTITIONS"."PART_ID", "SDS"."SD_ID", "SDS"."CD_ID", "SERDES"."SERDE_ID", "PARTITIONS"."CREATE_TIME", "PARTITIONS"."LAST_ACCESS_TIME", "SDS"."INPUT_FORMAT", "SDS"."IS_COMPRESSED", "SDS"."IS_STOREDASSUBDIRECTORIES", "SDS"."LOCATION", "SDS"."NUM_BUCKETS", "SDS"."OUTPUT_FORMAT", "SERDES"."NAME", "SERDES"."SLIB" from "PARTITIONS"  left outer join "SDS" on "PARTITIONS"."SD_ID" = "SDS"."SD_ID"   left outer join "SERDES" on "SDS"."SERDE_ID" = "SERDES"."SERDE_ID" where "PART_ID" in (15576,15577,15578,15579,15580) order by "PART_NAME" asc]
16/08/16 09:55:24 [main]: DEBUG metastore.MetaStoreDirectSql: Direct SQL query in 0.576138ms + 0.343696ms, the query is [select "PART_ID", "PARAM_KEY", "PARAM_VALUE" from "PARTITION_PARAMS" where "PART_ID" in (15576,15577,15578,15579,15580) and "PARAM_KEY" is not null order by "PART_ID" asc]
16/08/16 09:55:24 [main]: DEBUG metastore.MetaStoreDirectSql: Direct SQL query in 0.518183ms + 0.150186ms, the query is [select "PART_ID", "PART_KEY_VAL" from "PARTITION_KEY_VALS" where "PART_ID" in (15576,15577,15578,15579,15580) and "INTEGER_IDX" >= 0 order by "PART_ID" asc, "INTEGER_IDX" asc]
16/08/16 09:55:24 [main]: DEBUG metastore.MetaStoreDirectSql: Direct SQL query in 0.434036ms + 0.031662ms, the query is [select "SD_ID", "PARAM_KEY", "PARAM_VALUE" from "SD_PARAMS" where "SD_ID" in (15688,15689,15690,15691,15692) and "PARAM_KEY" is not null order by "SD_ID" asc]
16/08/16 09:55:24 [main]: DEBUG metastore.MetaStoreDirectSql: Direct SQL query in 0.430483ms + 0.03377ms, the query is [select "SD_ID", "COLUMN_NAME", "SORT_COLS"."ORDER" from "SORT_COLS" where "SD_ID" in (15688,15689,15690,15691,15692) and "INTEGER_IDX" >= 0 order by "SD_ID" asc, "INTEGER_IDX" asc]
16/08/16 09:55:24 [main]: DEBUG metastore.MetaStoreDirectSql: Direct SQL query in 0.41493ms + 0.029781ms, the query is [select "SD_ID", "BUCKET_COL_NAME" from "BUCKETING_COLS" where "SD_ID" in (15688,15689,15690,15691,15692) and "INTEGER_IDX" >= 0 order by "SD_ID" asc, "INTEGER_IDX" asc]
16/08/16 09:55:24 [main]: DEBUG metastore.MetaStoreDirectSql: Direct SQL query in 0.424482ms + 0.030586ms, the query is [select "SD_ID", "SKEWED_COL_NAME" from "SKEWED_COL_NAMES" where "SD_ID" in (15688,15689,15690,15691,15692) and "INTEGER_IDX" >= 0 order by "SD_ID" asc, "INTEGER_IDX" asc]
16/08/16 09:55:24 [main]: DEBUG metastore.MetaStoreDirectSql: Direct SQL query in 0.502815ms + 0.27667ms, the query is [select "CD_ID", "COMMENT", "COLUMN_NAME", "TYPE_NAME" from "COLUMNS_V2" where "CD_ID" in (117) and "INTEGER_IDX" >= 0 order by "CD_ID" asc, "INTEGER_IDX" asc]
16/08/16 09:55:24 [main]: DEBUG metastore.MetaStoreDirectSql: Direct SQL query in 0.520701ms + 0.109322ms, the query is [select "SERDE_ID", "PARAM_KEY", "PARAM_VALUE" from "SERDE_PARAMS" where "SERDE_ID" in (15688,15689,15690,15691,15692) and "PARAM_KEY" is not null order by "SERDE_ID" asc]
16/08/16 09:55:24 [main]: DEBUG metastore.ObjectStore: Commit transaction: count = 0, isactive true at:
	org.apache.hadoop.hive.metastore.ObjectStore$GetHelper.commit(ObjectStore.java:2747)
16/08/16 09:55:24 [main]: DEBUG metastore.ObjectStore: 5 entries retrieved using SQL in 31.544522ms
16/08/16 09:55:24 [main]: DEBUG parse.CalcitePlanner: CBO Planning details:

16/08/16 09:55:24 [main]: DEBUG parse.CalcitePlanner: Original Plan:
HiveProject(_o__c0=[$0])
  HiveAggregate(group=[{}], agg#0=[count()])
    HiveProject($f0=[$0])
      HiveFilter(condition=[=($26, _UTF-16LE'2012-09-18')])
        HiveTableScan(table=[[ods.d_sample_data]])

16/08/16 09:55:24 [main]: DEBUG parse.CalcitePlanner: Plan After PPD, PartPruning, ColumnPruning:
HiveAggregate(group=[{}], agg#0=[count()])
  HiveProject(p_date=[CAST(_UTF-16LE'2012-09-18'):VARCHAR(2147483647) CHARACTER SET "UTF-16LE" COLLATE "ISO-8859-1$en_US$primary"])
    HiveFilter(condition=[=($26, _UTF-16LE'2012-09-18')])
      HiveTableScan(table=[[ods.d_sample_data]])

16/08/16 09:55:24 [main]: DEBUG parse.CalcitePlanner: Plan After Join Reordering:
HiveAggregate(group=[{}], agg#0=[count()]): rowcount = 1.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 87
  HiveFilter(condition=[=($26, _UTF-16LE'2012-09-18')]): rowcount = 1.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 81
    HiveTableScan(table=[[ods.d_sample_data]]): rowcount = 1.0, cumulative cost = {0}, id = 54

16/08/16 09:55:24 [main]: DEBUG translator.PlanModifierForASTConv: Original plan for PlanModifier
 HiveAggregate(group=[{}], agg#0=[count()])
  HiveFilter(condition=[=($26, _UTF-16LE'2012-09-18')])
    HiveTableScan(table=[[ods.d_sample_data]])

16/08/16 09:55:24 [main]: DEBUG translator.PlanModifierForASTConv: Plan after top-level introduceDerivedTable
 HiveProject($f0=[$0])
  HiveAggregate(group=[{}], agg#0=[count()])
    HiveFilter(condition=[=($26, _UTF-16LE'2012-09-18')])
      HiveTableScan(table=[[ods.d_sample_data]])

16/08/16 09:55:24 [main]: DEBUG translator.PlanModifierForASTConv: Plan after nested convertOpTree
 HiveProject($f0=[$0])
  HiveAggregate(group=[{}], agg#0=[count()])
    HiveFilter(condition=[=($26, _UTF-16LE'2012-09-18')])
      HiveTableScan(table=[[ods.d_sample_data]])

16/08/16 09:55:24 [main]: DEBUG translator.PlanModifierForASTConv: Plan after fixTopOBSchema
 HiveProject($f0=[$0])
  HiveAggregate(group=[{}], agg#0=[count()])
    HiveFilter(condition=[=($26, _UTF-16LE'2012-09-18')])
      HiveTableScan(table=[[ods.d_sample_data]])

16/08/16 09:55:24 [main]: DEBUG translator.PlanModifierForASTConv: Final plan after modifier
 HiveProject(c0=[$0])
  HiveAggregate(group=[{}], agg#0=[count()])
    HiveFilter(condition=[=($26, _UTF-16LE'2012-09-18')])
      HiveTableScan(table=[[ods.d_sample_data]])

16/08/16 09:55:24 [main]: DEBUG exec.FunctionRegistry: Looking up GenericUDAF: count
16/08/16 09:55:24 [main]: INFO parse.CalcitePlanner: Get metadata for source tables
16/08/16 09:55:24 [main]: INFO metastore.HiveMetaStore: 0: get_table : db=ods tbl=d_sample_data
16/08/16 09:55:24 [main]: INFO HiveMetaStore.audit: ugi=spiderdt	ip=unknown-ip-addr	cmd=get_table : db=ods tbl=d_sample_data	
16/08/16 09:55:24 [main]: DEBUG metastore.ObjectStore: Open transaction: count = 1, isActive = true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getTable(ObjectStore.java:1096)
16/08/16 09:55:24 [main]: DEBUG metastore.ObjectStore: Open transaction: count = 2, isActive = true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getMTable(ObjectStore.java:1290)
16/08/16 09:55:24 [main]: DEBUG metastore.ObjectStore: Commit transaction: count = 1, isactive true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getMTable(ObjectStore.java:1304)
16/08/16 09:55:24 [main]: DEBUG metastore.ObjectStore: Commit transaction: count = 0, isactive true at:
	org.apache.hadoop.hive.metastore.ObjectStore.getTable(ObjectStore.java:1098)
16/08/16 09:55:24 [main]: INFO parse.CalcitePlanner: Get metadata for subqueries
16/08/16 09:55:24 [main]: INFO parse.CalcitePlanner: Get metadata for destination tables
16/08/16 09:55:24 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #12
16/08/16 09:55:24 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #12
16/08/16 09:55:24 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getEZForPath took 1ms
16/08/16 09:55:24 [main]: INFO ql.Context: New scratch dir is hdfs://192.168.1.3:9000/tmp/hive/spiderdt/51225d5e-db54-49c7-ac07-21870a695009/hive_2016-08-16_09-55-22_736_9092508509176823623-1
16/08/16 09:55:24 [main]: DEBUG hive.log: DDL: struct d_sample_data { i32 inventory_id, i32 biblio_id, i32 order_id, i32 line_id, date date, date source_date, date pub_date, string catalog_type, double source_lcp, i32 current_lcp, double list_price, double rental_units, double rental_price, double rental_bookings, double site_liq_units, double site_liq_price, double site_liq_bookings, double real_price, string bisac_code, string bic_code, string literal, string literal_root, string audience, i32 biblio_series, string bisac_code_series, string literal_root_series}
16/08/16 09:55:24 [main]: DEBUG lazy.LazySerDeParameters: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe initialized with: columnNames=[inventory_id, biblio_id, order_id, line_id, date, source_date, pub_date, catalog_type, source_lcp, current_lcp, list_price, rental_units, rental_price, rental_bookings, site_liq_units, site_liq_price, site_liq_bookings, real_price, bisac_code, bic_code, literal, literal_root, audience, biblio_series, bisac_code_series, literal_root_series] columnTypes=[int, int, int, int, date, date, date, string, double, int, double, double, double, double, double, double, double, double, string, string, string, string, string, int, string, string] separator=[[B@5ddd84d2] nullstring=\N lastColumnTakesRest=false timestampFormats=null
16/08/16 09:55:24 [main]: DEBUG parse.CalcitePlanner: Created Table Plan for d_sample_data TS[0]
16/08/16 09:55:24 [main]: DEBUG parse.CalcitePlanner: Created Filter Plan for null row schema: d_sample_data{(inventory_id,inventory_id: int)(biblio_id,biblio_id: int)(order_id,order_id: int)(line_id,line_id: int)(date,date: date)(source_date,source_date: date)(pub_date,pub_date: date)(catalog_type,catalog_type: string)(source_lcp,source_lcp: double)(current_lcp,current_lcp: int)(list_price,list_price: double)(rental_units,rental_units: double)(rental_price,rental_price: double)(rental_bookings,rental_bookings: double)(site_liq_units,site_liq_units: double)(site_liq_price,site_liq_price: double)(site_liq_bookings,site_liq_bookings: double)(real_price,real_price: double)(bisac_code,bisac_code: string)(bic_code,bic_code: string)(literal,literal: string)(literal_root,literal_root: string)(audience,audience: string)(biblio_series,biblio_series: int)(bisac_code_series,bisac_code_series: string)(literal_root_series,literal_root_series: string)(p_date,p_date: string)(p_bisac_code,p_bisac_code: string)(block__offset__inside__file,BLOCK__OFFSET__INSIDE__FILE: bigint)(input__file__name,INPUT__FILE__NAME: string)(row__id,ROW__ID: struct<transactionid:bigint,bucketid:int,rowid:bigint>)} 
16/08/16 09:55:24 [main]: DEBUG exec.FunctionRegistry: Looking up GenericUDAF: count
16/08/16 09:55:24 [main]: DEBUG parse.CalcitePlanner: RR before GB d_sample_data{(inventory_id,inventory_id: int)(biblio_id,biblio_id: int)(order_id,order_id: int)(line_id,line_id: int)(date,date: date)(source_date,source_date: date)(pub_date,pub_date: date)(catalog_type,catalog_type: string)(source_lcp,source_lcp: double)(current_lcp,current_lcp: int)(list_price,list_price: double)(rental_units,rental_units: double)(rental_price,rental_price: double)(rental_bookings,rental_bookings: double)(site_liq_units,site_liq_units: double)(site_liq_price,site_liq_price: double)(site_liq_bookings,site_liq_bookings: double)(real_price,real_price: double)(bisac_code,bisac_code: string)(bic_code,bic_code: string)(literal,literal: string)(literal_root,literal_root: string)(audience,audience: string)(biblio_series,biblio_series: int)(bisac_code_series,bisac_code_series: string)(literal_root_series,literal_root_series: string)(p_date,p_date: string)(p_bisac_code,p_bisac_code: string)(block__offset__inside__file,BLOCK__OFFSET__INSIDE__FILE: bigint)(input__file__name,INPUT__FILE__NAME: string)(row__id,ROW__ID: struct<transactionid:bigint,bucketid:int,rowid:bigint>)}  after GB {((tok_functionstar count),_col0: bigint)} 
16/08/16 09:55:24 [main]: DEBUG parse.CalcitePlanner: tree: (tok_select (tok_selexpr (tok_functionstar count) c0))
16/08/16 09:55:24 [main]: DEBUG parse.CalcitePlanner: genSelectPlan: input = {((tok_functionstar count),_col0: bigint)}  starRr = d_sample_data{(inventory_id,inventory_id: int)(biblio_id,biblio_id: int)(order_id,order_id: int)(line_id,line_id: int)(date,date: date)(source_date,source_date: date)(pub_date,pub_date: date)(catalog_type,catalog_type: string)(source_lcp,source_lcp: double)(current_lcp,current_lcp: int)(list_price,list_price: double)(rental_units,rental_units: double)(rental_price,rental_price: double)(rental_bookings,rental_bookings: double)(site_liq_units,site_liq_units: double)(site_liq_price,site_liq_price: double)(site_liq_bookings,site_liq_bookings: double)(real_price,real_price: double)(bisac_code,bisac_code: string)(bic_code,bic_code: string)(literal,literal: string)(literal_root,literal_root: string)(audience,audience: string)(biblio_series,biblio_series: int)(bisac_code_series,bisac_code_series: string)(literal_root_series,literal_root_series: string)(p_date,p_date: string)(p_bisac_code,p_bisac_code: string)(block__offset__inside__file,BLOCK__OFFSET__INSIDE__FILE: bigint)(input__file__name,INPUT__FILE__NAME: string)(row__id,ROW__ID: struct<transactionid:bigint,bucketid:int,rowid:bigint>)} 
16/08/16 09:55:24 [main]: DEBUG parse.CalcitePlanner: Created Select Plan row schema: null{(c0,_col0: bigint)} 
16/08/16 09:55:24 [main]: DEBUG parse.CalcitePlanner: Created Select Plan for clause: insclause-0
16/08/16 09:55:24 [main]: DEBUG ql.Context: Created staging dir = hdfs://192.168.1.3:9000/tmp/hive/spiderdt/51225d5e-db54-49c7-ac07-21870a695009/hive_2016-08-16_09-55-22_736_9092508509176823623-1/-mr-10001/.hive-staging_hive_2016-08-16_09-55-22_736_9092508509176823623-1 for path = hdfs://192.168.1.3:9000/tmp/hive/spiderdt/51225d5e-db54-49c7-ac07-21870a695009/hive_2016-08-16_09-55-22_736_9092508509176823623-1/-mr-10001
16/08/16 09:55:24 [main]: INFO common.FileUtils: Creating directory if it doesn't exist: hdfs://192.168.1.3:9000/tmp/hive/spiderdt/51225d5e-db54-49c7-ac07-21870a695009/hive_2016-08-16_09-55-22_736_9092508509176823623-1/-mr-10001/.hive-staging_hive_2016-08-16_09-55-22_736_9092508509176823623-1
16/08/16 09:55:24 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #13
16/08/16 09:55:24 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #13
16/08/16 09:55:24 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 2ms
16/08/16 09:55:24 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #14
16/08/16 09:55:24 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #14
16/08/16 09:55:24 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 1ms
16/08/16 09:55:24 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #15
16/08/16 09:55:24 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #15
16/08/16 09:55:24 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 1ms
16/08/16 09:55:24 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #16
16/08/16 09:55:24 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #16
16/08/16 09:55:24 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 0ms
16/08/16 09:55:24 [main]: DEBUG hdfs.DFSClient: /tmp/hive/spiderdt/51225d5e-db54-49c7-ac07-21870a695009/hive_2016-08-16_09-55-22_736_9092508509176823623-1/-mr-10001/.hive-staging_hive_2016-08-16_09-55-22_736_9092508509176823623-1: masked=rwxr-xr-x
16/08/16 09:55:24 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #17
16/08/16 09:55:24 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #17
16/08/16 09:55:24 [main]: DEBUG ipc.ProtobufRpcEngine: Call: mkdirs took 7ms
16/08/16 09:55:24 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #18
16/08/16 09:55:24 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #18
16/08/16 09:55:24 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 1ms
16/08/16 09:55:24 [main]: DEBUG shims.HdfsUtils: {-chgrp,-R,supergroup,hdfs://192.168.1.3:9000/tmp/hive/spiderdt/51225d5e-db54-49c7-ac07-21870a695009/hive_2016-08-16_09-55-22_736_9092508509176823623-1/-mr-10001}
16/08/16 09:55:24 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #19
16/08/16 09:55:24 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #19
16/08/16 09:55:24 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 1ms
16/08/16 09:55:24 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #20
16/08/16 09:55:24 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #20
16/08/16 09:55:24 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getListing took 0ms
16/08/16 09:55:24 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #21
16/08/16 09:55:24 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #21
16/08/16 09:55:24 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getListing took 1ms
16/08/16 09:55:24 [main]: DEBUG shims.HdfsUtils: Return value is :0
16/08/16 09:55:24 [main]: DEBUG shims.HdfsUtils: {-chmod,-R,700,hdfs://192.168.1.3:9000/tmp/hive/spiderdt/51225d5e-db54-49c7-ac07-21870a695009/hive_2016-08-16_09-55-22_736_9092508509176823623-1/-mr-10001}
16/08/16 09:55:24 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #22
16/08/16 09:55:24 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #22
16/08/16 09:55:24 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 1ms
16/08/16 09:55:24 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #23
16/08/16 09:55:24 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #23
16/08/16 09:55:24 [main]: DEBUG ipc.ProtobufRpcEngine: Call: setPermission took 4ms
16/08/16 09:55:24 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #24
16/08/16 09:55:24 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #24
16/08/16 09:55:24 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getListing took 1ms
16/08/16 09:55:24 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #25
16/08/16 09:55:24 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #25
16/08/16 09:55:24 [main]: DEBUG ipc.ProtobufRpcEngine: Call: setPermission took 6ms
16/08/16 09:55:24 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #26
16/08/16 09:55:24 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #26
16/08/16 09:55:24 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getListing took 1ms
16/08/16 09:55:24 [main]: DEBUG shims.HdfsUtils: Return value is :0
16/08/16 09:55:24 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #27
16/08/16 09:55:24 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #27
16/08/16 09:55:24 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 1ms
16/08/16 09:55:24 [main]: DEBUG lazy.LazySerDeParameters: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe initialized with: columnNames=[_col0] columnTypes=[bigint] separator=[[B@4e5364a3] nullstring=\N lastColumnTakesRest=false timestampFormats=null
16/08/16 09:55:24 [main]: DEBUG lazy.LazySerDeParameters: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe initialized with: columnNames=[_col0] columnTypes=[bigint] separator=[[B@62054faf] nullstring=\N lastColumnTakesRest=false timestampFormats=null
16/08/16 09:55:24 [main]: DEBUG parse.CalcitePlanner: Set stats collection dir : hdfs://192.168.1.3:9000/tmp/hive/spiderdt/51225d5e-db54-49c7-ac07-21870a695009/hive_2016-08-16_09-55-22_736_9092508509176823623-1/-mr-10001/.hive-staging_hive_2016-08-16_09-55-22_736_9092508509176823623-1/-ext-10003
16/08/16 09:55:24 [main]: DEBUG parse.CalcitePlanner: Created FileSink Plan for clause: insclause-0dest_path: hdfs://192.168.1.3:9000/tmp/hive/spiderdt/51225d5e-db54-49c7-ac07-21870a695009/hive_2016-08-16_09-55-22_736_9092508509176823623-1/-mr-10001 row schema: null{(c0,_col0: bigint)} 
16/08/16 09:55:24 [main]: DEBUG parse.CalcitePlanner: Created Body Plan for Query Block null
16/08/16 09:55:24 [main]: DEBUG parse.CalcitePlanner: Created Plan for Query Block null
16/08/16 09:55:24 [main]: INFO parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
16/08/16 09:55:24 [main]: DEBUG parse.CalcitePlanner: Before logical optimization
TS[0]-FIL[1]-SEL[2]-GBY[3]-RS[4]-GBY[5]-SEL[6]-FS[7]
16/08/16 09:55:24 [main]: DEBUG optimizer.PointLookupOptimizer: Partition columns not separated for null, is not IN operator : 
16/08/16 09:55:24 [main]: INFO ppd.OpProcFactory: Processing for FS(7)
16/08/16 09:55:24 [main]: INFO ppd.OpProcFactory: Processing for SEL(6)
16/08/16 09:55:24 [main]: INFO ppd.OpProcFactory: Processing for GBY(5)
16/08/16 09:55:24 [main]: INFO ppd.OpProcFactory: Processing for RS(4)
16/08/16 09:55:24 [main]: INFO ppd.OpProcFactory: Processing for GBY(3)
16/08/16 09:55:24 [main]: INFO ppd.OpProcFactory: Processing for SEL(2)
16/08/16 09:55:24 [main]: INFO ppd.OpProcFactory: Processing for FIL(1)
16/08/16 09:55:24 [main]: DEBUG ppd.OpProcFactory: Pushdown predicates of FIL for alias d_sample_data: (p_date = '2012-09-18')
16/08/16 09:55:24 [main]: INFO ppd.OpProcFactory: Processing for TS(0)
16/08/16 09:55:24 [main]: DEBUG ppd.OpProcFactory: Pushdown predicates of TS for alias d_sample_data: (p_date = '2012-09-18')
16/08/16 09:55:24 [main]: DEBUG ppd.SimplePredicatePushDown: After PPD:
TS[0]-FIL[8]-SEL[2]-GBY[3]-RS[4]-GBY[5]-SEL[6]-FS[7]
16/08/16 09:55:24 [main]: DEBUG ppr.PartitionPruner: Filter w/ compacting: (p_date = '2012-09-18'); filter w/o compacting: (p_date = '2012-09-18')
16/08/16 09:55:24 [main]: DEBUG hive.log: DDL: struct d_sample_data { i32 inventory_id, i32 biblio_id, i32 order_id, i32 line_id, date date, date source_date, date pub_date, string catalog_type, double source_lcp, i32 current_lcp, double list_price, double rental_units, double rental_price, double rental_bookings, double site_liq_units, double site_liq_price, double site_liq_bookings, double real_price, string bisac_code, string bic_code, string literal, string literal_root, string audience, i32 biblio_series, string bisac_code_series, string literal_root_series}
16/08/16 09:55:24 [main]: DEBUG hive.log: DDL: struct d_sample_data { i32 inventory_id, i32 biblio_id, i32 order_id, i32 line_id, date date, date source_date, date pub_date, string catalog_type, double source_lcp, i32 current_lcp, double list_price, double rental_units, double rental_price, double rental_bookings, double site_liq_units, double site_liq_price, double site_liq_bookings, double real_price, string bisac_code, string bic_code, string literal, string literal_root, string audience, i32 biblio_series, string bisac_code_series, string literal_root_series}
16/08/16 09:55:24 [main]: DEBUG hive.log: DDL: struct d_sample_data { i32 inventory_id, i32 biblio_id, i32 order_id, i32 line_id, date date, date source_date, date pub_date, string catalog_type, double source_lcp, i32 current_lcp, double list_price, double rental_units, double rental_price, double rental_bookings, double site_liq_units, double site_liq_price, double site_liq_bookings, double real_price, string bisac_code, string bic_code, string literal, string literal_root, string audience, i32 biblio_series, string bisac_code_series, string literal_root_series}
16/08/16 09:55:24 [main]: DEBUG hive.log: DDL: struct d_sample_data { i32 inventory_id, i32 biblio_id, i32 order_id, i32 line_id, date date, date source_date, date pub_date, string catalog_type, double source_lcp, i32 current_lcp, double list_price, double rental_units, double rental_price, double rental_bookings, double site_liq_units, double site_liq_price, double site_liq_bookings, double real_price, string bisac_code, string bic_code, string literal, string literal_root, string audience, i32 biblio_series, string bisac_code_series, string literal_root_series}
16/08/16 09:55:24 [main]: DEBUG hive.log: DDL: struct d_sample_data { i32 inventory_id, i32 biblio_id, i32 order_id, i32 line_id, date date, date source_date, date pub_date, string catalog_type, double source_lcp, i32 current_lcp, double list_price, double rental_units, double rental_price, double rental_bookings, double site_liq_units, double site_liq_price, double site_liq_bookings, double real_price, string bisac_code, string bic_code, string literal, string literal_root, string audience, i32 biblio_series, string bisac_code_series, string literal_root_series}
16/08/16 09:55:24 [main]: DEBUG optimizer.ColumnPrunerProcFactory: Reduce Sink Operator 4 key:[]
16/08/16 09:55:24 [main]: INFO optimizer.ColumnPrunerProcFactory: RS 4 oldColExprMap: {VALUE._col0=Column[_col0]}
16/08/16 09:55:24 [main]: INFO optimizer.ColumnPrunerProcFactory: RS 4 newColExprMap: {VALUE._col0=Column[_col0]}
16/08/16 09:55:24 [main]: DEBUG optimizer.IdentityProjectRemover: Identity project remover optimization removed : SEL[6]
16/08/16 09:55:24 [main]: DEBUG parse.CalcitePlanner: After logical optimization
TS[0]-SEL[2]-GBY[3]-RS[4]-GBY[5]-FS[7]
16/08/16 09:55:24 [main]: DEBUG exec.TableScanOperator: Setting stats (Num rows: 1 Data size: 120112 Basic stats: PARTIAL Column stats: NONE) on TS[0]
16/08/16 09:55:24 [main]: DEBUG annotation.StatsRulesProcFactory: [0] STATS-TS[0] (d_sample_data):  numRows: 1 dataSize: 120112 basicStatsState: PARTIAL colStatsState: NONE colStats: null
16/08/16 09:55:24 [main]: DEBUG exec.SelectOperator: Setting stats (Num rows: 1 Data size: 120112 Basic stats: PARTIAL Column stats: NONE) on SEL[2]
16/08/16 09:55:24 [main]: DEBUG annotation.StatsRulesProcFactory: [1] STATS-SEL[2]:  numRows: 1 dataSize: 120112 basicStatsState: PARTIAL colStatsState: NONE colStats: null
16/08/16 09:55:24 [main]: DEBUG annotation.StatsRulesProcFactory: STATS-GBY[3]: inputSize: 120112 maxSplitSize: 256000000 parallelism: 1 containsGroupingSet: false sizeOfGroupingSet: 1
16/08/16 09:55:24 [main]: DEBUG annotation.StatsRulesProcFactory: [Case 1] STATS-GBY[3]: cardinality: 1
16/08/16 09:55:24 [main]: DEBUG exec.GroupByOperator: Setting stats (Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE) on GBY[3]
16/08/16 09:55:24 [main]: DEBUG annotation.StatsRulesProcFactory: [0] STATS-GBY[3]:  numRows: 1 dataSize: 8 basicStatsState: COMPLETE colStatsState: NONE colStats: {_col0= colName: _col0 colType: bigint countDistincts: 1 numNulls: 0 avgColLen: 8.0 numTrues: 0 numFalses: 0 isPrimaryKey: false}
16/08/16 09:55:24 [main]: DEBUG exec.ReduceSinkOperator: Setting stats (Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE) on RS[4]
16/08/16 09:55:24 [main]: DEBUG annotation.StatsRulesProcFactory: [0] STATS-RS[4]:  numRows: 1 dataSize: 8 basicStatsState: COMPLETE colStatsState: NONE colStats: {_col0= colName: _col0 colType: bigint countDistincts: 1 numNulls: 0 avgColLen: 8.0 numTrues: 0 numFalses: 0 isPrimaryKey: false}
16/08/16 09:55:24 [main]: DEBUG annotation.StatsRulesProcFactory: STATS-GBY[5]: inputSize: 1 maxSplitSize: 256000000 parallelism: 1 containsGroupingSet: false sizeOfGroupingSet: 1
16/08/16 09:55:24 [main]: DEBUG annotation.StatsRulesProcFactory: [Case 7] STATS-GBY[5]: cardinality: 0
16/08/16 09:55:24 [main]: INFO annotation.StatsRulesProcFactory: STATS-GBY[5]: Equals 0 in number of rows.0 rows will be set to 1
16/08/16 09:55:24 [main]: DEBUG exec.GroupByOperator: Setting stats (Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE) on GBY[5]
16/08/16 09:55:24 [main]: DEBUG annotation.StatsRulesProcFactory: [0] STATS-GBY[5]:  numRows: 1 dataSize: 8 basicStatsState: COMPLETE colStatsState: NONE colStats: {_col0= colName: _col0 colType: bigint countDistincts: 1 numNulls: 0 avgColLen: 8.0 numTrues: 0 numFalses: 0 isPrimaryKey: false}
16/08/16 09:55:24 [main]: DEBUG annotation.StatsRulesProcFactory: [0] STATS-FS[7]:  numRows: 1 dataSize: 8 basicStatsState: COMPLETE colStatsState: NONE colStats: {_col0= colName: _col0 colType: bigint countDistincts: 1 numNulls: 0 avgColLen: 8.0 numTrues: 0 numFalses: 0 isPrimaryKey: false}
16/08/16 09:55:24 [main]: DEBUG exec.TableScanOperator: Setting traits (org.apache.hadoop.hive.ql.plan.OpTraits@4ae958b0) on TS[0]
16/08/16 09:55:24 [main]: DEBUG exec.SelectOperator: Setting traits (org.apache.hadoop.hive.ql.plan.OpTraits@7c682e26) on SEL[2]
16/08/16 09:55:24 [main]: DEBUG exec.GroupByOperator: Setting traits (org.apache.hadoop.hive.ql.plan.OpTraits@4ff074a0) on GBY[3]
16/08/16 09:55:24 [main]: DEBUG exec.ReduceSinkOperator: Setting traits (org.apache.hadoop.hive.ql.plan.OpTraits@340fc1aa) on RS[4]
16/08/16 09:55:24 [main]: DEBUG exec.GroupByOperator: Setting traits (org.apache.hadoop.hive.ql.plan.OpTraits@34a33343) on GBY[5]
16/08/16 09:55:24 [main]: DEBUG exec.FileSinkOperator: Setting traits (org.apache.hadoop.hive.ql.plan.OpTraits@34a33343) on FS[7]
16/08/16 09:55:24 [main]: INFO spark.SetSparkReducerParallelism: Number of reducers determined to be: 1
16/08/16 09:55:24 [main]: DEBUG spark.GenSparkWork: Root operator: TS[0]
16/08/16 09:55:24 [main]: DEBUG spark.GenSparkWork: Leaf operator: RS[4]
16/08/16 09:55:24 [main]: DEBUG spark.GenSparkUtils: Adding map work (Map 1) for TS[0]
16/08/16 09:55:24 [main]: DEBUG ppr.PartitionPruner: Filter w/ compacting: (p_date = '2012-09-18'); filter w/o compacting: (p_date = '2012-09-18')
16/08/16 09:55:24 [main]: DEBUG hive.log: DDL: struct d_sample_data { i32 inventory_id, i32 biblio_id, i32 order_id, i32 line_id, date date, date source_date, date pub_date, string catalog_type, double source_lcp, i32 current_lcp, double list_price, double rental_units, double rental_price, double rental_bookings, double site_liq_units, double site_liq_price, double site_liq_bookings, double real_price, string bisac_code, string bic_code, string literal, string literal_root, string audience, i32 biblio_series, string bisac_code_series, string literal_root_series}
16/08/16 09:55:24 [main]: DEBUG hive.log: DDL: struct d_sample_data { i32 inventory_id, i32 biblio_id, i32 order_id, i32 line_id, date date, date source_date, date pub_date, string catalog_type, double source_lcp, i32 current_lcp, double list_price, double rental_units, double rental_price, double rental_bookings, double site_liq_units, double site_liq_price, double site_liq_bookings, double real_price, string bisac_code, string bic_code, string literal, string literal_root, string audience, i32 biblio_series, string bisac_code_series, string literal_root_series}
16/08/16 09:55:24 [main]: DEBUG hive.log: DDL: struct d_sample_data { i32 inventory_id, i32 biblio_id, i32 order_id, i32 line_id, date date, date source_date, date pub_date, string catalog_type, double source_lcp, i32 current_lcp, double list_price, double rental_units, double rental_price, double rental_bookings, double site_liq_units, double site_liq_price, double site_liq_bookings, double real_price, string bisac_code, string bic_code, string literal, string literal_root, string audience, i32 biblio_series, string bisac_code_series, string literal_root_series}
16/08/16 09:55:24 [main]: DEBUG optimizer.GenMapRedUtils: Adding hdfs://192.168.1.3:9000/user/hive/warehouse/ods.db/sample/data/p_date=2012-09-18/p_bisac_code=BUS008000 of tabled_sample_data
16/08/16 09:55:24 [main]: DEBUG hive.log: DDL: struct d_sample_data { i32 inventory_id, i32 biblio_id, i32 order_id, i32 line_id, date date, date source_date, date pub_date, string catalog_type, double source_lcp, i32 current_lcp, double list_price, double rental_units, double rental_price, double rental_bookings, double site_liq_units, double site_liq_price, double site_liq_bookings, double real_price, string bisac_code, string bic_code, string literal, string literal_root, string audience, i32 biblio_series, string bisac_code_series, string literal_root_series}
16/08/16 09:55:24 [main]: DEBUG hive.log: DDL: struct d_sample_data { i32 inventory_id, i32 biblio_id, i32 order_id, i32 line_id, date date, date source_date, date pub_date, string catalog_type, double source_lcp, i32 current_lcp, double list_price, double rental_units, double rental_price, double rental_bookings, double site_liq_units, double site_liq_price, double site_liq_bookings, double real_price, string bisac_code, string bic_code, string literal, string literal_root, string audience, i32 biblio_series, string bisac_code_series, string literal_root_series}
16/08/16 09:55:24 [main]: DEBUG optimizer.GenMapRedUtils: Adding hdfs://192.168.1.3:9000/user/hive/warehouse/ods.db/sample/data/p_date=2012-09-18/p_bisac_code=BUS010000 of tabled_sample_data
16/08/16 09:55:24 [main]: DEBUG hive.log: DDL: struct d_sample_data { i32 inventory_id, i32 biblio_id, i32 order_id, i32 line_id, date date, date source_date, date pub_date, string catalog_type, double source_lcp, i32 current_lcp, double list_price, double rental_units, double rental_price, double rental_bookings, double site_liq_units, double site_liq_price, double site_liq_bookings, double real_price, string bisac_code, string bic_code, string literal, string literal_root, string audience, i32 biblio_series, string bisac_code_series, string literal_root_series}
16/08/16 09:55:24 [main]: DEBUG hive.log: DDL: struct d_sample_data { i32 inventory_id, i32 biblio_id, i32 order_id, i32 line_id, date date, date source_date, date pub_date, string catalog_type, double source_lcp, i32 current_lcp, double list_price, double rental_units, double rental_price, double rental_bookings, double site_liq_units, double site_liq_price, double site_liq_bookings, double real_price, string bisac_code, string bic_code, string literal, string literal_root, string audience, i32 biblio_series, string bisac_code_series, string literal_root_series}
16/08/16 09:55:24 [main]: DEBUG optimizer.GenMapRedUtils: Adding hdfs://192.168.1.3:9000/user/hive/warehouse/ods.db/sample/data/p_date=2012-09-18/p_bisac_code=BUS019000 of tabled_sample_data
16/08/16 09:55:24 [main]: DEBUG hive.log: DDL: struct d_sample_data { i32 inventory_id, i32 biblio_id, i32 order_id, i32 line_id, date date, date source_date, date pub_date, string catalog_type, double source_lcp, i32 current_lcp, double list_price, double rental_units, double rental_price, double rental_bookings, double site_liq_units, double site_liq_price, double site_liq_bookings, double real_price, string bisac_code, string bic_code, string literal, string literal_root, string audience, i32 biblio_series, string bisac_code_series, string literal_root_series}
16/08/16 09:55:24 [main]: DEBUG hive.log: DDL: struct d_sample_data { i32 inventory_id, i32 biblio_id, i32 order_id, i32 line_id, date date, date source_date, date pub_date, string catalog_type, double source_lcp, i32 current_lcp, double list_price, double rental_units, double rental_price, double rental_bookings, double site_liq_units, double site_liq_price, double site_liq_bookings, double real_price, string bisac_code, string bic_code, string literal, string literal_root, string audience, i32 biblio_series, string bisac_code_series, string literal_root_series}
16/08/16 09:55:24 [main]: DEBUG optimizer.GenMapRedUtils: Adding hdfs://192.168.1.3:9000/user/hive/warehouse/ods.db/sample/data/p_date=2012-09-18/p_bisac_code=BUS030000 of tabled_sample_data
16/08/16 09:55:24 [main]: DEBUG hive.log: DDL: struct d_sample_data { i32 inventory_id, i32 biblio_id, i32 order_id, i32 line_id, date date, date source_date, date pub_date, string catalog_type, double source_lcp, i32 current_lcp, double list_price, double rental_units, double rental_price, double rental_bookings, double site_liq_units, double site_liq_price, double site_liq_bookings, double real_price, string bisac_code, string bic_code, string literal, string literal_root, string audience, i32 biblio_series, string bisac_code_series, string literal_root_series}
16/08/16 09:55:24 [main]: DEBUG hive.log: DDL: struct d_sample_data { i32 inventory_id, i32 biblio_id, i32 order_id, i32 line_id, date date, date source_date, date pub_date, string catalog_type, double source_lcp, i32 current_lcp, double list_price, double rental_units, double rental_price, double rental_bookings, double site_liq_units, double site_liq_price, double site_liq_bookings, double real_price, string bisac_code, string bic_code, string literal, string literal_root, string audience, i32 biblio_series, string bisac_code_series, string literal_root_series}
16/08/16 09:55:24 [main]: DEBUG optimizer.GenMapRedUtils: Adding hdfs://192.168.1.3:9000/user/hive/warehouse/ods.db/sample/data/p_date=2012-09-18/p_bisac_code=BUS041000 of tabled_sample_data
16/08/16 09:55:24 [main]: DEBUG hive.log: DDL: struct d_sample_data { i32 inventory_id, i32 biblio_id, i32 order_id, i32 line_id, date date, date source_date, date pub_date, string catalog_type, double source_lcp, i32 current_lcp, double list_price, double rental_units, double rental_price, double rental_bookings, double site_liq_units, double site_liq_price, double site_liq_bookings, double real_price, string bisac_code, string bic_code, string literal, string literal_root, string audience, i32 biblio_series, string bisac_code_series, string literal_root_series}
16/08/16 09:55:24 [main]: DEBUG hive.log: DDL: struct d_sample_data { i32 inventory_id, i32 biblio_id, i32 order_id, i32 line_id, date date, date source_date, date pub_date, string catalog_type, double source_lcp, i32 current_lcp, double list_price, double rental_units, double rental_price, double rental_bookings, double site_liq_units, double site_liq_price, double site_liq_bookings, double real_price, string bisac_code, string bic_code, string literal, string literal_root, string audience, i32 biblio_series, string bisac_code_series, string literal_root_series}
16/08/16 09:55:24 [main]: DEBUG optimizer.GenMapRedUtils: Information added for path hdfs://192.168.1.3:9000/user/hive/warehouse/ods.db/sample/data/p_date=2012-09-18/p_bisac_code=BUS008000
16/08/16 09:55:24 [main]: DEBUG optimizer.GenMapRedUtils: Information added for path hdfs://192.168.1.3:9000/user/hive/warehouse/ods.db/sample/data/p_date=2012-09-18/p_bisac_code=BUS010000
16/08/16 09:55:24 [main]: DEBUG optimizer.GenMapRedUtils: Information added for path hdfs://192.168.1.3:9000/user/hive/warehouse/ods.db/sample/data/p_date=2012-09-18/p_bisac_code=BUS019000
16/08/16 09:55:24 [main]: DEBUG optimizer.GenMapRedUtils: Information added for path hdfs://192.168.1.3:9000/user/hive/warehouse/ods.db/sample/data/p_date=2012-09-18/p_bisac_code=BUS030000
16/08/16 09:55:24 [main]: DEBUG optimizer.GenMapRedUtils: Information added for path hdfs://192.168.1.3:9000/user/hive/warehouse/ods.db/sample/data/p_date=2012-09-18/p_bisac_code=BUS041000
16/08/16 09:55:24 [main]: DEBUG spark.GenSparkWork: First pass. Leaf operator: RS[4]
16/08/16 09:55:24 [main]: DEBUG spark.GenSparkWork: Root operator: GBY[5]
16/08/16 09:55:24 [main]: DEBUG spark.GenSparkWork: Leaf operator: FS[7]
16/08/16 09:55:24 [main]: DEBUG spark.GenSparkUtils: Adding reduce work (Reducer 2) for GBY[5]
16/08/16 09:55:24 [main]: DEBUG spark.GenSparkUtils: Setting up reduce sink: RS[4] with following reduce work: Reducer 2
16/08/16 09:55:24 [main]: DEBUG spark.GenSparkWork: Removing RS[4] as parent from GBY[5]
16/08/16 09:55:24 [main]: DEBUG spark.GenSparkWork: First pass. Leaf operator: FS[7]
16/08/16 09:55:24 [main]: DEBUG parse.TaskCompiler: Skipping runtime skew join optimization
16/08/16 09:55:24 [main]: DEBUG physical.NullScanTaskDispatcher: Looking at: Map 1
16/08/16 09:55:24 [main]: DEBUG physical.NullScanTaskDispatcher: Looking for table scans where optimization is applicable
16/08/16 09:55:24 [main]: DEBUG physical.NullScanTaskDispatcher: Found 0 null table scans
16/08/16 09:55:24 [main]: DEBUG physical.NullScanTaskDispatcher: Looking at: Map 1
16/08/16 09:55:24 [main]: DEBUG physical.NullScanTaskDispatcher: Looking for table scans where optimization is applicable
16/08/16 09:55:24 [main]: DEBUG physical.NullScanTaskDispatcher: Found 0 null table scans
16/08/16 09:55:24 [main]: DEBUG physical.NullScanTaskDispatcher: Looking at: Map 1
16/08/16 09:55:24 [main]: DEBUG physical.NullScanTaskDispatcher: Looking for table scans where optimization is applicable
16/08/16 09:55:24 [main]: DEBUG physical.NullScanTaskDispatcher: Found 0 null table scans
16/08/16 09:55:24 [main]: DEBUG parse.TaskCompiler: Skipping vectorization
16/08/16 09:55:24 [main]: DEBUG parse.TaskCompiler: Skipping stage id rearranger
16/08/16 09:55:24 [main]: INFO parse.CalcitePlanner: Completed plan generation
16/08/16 09:55:24 [main]: INFO ql.Driver: Semantic Analysis Completed
16/08/16 09:55:24 [main]: DEBUG parse.CalcitePlanner: validation start
16/08/16 09:55:24 [main]: DEBUG parse.CalcitePlanner: not validating writeEntity, because entity is neither table nor partition
16/08/16 09:55:24 [main]: INFO ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:c0, type:bigint, comment:null)], properties:null)
16/08/16 09:55:24 [main]: DEBUG lazy.LazySerDeParameters: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe initialized with: columnNames=[_col0] columnTypes=[bigint] separator=[[B@2ec92631] nullstring=\N lastColumnTakesRest=false timestampFormats=null
16/08/16 09:55:24 [main]: INFO exec.ListSinkOperator: Initializing operator LIST_SINK[9]
16/08/16 09:55:24 [main]: DEBUG lazy.LazySerDeParameters: org.apache.hadoop.hive.serde2.DelimitedJSONSerDe initialized with: columnNames=[] columnTypes=[] separator=[[B@3c89b864] nullstring=NULL lastColumnTakesRest=false timestampFormats=null
16/08/16 09:55:24 [main]: DEBUG exec.ListSinkOperator: Initialization Done 9 LIST_SINK
16/08/16 09:55:24 [main]: DEBUG exec.ListSinkOperator: Operator 9 LIST_SINK initialized
16/08/16 09:55:24 [main]: DEBUG exec.ListSinkOperator: Initialization Done 9 LIST_SINK done is reset.
16/08/16 09:55:24 [main]: INFO metadata.Hive: Dumping metastore api call timing information for : compilation phase
16/08/16 09:55:24 [main]: DEBUG metadata.Hive: Total time spent in each metastore function (ms): {listPartitionsByExpr_(String, String, byte[], String, short, List, )=71}
16/08/16 09:55:24 [main]: INFO ql.Driver: Completed compiling command(queryId=spiderdt_20160816095522_18717c8b-3f00-49a6-8b7f-a80488d76090); Time taken: 1.993 seconds
16/08/16 09:55:24 [main]: INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager
16/08/16 09:55:24 [main]: INFO ql.Driver: Executing command(queryId=spiderdt_20160816095522_18717c8b-3f00-49a6-8b7f-a80488d76090): select count(*) from ods.d_sample_data where p_date = '2012-09-18' 
Query ID = spiderdt_20160816095522_18717c8b-3f00-49a6-8b7f-a80488d76090
Total jobs = 1
16/08/16 09:55:24 [main]: INFO ql.Driver: Query ID = spiderdt_20160816095522_18717c8b-3f00-49a6-8b7f-a80488d76090
16/08/16 09:55:24 [main]: INFO ql.Driver: Total jobs = 1
Launching Job 1 out of 1
16/08/16 09:55:24 [main]: INFO ql.Driver: Launching Job 1 out of 1
16/08/16 09:55:24 [main]: INFO ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>16/08/16 09:55:24 [main]: INFO spark.SparkTask: In order to change the average load for a reducer (in bytes):

In order to limit the maximum number of reducers:16/08/16 09:55:24 [main]: INFO spark.SparkTask:   set hive.exec.reducers.bytes.per.reducer=<number>

  set hive.exec.reducers.max=<number>16/08/16 09:55:24 [main]: INFO spark.SparkTask: In order to limit the maximum number of reducers:

In order to set a constant number of reducers:16/08/16 09:55:24 [main]: INFO spark.SparkTask:   set hive.exec.reducers.max=<number>

16/08/16 09:55:24 [main]: INFO spark.SparkTask: In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
16/08/16 09:55:24 [main]: INFO spark.SparkTask:   set mapreduce.job.reduces=<number>
16/08/16 09:55:24 [main]: INFO session.SparkSessionManagerImpl: Setting up the session manager.
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.admin.acl -> *).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.job.committer.cancel-timeout -> 60000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.master.hfilecleaner.plugins -> org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.process-kill-wait.ms -> 2000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.regionSplitLimit -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.scanner.timeout.period -> 60000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rootdir -> hdfs://192.168.1.3:9000/hbase).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hregion.majorcompaction -> 604800000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.admin.address -> 192.168.1.3:8033).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.logroll.period -> 3600000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hstore.compactionThreshold -> 3).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.client.job.max-retries -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hstore.bytes.per.checksum -> 16384).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.recovery.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.delete.thread-count -> 4).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.admin-env -> MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.ipc.client.fallback-to-simple-auth-allowed -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.checksum.algo.impl -> org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.log.retain-seconds -> 10800).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.max.perregion.tasks -> 1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hregion.max.filesize -> 10737418240).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.region.split.policy -> org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.server.thread.wakefrequency -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hregion.majorcompaction.jitter -> 0.50).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.coprocessor.abortonerror -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.master.logcleaner.ttl -> 600000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.ha.automatic-failover.embedded -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.keytab -> /etc/krb5.keytab).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.client.max-cached-nodemanagers-proxies -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.app-checker.class -> org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load spark property from hive configuration (spark.master -> yarn-cluster).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (zookeeper.znode.parent -> /hbase).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.am.max-attempts -> 2).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.ipc.server.callqueue.scan.ratio -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load RPC property from hive configuration (hive.spark.client.rpc.threads -> 8).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.thrift.framed.max_frame_size_in_mb -> 2).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load spark property from hive configuration (spark.serializer -> org.apache.spark.serializer.KryoSerializer).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.client.nodemanager-client-async.thread-pool-max-size -> 500).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.keytab -> /etc/krb5.keytab).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rest.filter.classes -> org.apache.hadoop.hbase.rest.filter.GzipFilter).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.master.port -> 16000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load RPC property from hive configuration (hive.spark.client.connect.timeout -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.dynamic.jars.dir -> hdfs://192.168.1.3:9000/hbase/lib).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.catalog.timeout -> 600000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hstore.blockingStoreFiles -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.client.retry-interval-ms -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.fs.state-store.uri -> /tmp/hadoop-spiderdt/yarn/system/rmstore).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hstore.checksum.algorithm -> CRC32).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.container.log.limit.kb -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.resourcemanager.minimum.version -> NONE).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.client.nodemanager-connect.retry-interval-ms -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.leveldb-timeline-store.read-cache-size -> 104857600).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.pmem-check-enabled -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.optionalcacheflushinterval -> 3600000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rpc.timeout -> 60000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.property.clientPort -> 2181).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.amlauncher.thread-count -> 50).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.nm.uploader.replication.factor -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.property.syncLimit -> 5).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.master.catalog.timeout -> 600000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.write.buffer -> 2097152).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.snapshot.restore.take.failsafe.snapshot -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.handler-thread-count -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.connect.max-wait.ms -> 900000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.localizer.fetch.thread-count -> 4).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.bulkload.staging.dir -> /user/spiderdt/hbase-staging).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (zookeeper.znode.rootserver -> root-region-server).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rest.port -> 8080).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.hostname -> 192.168.1.3).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.client.failover-retries-on-socket-timeouts -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rootdir.perms -> 700).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.windows-container.cpu-limit.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.vmem-pmem-ratio -> 2.1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.localityCheck.threadPoolSize -> 2).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms -> 300000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.auth.token.max.lifetime -> 604800000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.dns.nameserver -> default).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.container-manager.thread-count -> 20).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.snapshot.enabled -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.fs.state-store.retry-policy-spec -> 2000, 500).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.delete.debug-delay-sec -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.cells.scanned.per.heartbeat.check -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.container.liveness-monitor.interval-ms -> 600000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.acl.enable -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern -> ^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.zk-timeout-ms -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.max-completed-applications -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regions.slop -> 0.2).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.job.task.listener.thread-count -> 30).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.useMulti -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.connect.retry-interval.ms -> 30000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.webapp.address -> 0.0.0.0:8188).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.cleaner.resource-sleep-ms -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.http.staticuser.user -> dr.stack).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.table.max.rowsize -> 1073741824).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hstore.blockingWaitTime -> 90000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.bin.path -> /home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/bin/yarn).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.client.application-client-protocol.poll-interval-ms -> 200).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.quorum -> 192.168.1.3,192.168.1.4,192.168.1.5).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rpc.shortoperation.timeout -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.admin.thread-count -> 1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.log-aggregation.retain-check-interval-seconds -> -1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.thrift.framed -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load spark property from hive configuration (spark.executor.instances -> 1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.admin.client.thread-count -> 1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.tmp.dir -> /tmp/hbase-spiderdt).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.ttl-ms -> 604800000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.recovery.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.property.initLimit -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load spark property from hive configuration (spark.driver.memory -> 2g).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.thrift.compact -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.fs.state-store.retry-interval-ms -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.master.info.bindAddress -> 0.0.0.0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.lease.recovery.timeout -> 900000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.property.maxClientCnxns -> 300).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.online.schema.update.enable -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.store.in-memory.initial-delay-mins -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.security.exec.permission.checks -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.peerport -> 2888).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.webapp.address -> 0.0.0.0:8788).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.resource.mb -> 1536).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.container-monitor.interval-ms -> 3000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts -> 3).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.scheduler.maximum-allocation-vcores -> 32).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.dfs.client.read.shortcircuit.buffer.size -> 131072).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.http.policy -> HTTP_ONLY).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.region.replica.replication.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rest.readonly -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.config.read.zookeeper.config -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.snapshot.restore.failsafe.name -> hbase-failsafe-{snapshot.name}-{restore.timestamp}).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.scanner.max.result.size -> 2097152).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.metrics.showTableName -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.nm.uploader.thread-count -> 20).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.client.job.retry-interval -> 2000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.store.class -> org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.container-executor.class -> org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.shuffle.log.separate -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.http.filter.initializers -> org.apache.hadoop.hbase.http.lib.StaticUserWebFilter).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.max.perserver.tasks -> 5).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rest.threads.min -> 2).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.zk-retry-interval-ms -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.keyvalue.maxsize -> 10485760).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.remote-app-log-dir -> /tmp/logs).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.storescanner.parallel.seek.enable -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.webapp.address -> 192.168.1.3:8088).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.store.in-memory.check-period-mins -> 720).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.hostname -> 0.0.0.0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load RPC property from hive configuration (hive.spark.client.secret.bits -> 256).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.column.max.version -> 1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.resource-tracker.address -> 192.168.1.3:8031).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.disk-health-checker.min-healthy-disks -> 0.25).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.dns.interface -> default).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.master.loadbalancer.class -> org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.delayed.delegation-token.removal-interval-ms -> 30000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.handler.count -> 30).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.defaults.for.version.skip -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.server.compactchecker.interval.multiplier -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.master.distributed.log.replay -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.info.port -> 16030).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.storefile.refresh.period -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.uploader.server.address -> 0.0.0.0:8046).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rest.threads.max -> 100).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.balancer.period -> 300000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.info.bindAddress -> 0.0.0.0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.leveldb-state-store.path -> /tmp/hadoop-spiderdt/yarn/system/rmstore).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.master.logcleaner.plugins -> org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs -> 86400).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.windows-container.memory-limit.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.security.authentication -> simple).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.localizer.cache.cleanup.interval-ms -> 600000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.auth.key.update.interval -> 86400000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.zk-num-retries -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rest.support.proxyuser -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.env-whitelist -> JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,HADOOP_YARN_HOME).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.linux-container-executor.cgroups.hierarchy -> /hadoop-yarn).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.container.log.backups -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.disk-health-checker.interval-ms -> 120000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.resource-tracker.client.thread-count -> 50).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.proxy-user-privileges.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.cleaner.initial-delay-mins -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.admin.address -> 0.0.0.0:8047).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.cluster.distributed -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.linux-container-executor.cgroups.mount -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.fs.tmp.dir -> /user/spiderdt/hbase-staging).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.log-aggregation-enable -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.nodemanager.minimum.version -> NONE).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.local-cache.max-files-per-directory -> 8192).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.server.scanner.max.result.size -> 104857600).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.scheduler.maximum-allocation-mb -> 8192).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.thrift.maxQueuedRequests -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user -> nobody).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs -> 86400).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.max.total.tasks -> 100).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.info.port.auto -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.client.best-effort -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load RPC property from hive configuration (hive.spark.client.server.connect.timeout -> 90000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hregion.memstore.mslab.enabled -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.zk-state-store.parent-path -> /rmstore).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.client.failover-retries -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.port -> 16020).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.nodemanagers.heartbeat-interval-ms -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.dns.interface -> default).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.staging-dir -> /tmp/hadoop-yarn/staging).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.lease.recovery.dfs.timeout -> 64000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nm.liveness-monitor.expiry-interval-ms -> 600000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.table.lock.enable -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.local-dirs -> /tmp/hadoop-spiderdt/nm-local-dir).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.recovery.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hregion.percolumnfamilyflush.size.lower.bound -> 16777216).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage -> 90.0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.ipc.server.callqueue.read.ratio -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.health-checker.interval-ms -> 600000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.logroll.errors.tolerated -> 2).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.task.container.log.backups -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.http.max.threads -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.log-aggregation.compression-type -> none).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.log-dirs -> ${yarn.log.dir}/userlogs).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.address -> 0.0.0.0:0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.address -> 0.0.0.0:10200).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.configuration.provider-class -> org.apache.hadoop.yarn.LocalConfigurationProvider).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.status.multicast.address.ip -> 226.1.1.3).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.dns.nameserver -> default).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.status.multicast.address.port -> 16100).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.http-authentication.type -> simple).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.log-aggregation.retain-seconds -> -1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.scheduler.minimum-allocation-vcores -> 1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load spark property from hive configuration (spark.executor.memory -> 2g).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.client.max-retries -> 30).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.status.publisher.class -> org.apache.hadoop.hbase.master.ClusterStatusPublisher$MulticastPublisher).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.address -> 192.168.1.3:8032).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.nodemanager-connect-retries -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.client-server.address -> 0.0.0.0:8045).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.status.published -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.retries.number -> 35).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.linux-container-executor.resources-handler.class -> org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.work-preserving-recovery.enabled -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.scheduler.client.thread-count -> 50).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.status.listener.class -> org.apache.hadoop.hbase.client.ClusterStatusListener$MulticastListener).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.scanner.caching -> 2147483647).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.webapp.https.address -> 0.0.0.0:8190).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.command-opts -> -Xmx1024m).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.property.dataDir -> /tmp/hbase-spiderdt/zookeeper).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.client.failover-proxy-provider -> org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.remote-app-log-dir-suffix -> logs).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.local.dir -> /tmp/hbase-spiderdt/local/).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.localizer.client.thread-count -> 5).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.uploader.server.thread-count -> 50).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.security.visibility.mutations.checkauths -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.client.max-retries -> 3).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.scheduler.class -> org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.msginterval -> 3000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.scheduler.address -> 192.168.1.3:8030).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (zookeeper.znode.acl.parent -> acl).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.ha.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.state-store.max-completed-applications -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.shuffle.log.limit.kb -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds -> -1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.pause -> 100).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.state-store-class -> org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.store.class -> org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.scheduler.monitor.policies -> org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rs.cacheblocksonwrite -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.ipc.rpc.class -> org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.coprocessor.enabled -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.data.umask.enable -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.checksum.verify -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.keytab -> /etc/krb5.keytab).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.ttl-enable -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.ipc.server.callqueue.handler.factor -> 0.1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hregion.memstore.block.multiplier -> 4).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.hostname -> 0.0.0.0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hstore.time.to.purge.deletes -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.client.thread-count -> 50).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.thrift.htablepool.size.max -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.cleaner.period-mins -> 1440).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.resource.cpu-vcores -> 1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.root-dir -> /sharedcache).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.replication.rpc.codec -> org.apache.hadoop.hbase.codec.KeyValueCodecWithTags).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hstore.compaction.kv.max -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.scheduler.minimum-allocation-mb -> 1024).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.vmem-check-enabled -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.localizer.address -> 0.0.0.0:8040).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hstore.compaction.max -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.resource.cpu-vcores -> 8).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.thrift.maxWorkerThreads -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.data.umask -> 000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.coprocessor.user.enabled -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.zk-acl -> world:anyone:rwcda).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hstore.flusher.count -> 2).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.client.nodemanager-connect.max-wait-ms -> 180000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.client-am.ipc.max-retries -> 3).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.metrics.exposeOperationTimes -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.ipc.client.tcpnodelay -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.localizer.cache.target-size-mb -> 10240).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.store-class -> org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.recovery.dir -> /tmp/hadoop-spiderdt/yarn-nm-recovery).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load RPC property from hive configuration (hive.spark.client.rpc.max.size -> 52428800).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.docker-container-executor.exec-name -> /usr/bin/docker).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.store.in-memory.staleness-period-mins -> 10080).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.webapp.address -> 0.0.0.0:8042).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.job.committer.commit-window -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hregion.memstore.flush.size -> 134217728).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.bulkload.retries.number -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.hlog.reader.impl -> org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.sleep-delay-before-sigkill.ms -> 250).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.handler.abort.on.error.percent -> 0.5).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.shuffle.log.backups -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.coordinated.state.manager.class -> org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.scheduler.monitor.enable -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.server.versionfile.writeattempts -> 3).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.defaults.for.version -> 1.1.1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.am.liveness-monitor.expiry-interval-ms -> 600000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.leveldb-timeline-store.path -> /tmp/hadoop-spiderdt/yarn/timeline).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.ha.automatic-failover.enabled -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.leveldb-state-store.path -> /tmp/hadoop-spiderdt/yarn/timeline).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.hlog.writer.impl -> org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.leaderport -> 3888).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.thrift.minWorkerThreads -> 16).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.storescanner.parallel.seek.threads -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hregion.preclose.flush.size -> 5242880).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.resource.percentage-physical-cpu-limit -> 100).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.hard-kill-timeout-ms -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.http-authentication.simple.anonymous.allowed -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.client-server.thread-count -> 50).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.resource.memory-mb -> 8192).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.system-metrics-publisher.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.nested-level -> 3).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.health-checker.script.timeout-ms -> 1200000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.fs.state-store.num-retries -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.ha.automatic-failover.zk-base-path -> /yarn-leader-election).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.master.info.port -> 16010).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.aux-services.mapreduce_shuffle.class -> org.apache.hadoop.mapred.ShuffleHandler).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.master.infoserver.redirect -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.webapp.https.address -> 192.168.1.3:8090).
16/08/16 09:55:24 [main]: DEBUG channel.MultithreadEventLoopGroup: -Dio.netty.eventLoopThreads: 8
16/08/16 09:55:24 [main]: DEBUG nio.NioEventLoop: -Dio.netty.noKeySetOptimization: false
16/08/16 09:55:24 [main]: DEBUG nio.NioEventLoop: -Dio.netty.selectorAutoRebuildThreshold: 512
16/08/16 09:55:24 [main]: DEBUG internal.ThreadLocalRandom: -Dio.netty.initialSeedUniquifier: 0xd50ef4616d41179e (took 0 ms)
16/08/16 09:55:24 [main]: DEBUG buffer.ByteBufUtil: -Dio.netty.allocator.type: unpooled
16/08/16 09:55:24 [main]: DEBUG buffer.ByteBufUtil: -Dio.netty.threadLocalDirectBufferSize: 65536
16/08/16 09:55:24 [main]: DEBUG util.NetUtil: Loopback interface: lo (lo, 127.0.0.1)
16/08/16 09:55:24 [main]: DEBUG util.NetUtil: /proc/sys/net/core/somaxconn: 128
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.admin.acl -> *).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.job.committer.cancel-timeout -> 60000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.master.hfilecleaner.plugins -> org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.process-kill-wait.ms -> 2000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.regionSplitLimit -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.scanner.timeout.period -> 60000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rootdir -> hdfs://192.168.1.3:9000/hbase).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hregion.majorcompaction -> 604800000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.admin.address -> 192.168.1.3:8033).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.logroll.period -> 3600000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hstore.compactionThreshold -> 3).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.client.job.max-retries -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hstore.bytes.per.checksum -> 16384).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.recovery.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.delete.thread-count -> 4).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.admin-env -> MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.ipc.client.fallback-to-simple-auth-allowed -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.checksum.algo.impl -> org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.log.retain-seconds -> 10800).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.max.perregion.tasks -> 1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hregion.max.filesize -> 10737418240).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.region.split.policy -> org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.server.thread.wakefrequency -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hregion.majorcompaction.jitter -> 0.50).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.coprocessor.abortonerror -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.master.logcleaner.ttl -> 600000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.ha.automatic-failover.embedded -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.keytab -> /etc/krb5.keytab).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.client.max-cached-nodemanagers-proxies -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.app-checker.class -> org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load spark property from hive configuration (spark.master -> yarn-cluster).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (zookeeper.znode.parent -> /hbase).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.am.max-attempts -> 2).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.ipc.server.callqueue.scan.ratio -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load RPC property from hive configuration (hive.spark.client.rpc.threads -> 8).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.thrift.framed.max_frame_size_in_mb -> 2).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load spark property from hive configuration (spark.serializer -> org.apache.spark.serializer.KryoSerializer).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.client.nodemanager-client-async.thread-pool-max-size -> 500).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.keytab -> /etc/krb5.keytab).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rest.filter.classes -> org.apache.hadoop.hbase.rest.filter.GzipFilter).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.master.port -> 16000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load RPC property from hive configuration (hive.spark.client.connect.timeout -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.dynamic.jars.dir -> hdfs://192.168.1.3:9000/hbase/lib).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.catalog.timeout -> 600000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hstore.blockingStoreFiles -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.client.retry-interval-ms -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.fs.state-store.uri -> /tmp/hadoop-spiderdt/yarn/system/rmstore).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hstore.checksum.algorithm -> CRC32).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.container.log.limit.kb -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.resourcemanager.minimum.version -> NONE).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.client.nodemanager-connect.retry-interval-ms -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.leveldb-timeline-store.read-cache-size -> 104857600).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.pmem-check-enabled -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.optionalcacheflushinterval -> 3600000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rpc.timeout -> 60000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.property.clientPort -> 2181).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.amlauncher.thread-count -> 50).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.nm.uploader.replication.factor -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.property.syncLimit -> 5).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.master.catalog.timeout -> 600000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.write.buffer -> 2097152).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.snapshot.restore.take.failsafe.snapshot -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.handler-thread-count -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.connect.max-wait.ms -> 900000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.localizer.fetch.thread-count -> 4).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.bulkload.staging.dir -> /user/spiderdt/hbase-staging).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (zookeeper.znode.rootserver -> root-region-server).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rest.port -> 8080).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.hostname -> 192.168.1.3).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.client.failover-retries-on-socket-timeouts -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rootdir.perms -> 700).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.windows-container.cpu-limit.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.vmem-pmem-ratio -> 2.1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.localityCheck.threadPoolSize -> 2).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms -> 300000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.auth.token.max.lifetime -> 604800000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.dns.nameserver -> default).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.container-manager.thread-count -> 20).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.snapshot.enabled -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.fs.state-store.retry-policy-spec -> 2000, 500).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.delete.debug-delay-sec -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.cells.scanned.per.heartbeat.check -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.container.liveness-monitor.interval-ms -> 600000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.acl.enable -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern -> ^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.zk-timeout-ms -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.max-completed-applications -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regions.slop -> 0.2).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.job.task.listener.thread-count -> 30).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.useMulti -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.connect.retry-interval.ms -> 30000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.webapp.address -> 0.0.0.0:8188).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.cleaner.resource-sleep-ms -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.http.staticuser.user -> dr.stack).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.table.max.rowsize -> 1073741824).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hstore.blockingWaitTime -> 90000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.bin.path -> /home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/bin/yarn).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.client.application-client-protocol.poll-interval-ms -> 200).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.quorum -> 192.168.1.3,192.168.1.4,192.168.1.5).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rpc.shortoperation.timeout -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.admin.thread-count -> 1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.log-aggregation.retain-check-interval-seconds -> -1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.thrift.framed -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load spark property from hive configuration (spark.executor.instances -> 1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.admin.client.thread-count -> 1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.tmp.dir -> /tmp/hbase-spiderdt).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.ttl-ms -> 604800000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.recovery.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.property.initLimit -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load spark property from hive configuration (spark.driver.memory -> 2g).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.thrift.compact -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.fs.state-store.retry-interval-ms -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.master.info.bindAddress -> 0.0.0.0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.lease.recovery.timeout -> 900000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.property.maxClientCnxns -> 300).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.online.schema.update.enable -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.store.in-memory.initial-delay-mins -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.security.exec.permission.checks -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.peerport -> 2888).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.webapp.address -> 0.0.0.0:8788).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.resource.mb -> 1536).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.container-monitor.interval-ms -> 3000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts -> 3).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.scheduler.maximum-allocation-vcores -> 32).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.dfs.client.read.shortcircuit.buffer.size -> 131072).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.http.policy -> HTTP_ONLY).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.region.replica.replication.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rest.readonly -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.config.read.zookeeper.config -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.snapshot.restore.failsafe.name -> hbase-failsafe-{snapshot.name}-{restore.timestamp}).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.scanner.max.result.size -> 2097152).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.metrics.showTableName -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.nm.uploader.thread-count -> 20).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.client.job.retry-interval -> 2000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.store.class -> org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.container-executor.class -> org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.shuffle.log.separate -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.http.filter.initializers -> org.apache.hadoop.hbase.http.lib.StaticUserWebFilter).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.max.perserver.tasks -> 5).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rest.threads.min -> 2).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.zk-retry-interval-ms -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.keyvalue.maxsize -> 10485760).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.remote-app-log-dir -> /tmp/logs).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.storescanner.parallel.seek.enable -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.webapp.address -> 192.168.1.3:8088).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.store.in-memory.check-period-mins -> 720).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.hostname -> 0.0.0.0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load RPC property from hive configuration (hive.spark.client.secret.bits -> 256).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.column.max.version -> 1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.resource-tracker.address -> 192.168.1.3:8031).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.disk-health-checker.min-healthy-disks -> 0.25).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.dns.interface -> default).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.master.loadbalancer.class -> org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.delayed.delegation-token.removal-interval-ms -> 30000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.handler.count -> 30).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.defaults.for.version.skip -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.server.compactchecker.interval.multiplier -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.master.distributed.log.replay -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.info.port -> 16030).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.storefile.refresh.period -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.uploader.server.address -> 0.0.0.0:8046).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rest.threads.max -> 100).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.balancer.period -> 300000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.info.bindAddress -> 0.0.0.0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.leveldb-state-store.path -> /tmp/hadoop-spiderdt/yarn/system/rmstore).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.master.logcleaner.plugins -> org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs -> 86400).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.windows-container.memory-limit.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.security.authentication -> simple).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.localizer.cache.cleanup.interval-ms -> 600000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.auth.key.update.interval -> 86400000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.zk-num-retries -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rest.support.proxyuser -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.env-whitelist -> JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,HADOOP_YARN_HOME).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.linux-container-executor.cgroups.hierarchy -> /hadoop-yarn).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.container.log.backups -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.disk-health-checker.interval-ms -> 120000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.resource-tracker.client.thread-count -> 50).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.proxy-user-privileges.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.cleaner.initial-delay-mins -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.admin.address -> 0.0.0.0:8047).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.cluster.distributed -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.linux-container-executor.cgroups.mount -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.fs.tmp.dir -> /user/spiderdt/hbase-staging).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.log-aggregation-enable -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.nodemanager.minimum.version -> NONE).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.local-cache.max-files-per-directory -> 8192).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.server.scanner.max.result.size -> 104857600).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.scheduler.maximum-allocation-mb -> 8192).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.thrift.maxQueuedRequests -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user -> nobody).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs -> 86400).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.max.total.tasks -> 100).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.info.port.auto -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.client.best-effort -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load RPC property from hive configuration (hive.spark.client.server.connect.timeout -> 90000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hregion.memstore.mslab.enabled -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.zk-state-store.parent-path -> /rmstore).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.client.failover-retries -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.port -> 16020).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.nodemanagers.heartbeat-interval-ms -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.dns.interface -> default).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.staging-dir -> /tmp/hadoop-yarn/staging).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.lease.recovery.dfs.timeout -> 64000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nm.liveness-monitor.expiry-interval-ms -> 600000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.table.lock.enable -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.local-dirs -> /tmp/hadoop-spiderdt/nm-local-dir).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.recovery.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hregion.percolumnfamilyflush.size.lower.bound -> 16777216).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage -> 90.0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.ipc.server.callqueue.read.ratio -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.health-checker.interval-ms -> 600000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.logroll.errors.tolerated -> 2).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.task.container.log.backups -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.http.max.threads -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.log-aggregation.compression-type -> none).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.log-dirs -> ${yarn.log.dir}/userlogs).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.address -> 0.0.0.0:0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.address -> 0.0.0.0:10200).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.configuration.provider-class -> org.apache.hadoop.yarn.LocalConfigurationProvider).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.status.multicast.address.ip -> 226.1.1.3).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.dns.nameserver -> default).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.status.multicast.address.port -> 16100).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.http-authentication.type -> simple).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.log-aggregation.retain-seconds -> -1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.scheduler.minimum-allocation-vcores -> 1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load spark property from hive configuration (spark.executor.memory -> 2g).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.client.max-retries -> 30).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.status.publisher.class -> org.apache.hadoop.hbase.master.ClusterStatusPublisher$MulticastPublisher).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.address -> 192.168.1.3:8032).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.nodemanager-connect-retries -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.client-server.address -> 0.0.0.0:8045).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.status.published -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.retries.number -> 35).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.linux-container-executor.resources-handler.class -> org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.work-preserving-recovery.enabled -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.scheduler.client.thread-count -> 50).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.status.listener.class -> org.apache.hadoop.hbase.client.ClusterStatusListener$MulticastListener).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.scanner.caching -> 2147483647).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.webapp.https.address -> 0.0.0.0:8190).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.command-opts -> -Xmx1024m).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.property.dataDir -> /tmp/hbase-spiderdt/zookeeper).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.client.failover-proxy-provider -> org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.remote-app-log-dir-suffix -> logs).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.local.dir -> /tmp/hbase-spiderdt/local/).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.localizer.client.thread-count -> 5).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.uploader.server.thread-count -> 50).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.security.visibility.mutations.checkauths -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.client.max-retries -> 3).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.scheduler.class -> org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.msginterval -> 3000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.scheduler.address -> 192.168.1.3:8030).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (zookeeper.znode.acl.parent -> acl).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.ha.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.state-store.max-completed-applications -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.shuffle.log.limit.kb -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds -> -1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.client.pause -> 100).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.state-store-class -> org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.store.class -> org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.scheduler.monitor.policies -> org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.rs.cacheblocksonwrite -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.ipc.rpc.class -> org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.coprocessor.enabled -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.data.umask.enable -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.checksum.verify -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.keytab -> /etc/krb5.keytab).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.ttl-enable -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.ipc.server.callqueue.handler.factor -> 0.1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hregion.memstore.block.multiplier -> 4).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.hostname -> 0.0.0.0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hstore.time.to.purge.deletes -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.client.thread-count -> 50).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.thrift.htablepool.size.max -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.cleaner.period-mins -> 1440).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.resource.cpu-vcores -> 1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.root-dir -> /sharedcache).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.replication.rpc.codec -> org.apache.hadoop.hbase.codec.KeyValueCodecWithTags).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hstore.compaction.kv.max -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.scheduler.minimum-allocation-mb -> 1024).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.vmem-check-enabled -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.localizer.address -> 0.0.0.0:8040).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hstore.compaction.max -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.resource.cpu-vcores -> 8).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.thrift.maxWorkerThreads -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.data.umask -> 000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.coprocessor.user.enabled -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.zk-acl -> world:anyone:rwcda).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hstore.flusher.count -> 2).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.client.nodemanager-connect.max-wait-ms -> 180000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.client-am.ipc.max-retries -> 3).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.metrics.exposeOperationTimes -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.ipc.client.tcpnodelay -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.localizer.cache.target-size-mb -> 10240).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.store-class -> org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.recovery.dir -> /tmp/hadoop-spiderdt/yarn-nm-recovery).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms -> 1000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load RPC property from hive configuration (hive.spark.client.rpc.max.size -> 52428800).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.docker-container-executor.exec-name -> /usr/bin/docker).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.store.in-memory.staleness-period-mins -> 10080).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.webapp.address -> 0.0.0.0:8042).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.job.committer.commit-window -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hregion.memstore.flush.size -> 134217728).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.bulkload.retries.number -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.hlog.reader.impl -> org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.sleep-delay-before-sigkill.ms -> 250).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.handler.abort.on.error.percent -> 0.5).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.shuffle.log.backups -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.coordinated.state.manager.class -> org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.scheduler.monitor.enable -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.server.versionfile.writeattempts -> 3).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.defaults.for.version -> 1.1.1).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.am.liveness-monitor.expiry-interval-ms -> 600000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.leveldb-timeline-store.path -> /tmp/hadoop-spiderdt/yarn/timeline).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.ha.automatic-failover.enabled -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.leveldb-state-store.path -> /tmp/hadoop-spiderdt/yarn/timeline).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.regionserver.hlog.writer.impl -> org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.zookeeper.leaderport -> 3888).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.thrift.minWorkerThreads -> 16).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.storescanner.parallel.seek.threads -> 10).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.hregion.preclose.flush.size -> 5242880).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.resource.percentage-physical-cpu-limit -> 100).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.app.mapreduce.am.hard-kill-timeout-ms -> 10000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.timeline-service.http-authentication.simple.anonymous.allowed -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.client-server.thread-count -> 50).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.resource.memory-mb -> 8192).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.system-metrics-publisher.enabled -> false).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.sharedcache.nested-level -> 3).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.health-checker.script.timeout-ms -> 1200000).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.fs.state-store.num-retries -> 0).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.ha.automatic-failover.zk-base-path -> /yarn-leader-election).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.master.info.port -> 16010).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.nodemanager.aux-services.mapreduce_shuffle.class -> org.apache.hadoop.mapred.ShuffleHandler).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load HBase configuration (hbase.master.infoserver.redirect -> true).
16/08/16 09:55:24 [main]: INFO spark.HiveSparkClientFactory: load yarn property from hive configuration in yarn-cluster mode (yarn.resourcemanager.webapp.https.address -> 192.168.1.3:8090).
16/08/16 09:55:25 [main]: INFO client.SparkClientImpl: No spark.home provided, calling SparkSubmit directly.
16/08/16 09:55:25 [main]: INFO client.SparkClientImpl: Running client driver with argv: /home/spiderdt/work/git/spiderdt-env/cluster/tarball/jdk1.8.0_60/jre/bin/java org.apache.spark.deploy.SparkSubmit --executor-memory 2g --num-executors 1 --properties-file /tmp/spark-submit.2590599674292358145.properties --class org.apache.hive.spark.client.RemoteDriver /home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/hive-exec-2.1.0.jar --remote-host client --remote-port 40972 --conf hive.spark.client.connect.timeout=1000 --conf hive.spark.client.server.connect.timeout=90000 --conf hive.spark.client.channel.log.level=null --conf hive.spark.client.rpc.max.size=52428800 --conf hive.spark.client.rpc.threads=8 --conf hive.spark.client.secret.bits=256 --conf hive.spark.client.rpc.server.address=null
16/08/16 09:55:25 [stderr-redir-1]: INFO client.SparkClientImpl: Warning: Ignoring non-spark config property: hive.spark.client.server.connect.timeout=90000
16/08/16 09:55:25 [stderr-redir-1]: INFO client.SparkClientImpl: Warning: Ignoring non-spark config property: hive.spark.client.rpc.threads=8
16/08/16 09:55:25 [stderr-redir-1]: INFO client.SparkClientImpl: Warning: Ignoring non-spark config property: hive.spark.client.connect.timeout=1000
16/08/16 09:55:25 [stderr-redir-1]: INFO client.SparkClientImpl: Warning: Ignoring non-spark config property: hive.spark.client.secret.bits=256
16/08/16 09:55:25 [stderr-redir-1]: INFO client.SparkClientImpl: Warning: Ignoring non-spark config property: hive.spark.client.rpc.max.size=52428800
16/08/16 09:55:25 [stderr-redir-1]: INFO client.SparkClientImpl: SLF4J: Class path contains multiple SLF4J bindings.
16/08/16 09:55:25 [stderr-redir-1]: INFO client.SparkClientImpl: SLF4J: Found binding in [jar:file:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/apache-hive-2.1.0-bin/lib/log4j-slf4j-impl-2.4.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
16/08/16 09:55:25 [stderr-redir-1]: INFO client.SparkClientImpl: SLF4J: Found binding in [jar:file:/home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop-2.7.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
16/08/16 09:55:25 [stderr-redir-1]: INFO client.SparkClientImpl: SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
16/08/16 09:55:25 [stderr-redir-1]: INFO client.SparkClientImpl: SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
16/08/16 09:55:25 [stderr-redir-1]: INFO client.SparkClientImpl: ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.
16/08/16 09:55:30 [RPC-Handler-3]: DEBUG util.ResourceLeakDetector: -Dio.netty.leakDetectionLevel: simple
16/08/16 09:55:30 [RPC-Handler-3]: DEBUG util.Recycler: -Dio.netty.recycler.maxCapacity.default: 262144
16/08/16 09:55:30 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$SaslMessage (41 bytes)
16/08/16 09:55:30 [RPC-Handler-3]: DEBUG internal.Cleaner0: java.nio.ByteBuffer.cleaner(): available
16/08/16 09:55:30 [RPC-Handler-3]: DEBUG rpc.RpcServer$SaslServerHandler: Handling SASL challenge message...
16/08/16 09:55:30 [RPC-Handler-3]: DEBUG rpc.RpcServer$SaslServerHandler: Sending SASL challenge response...
16/08/16 09:55:30 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$SaslMessage (98 bytes)
16/08/16 09:55:30 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$SaslMessage (275 bytes)
16/08/16 09:55:30 [RPC-Handler-3]: DEBUG rpc.RpcServer$SaslServerHandler: Handling SASL challenge message...
16/08/16 09:55:30 [RPC-Handler-3]: DEBUG rpc.RpcServer$SaslServerHandler: Sending SASL challenge response...
16/08/16 09:55:30 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$SaslMessage (45 bytes)
16/08/16 09:55:30 [RPC-Handler-3]: DEBUG rpc.RpcServer$SaslServerHandler: SASL negotiation finished with QOP auth.
16/08/16 09:55:30 [main]: DEBUG session.SparkSessionManagerImpl: New session (e01100e1-b79e-4464-8efe-03fba9a96ced) is created.
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: /tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced: masked=rwx------
16/08/16 09:55:30 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #28
16/08/16 09:55:30 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #28
16/08/16 09:55:30 [main]: DEBUG ipc.ProtobufRpcEngine: Call: mkdirs took 29ms
16/08/16 09:55:30 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #29
16/08/16 09:55:30 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #29
16/08/16 09:55:30 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 1ms
16/08/16 09:55:30 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #30
16/08/16 09:55:30 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #30
16/08/16 09:55:30 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 1ms
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: /tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar: masked=rw-r--r--
16/08/16 09:55:30 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #31
16/08/16 09:55:30 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #31
16/08/16 09:55:30 [main]: DEBUG ipc.ProtobufRpcEngine: Call: create took 9ms
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [LeaseRenewer:spiderdt@192.168.1.3:9000]: DEBUG hdfs.LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1190001536_1] with renew id 1 started
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=0, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=0, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=64512, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 0
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: Allocating new block
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=1, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=1, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=129024, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 1
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=2, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=129024
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=2, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=193536, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 2
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=3, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=193536
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=3, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=258048, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 3
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=4, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=258048
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=4, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=322560, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 4
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=5, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=322560
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=5, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=387072, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 5
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=6, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=387072
16/08/16 09:55:30 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #32
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=6, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=451584, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 6
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=7, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=451584
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=7, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=516096, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 7
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=8, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=516096
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=8, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=580608, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 8
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=9, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=580608
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=9, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=645120, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 9
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=10, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=645120
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=10, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=709632, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 10
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #32
16/08/16 09:55:30 [Thread-17]: DEBUG ipc.ProtobufRpcEngine: Call: addBlock took 6ms
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=11, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=709632
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=11, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=774144, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 11
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=12, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=774144
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=12, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=838656, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 12
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=13, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=838656
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=13, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=903168, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 13
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=14, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=903168
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=14, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=967680, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 14
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=15, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=967680
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=15, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=1032192, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 15
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=16, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1032192
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=16, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=1096704, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 16
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=17, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1096704
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=17, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=1161216, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 17
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=18, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1161216
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=18, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=1225728, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 18
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=19, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1225728
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=19, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=1290240, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 19
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=20, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1290240
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=20, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=1354752, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 20
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=21, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1354752
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=21, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=1419264, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 21
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=22, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1419264
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=22, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=1483776, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 22
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=23, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1483776
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=23, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=1548288, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 23
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=24, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1548288
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=24, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=1612800, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 24
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=25, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1612800
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=25, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=1677312, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 25
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=26, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1677312
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=26, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=1741824, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 26
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=27, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1741824
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=27, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=1806336, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 27
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=28, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1806336
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=28, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=1870848, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 28
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=29, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1870848
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=29, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=1935360, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 29
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=30, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1935360
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=30, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=1999872, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 30
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=31, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1999872
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=31, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=2064384, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 31
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=32, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2064384
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=32, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=2128896, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 32
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=33, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2128896
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=33, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=2193408, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 33
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=34, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2193408
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=34, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=2257920, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 34
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=35, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2257920
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=35, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=2322432, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 35
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=36, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2322432
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=36, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=2386944, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 36
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=37, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2386944
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=37, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=2451456, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 37
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=38, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2451456
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=38, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=2515968, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 38
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=39, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2515968
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=39, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=2580480, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 39
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=40, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2580480
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=40, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=2644992, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 40
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=41, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2644992
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: pipeline = DatanodeInfoWithStorage[192.168.1.5:50010,DS-b2d4e3dd-27ee-4330-b476-f9a8f694587d,DISK]
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=41, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=2709504, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: pipeline = DatanodeInfoWithStorage[192.168.1.7:50010,DS-a0694e28-6249-430d-92ca-b5a0da1d08b1,DISK]
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: pipeline = DatanodeInfoWithStorage[192.168.1.6:50010,DS-b4c589a8-e20b-4d20-a321-df244c876bef,DISK]
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: Connecting to datanode 192.168.1.5:50010
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 41
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=42, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2709504
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=42, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=2774016, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 42
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=43, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2774016
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: Send buf size 131072
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=43, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=2838528, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 43
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=44, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2838528
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=44, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=2903040, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 44
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=45, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2903040
16/08/16 09:55:30 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #33
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=45, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=2967552, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 45
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=46, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2967552
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=46, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=3032064, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 46
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=47, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=3032064
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=47, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=3096576, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 47
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=48, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=3096576
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=48, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=3161088, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 48
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=49, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=3161088
16/08/16 09:55:30 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #33
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=49, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=3225600, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 49
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=50, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=3225600
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=50, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=3290112, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 50
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=51, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=3290112
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=51, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=3354624, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 51
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=52, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=3354624
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=52, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=3419136, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 52
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=53, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=3419136
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=53, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=3483648, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 53
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=54, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=3483648
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=54, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=3548160, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 54
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=55, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=3548160
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=55, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=3612672, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 55
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=56, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=3612672
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=56, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=3677184, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 56
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=57, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=3677184
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=57, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=3741696, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 57
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=58, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=3741696
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=58, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=3806208, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 58
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=59, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=3806208
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=59, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=3870720, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 59
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=60, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=3870720
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=60, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=3935232, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 60
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=61, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=3935232
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=61, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=3999744, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 61
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=62, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=3999744
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=62, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=4064256, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 62
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=63, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=4064256
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=63, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=4128768, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 63
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=64, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=4128768
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=64, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=4193280, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 64
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=65, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=4193280
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=65, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=4257792, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 65
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=66, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=4257792
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=66, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=4322304, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 66
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=67, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=4322304
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=67, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=4386816, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 67
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=68, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=4386816
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=68, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=4451328, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 68
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=69, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=4451328
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=69, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=4515840, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 69
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=70, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=4515840
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=70, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=4580352, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 70
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=71, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=4580352
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=71, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=4644864, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 71
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=72, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=4644864
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=72, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=4709376, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 72
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=73, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=4709376
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=73, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=4773888, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 73
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=74, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=4773888
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=74, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=4838400, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 74
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=75, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=4838400
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=75, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=4902912, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 75
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=76, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=4902912
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=76, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=4967424, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 76
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=77, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=4967424
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=77, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=5031936, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 77
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=78, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=5031936
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=78, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=5096448, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 78
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=79, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=5096448
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=79, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=5160960, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 79
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=80, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=5160960
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=80, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=5225472, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: Queued packet 80
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=81, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=5225472
16/08/16 09:55:30 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=81, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=5289984, blockSize=134217728, appendChunk=false
16/08/16 09:55:30 [Thread-17]: DEBUG ipc.ProtobufRpcEngine: Call: getServerDefaults took 6ms
16/08/16 09:55:30 [Thread-17]: DEBUG sasl.SaslDataTransferClient: SASL client skipping handshake in unsecured configuration for addr = /192.168.1.5, datanodeId = DatanodeInfoWithStorage[192.168.1.5:50010,DS-b2d4e3dd-27ee-4330-b476-f9a8f694587d,DISK]
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 129024
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 2 offsetInBlock: 129024 lastPacketInBlock: false lastByteOffsetInBlock: 193536
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 3 offsetInBlock: 193536 lastPacketInBlock: false lastByteOffsetInBlock: 258048
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 4 offsetInBlock: 258048 lastPacketInBlock: false lastByteOffsetInBlock: 322560
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 5 offsetInBlock: 322560 lastPacketInBlock: false lastByteOffsetInBlock: 387072
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 6 offsetInBlock: 387072 lastPacketInBlock: false lastByteOffsetInBlock: 451584
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 7 offsetInBlock: 451584 lastPacketInBlock: false lastByteOffsetInBlock: 516096
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 8 offsetInBlock: 516096 lastPacketInBlock: false lastByteOffsetInBlock: 580608
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 9 offsetInBlock: 580608 lastPacketInBlock: false lastByteOffsetInBlock: 645120
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 10 offsetInBlock: 645120 lastPacketInBlock: false lastByteOffsetInBlock: 709632
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 11 offsetInBlock: 709632 lastPacketInBlock: false lastByteOffsetInBlock: 774144
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 12 offsetInBlock: 774144 lastPacketInBlock: false lastByteOffsetInBlock: 838656
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 13 offsetInBlock: 838656 lastPacketInBlock: false lastByteOffsetInBlock: 903168
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 14 offsetInBlock: 903168 lastPacketInBlock: false lastByteOffsetInBlock: 967680
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 15 offsetInBlock: 967680 lastPacketInBlock: false lastByteOffsetInBlock: 1032192
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 16 offsetInBlock: 1032192 lastPacketInBlock: false lastByteOffsetInBlock: 1096704
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 17 offsetInBlock: 1096704 lastPacketInBlock: false lastByteOffsetInBlock: 1161216
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 18 offsetInBlock: 1161216 lastPacketInBlock: false lastByteOffsetInBlock: 1225728
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 19 offsetInBlock: 1225728 lastPacketInBlock: false lastByteOffsetInBlock: 1290240
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 20 offsetInBlock: 1290240 lastPacketInBlock: false lastByteOffsetInBlock: 1354752
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 21 offsetInBlock: 1354752 lastPacketInBlock: false lastByteOffsetInBlock: 1419264
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 22 offsetInBlock: 1419264 lastPacketInBlock: false lastByteOffsetInBlock: 1483776
16/08/16 09:55:30 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 23 offsetInBlock: 1483776 lastPacketInBlock: false lastByteOffsetInBlock: 1548288
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 24 offsetInBlock: 1548288 lastPacketInBlock: false lastByteOffsetInBlock: 1612800
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 25 offsetInBlock: 1612800 lastPacketInBlock: false lastByteOffsetInBlock: 1677312
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 26 offsetInBlock: 1677312 lastPacketInBlock: false lastByteOffsetInBlock: 1741824
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 27 offsetInBlock: 1741824 lastPacketInBlock: false lastByteOffsetInBlock: 1806336
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 28 offsetInBlock: 1806336 lastPacketInBlock: false lastByteOffsetInBlock: 1870848
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 29 offsetInBlock: 1870848 lastPacketInBlock: false lastByteOffsetInBlock: 1935360
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 30 offsetInBlock: 1935360 lastPacketInBlock: false lastByteOffsetInBlock: 1999872
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 31 offsetInBlock: 1999872 lastPacketInBlock: false lastByteOffsetInBlock: 2064384
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 32 offsetInBlock: 2064384 lastPacketInBlock: false lastByteOffsetInBlock: 2128896
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 33 offsetInBlock: 2128896 lastPacketInBlock: false lastByteOffsetInBlock: 2193408
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 34 offsetInBlock: 2193408 lastPacketInBlock: false lastByteOffsetInBlock: 2257920
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 35 offsetInBlock: 2257920 lastPacketInBlock: false lastByteOffsetInBlock: 2322432
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 36 offsetInBlock: 2322432 lastPacketInBlock: false lastByteOffsetInBlock: 2386944
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 37 offsetInBlock: 2386944 lastPacketInBlock: false lastByteOffsetInBlock: 2451456
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 38 offsetInBlock: 2451456 lastPacketInBlock: false lastByteOffsetInBlock: 2515968
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 39 offsetInBlock: 2515968 lastPacketInBlock: false lastByteOffsetInBlock: 2580480
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 40 offsetInBlock: 2580480 lastPacketInBlock: false lastByteOffsetInBlock: 2644992
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 41 offsetInBlock: 2644992 lastPacketInBlock: false lastByteOffsetInBlock: 2709504
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 42 offsetInBlock: 2709504 lastPacketInBlock: false lastByteOffsetInBlock: 2774016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 43 offsetInBlock: 2774016 lastPacketInBlock: false lastByteOffsetInBlock: 2838528
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 44 offsetInBlock: 2838528 lastPacketInBlock: false lastByteOffsetInBlock: 2903040
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 45 offsetInBlock: 2903040 lastPacketInBlock: false lastByteOffsetInBlock: 2967552
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 46 offsetInBlock: 2967552 lastPacketInBlock: false lastByteOffsetInBlock: 3032064
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 47 offsetInBlock: 3032064 lastPacketInBlock: false lastByteOffsetInBlock: 3096576
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 48 offsetInBlock: 3096576 lastPacketInBlock: false lastByteOffsetInBlock: 3161088
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 49 offsetInBlock: 3161088 lastPacketInBlock: false lastByteOffsetInBlock: 3225600
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 50 offsetInBlock: 3225600 lastPacketInBlock: false lastByteOffsetInBlock: 3290112
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 51 offsetInBlock: 3290112 lastPacketInBlock: false lastByteOffsetInBlock: 3354624
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 52 offsetInBlock: 3354624 lastPacketInBlock: false lastByteOffsetInBlock: 3419136
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 53 offsetInBlock: 3419136 lastPacketInBlock: false lastByteOffsetInBlock: 3483648
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 54 offsetInBlock: 3483648 lastPacketInBlock: false lastByteOffsetInBlock: 3548160
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 55 offsetInBlock: 3548160 lastPacketInBlock: false lastByteOffsetInBlock: 3612672
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 56 offsetInBlock: 3612672 lastPacketInBlock: false lastByteOffsetInBlock: 3677184
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 57 offsetInBlock: 3677184 lastPacketInBlock: false lastByteOffsetInBlock: 3741696
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 58 offsetInBlock: 3741696 lastPacketInBlock: false lastByteOffsetInBlock: 3806208
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 59 offsetInBlock: 3806208 lastPacketInBlock: false lastByteOffsetInBlock: 3870720
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 60 offsetInBlock: 3870720 lastPacketInBlock: false lastByteOffsetInBlock: 3935232
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 61 offsetInBlock: 3935232 lastPacketInBlock: false lastByteOffsetInBlock: 3999744
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 62 offsetInBlock: 3999744 lastPacketInBlock: false lastByteOffsetInBlock: 4064256
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 63 offsetInBlock: 4064256 lastPacketInBlock: false lastByteOffsetInBlock: 4128768
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 64 offsetInBlock: 4128768 lastPacketInBlock: false lastByteOffsetInBlock: 4193280
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 65 offsetInBlock: 4193280 lastPacketInBlock: false lastByteOffsetInBlock: 4257792
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 66 offsetInBlock: 4257792 lastPacketInBlock: false lastByteOffsetInBlock: 4322304
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 67 offsetInBlock: 4322304 lastPacketInBlock: false lastByteOffsetInBlock: 4386816
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 68 offsetInBlock: 4386816 lastPacketInBlock: false lastByteOffsetInBlock: 4451328
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 69 offsetInBlock: 4451328 lastPacketInBlock: false lastByteOffsetInBlock: 4515840
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 70 offsetInBlock: 4515840 lastPacketInBlock: false lastByteOffsetInBlock: 4580352
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 71 offsetInBlock: 4580352 lastPacketInBlock: false lastByteOffsetInBlock: 4644864
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 72 offsetInBlock: 4644864 lastPacketInBlock: false lastByteOffsetInBlock: 4709376
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 73 offsetInBlock: 4709376 lastPacketInBlock: false lastByteOffsetInBlock: 4773888
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 74 offsetInBlock: 4773888 lastPacketInBlock: false lastByteOffsetInBlock: 4838400
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 75 offsetInBlock: 4838400 lastPacketInBlock: false lastByteOffsetInBlock: 4902912
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 76 offsetInBlock: 4902912 lastPacketInBlock: false lastByteOffsetInBlock: 4967424
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 77 offsetInBlock: 4967424 lastPacketInBlock: false lastByteOffsetInBlock: 5031936
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 78 offsetInBlock: 5031936 lastPacketInBlock: false lastByteOffsetInBlock: 5096448
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 79 offsetInBlock: 5096448 lastPacketInBlock: false lastByteOffsetInBlock: 5160960
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 80 offsetInBlock: 5160960 lastPacketInBlock: false lastByteOffsetInBlock: 5225472
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4342570 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 81
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 81 offsetInBlock: 5225472 lastPacketInBlock: false lastByteOffsetInBlock: 5289984
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 4123921 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 2 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 3022278 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=82, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=5289984
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=82, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=5354496, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 3 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2196225 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 82
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=83, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=5354496
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=83, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=5419008, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 83
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=84, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=5419008
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 4 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2146355 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=84, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=5483520, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 84
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=85, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=5483520
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=85, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=5548032, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 85
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=86, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=5548032
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=86, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=5612544, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 82 offsetInBlock: 5289984 lastPacketInBlock: false lastByteOffsetInBlock: 5354496
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 83 offsetInBlock: 5354496 lastPacketInBlock: false lastByteOffsetInBlock: 5419008
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 5 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2072829 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 84 offsetInBlock: 5419008 lastPacketInBlock: false lastByteOffsetInBlock: 5483520
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 86
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=87, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=5612544
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=87, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=5677056, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 85 offsetInBlock: 5483520 lastPacketInBlock: false lastByteOffsetInBlock: 5548032
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 6 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2030615 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 86 offsetInBlock: 5548032 lastPacketInBlock: false lastByteOffsetInBlock: 5612544
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 87
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 87 offsetInBlock: 5612544 lastPacketInBlock: false lastByteOffsetInBlock: 5677056
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=88, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=5677056
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=88, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=5741568, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 7 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1970578 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 88
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=89, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=5741568
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=89, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=5806080, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 8 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1896431 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 9 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2129967 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 10 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2138947 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 11 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1941237 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 12 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2048848 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 13 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2101317 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 14 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1964773 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 15 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2037195 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 16 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2127570 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 17 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2033737 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 18 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2080708 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 19 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2081775 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 88 offsetInBlock: 5677056 lastPacketInBlock: false lastByteOffsetInBlock: 5741568
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 89
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=90, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=5806080
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=90, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=5870592, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 90
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=91, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=5870592
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=91, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=5935104, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 91
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=92, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=5935104
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=92, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=5999616, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 92
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=93, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=5999616
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=93, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=6064128, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 93
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=94, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6064128
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=94, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=6128640, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 94
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=95, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6128640
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=95, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=6193152, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 95
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=96, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6193152
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=96, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=6257664, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 96
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=97, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6257664
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=97, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=6322176, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 97
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=98, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6322176
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=98, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=6386688, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 98
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=99, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6386688
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=99, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=6451200, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 99
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=100, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6451200
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=100, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=6515712, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 100
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=101, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6515712
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=101, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=6580224, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 89 offsetInBlock: 5741568 lastPacketInBlock: false lastByteOffsetInBlock: 5806080
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 90 offsetInBlock: 5806080 lastPacketInBlock: false lastByteOffsetInBlock: 5870592
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 20 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2128987 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 101
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=102, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6580224
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=102, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=6644736, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 21 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2025843 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 91 offsetInBlock: 5870592 lastPacketInBlock: false lastByteOffsetInBlock: 5935104
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 102
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=103, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6644736
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 22 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2030619 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=103, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=6709248, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 103
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=104, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6709248
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=104, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=6773760, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 23 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2008244 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 104
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 92 offsetInBlock: 5935104 lastPacketInBlock: false lastByteOffsetInBlock: 5999616
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=105, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6773760
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=105, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=6838272, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 24 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2013593 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 93 offsetInBlock: 5999616 lastPacketInBlock: false lastByteOffsetInBlock: 6064128
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 105
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 94 offsetInBlock: 6064128 lastPacketInBlock: false lastByteOffsetInBlock: 6128640
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=106, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6838272
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=106, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=6902784, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 25 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1991353 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 106
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=107, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6902784
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=107, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=6967296, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 26 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2002454 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 107
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=108, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=6967296
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=108, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=7031808, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 27 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1983000 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 108
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=109, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=7031808
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 28 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1979621 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=109, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=7096320, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 109
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=110, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=7096320
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 29 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2037803 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=110, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=7160832, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 110
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=111, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=7160832
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 95 offsetInBlock: 6128640 lastPacketInBlock: false lastByteOffsetInBlock: 6193152
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 30 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2007232 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=111, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=7225344, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 111
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=112, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=7225344
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 31 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2123210 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=112, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=7289856, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 112
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=113, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=7289856
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 32 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1991442 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=113, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=7354368, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 96 offsetInBlock: 6193152 lastPacketInBlock: false lastByteOffsetInBlock: 6257664
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 113
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=114, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=7354368
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 97 offsetInBlock: 6257664 lastPacketInBlock: false lastByteOffsetInBlock: 6322176
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=114, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=7418880, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 33 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2036376 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 114
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=115, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=7418880
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 34 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1884791 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=115, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=7483392, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 115
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=116, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=7483392
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 35 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1908012 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=116, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=7547904, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 116
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=117, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=7547904
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 36 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2036915 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=117, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=7612416, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 117
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=118, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=7612416
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 37 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2042650 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=118, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=7676928, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 118
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=119, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=7676928
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 38 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2045693 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=119, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=7741440, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 119
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=120, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=7741440
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 39 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2030670 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=120, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=7805952, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 120
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=121, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=7805952
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 40 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2066407 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=121, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=7870464, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 41 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2037701 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 121
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=122, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=7870464
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 42 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2041259 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=122, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=7934976, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 122
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=123, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=7934976
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=123, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=7999488, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 43 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2055821 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 123
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=124, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=7999488
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=124, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=8064000, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 124
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 44 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2073344 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=125, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=8064000
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=125, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=8128512, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 45 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2056653 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 125
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=126, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=8128512
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=126, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=8193024, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 126
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 46 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2076238 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=127, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=8193024
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=127, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=8257536, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 127
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 47 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2044687 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=128, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=8257536
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=128, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=8322048, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 48 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2037684 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 128
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=129, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=8322048
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 49 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1959495 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=129, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=8386560, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 129
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=130, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=8386560
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 98 offsetInBlock: 6322176 lastPacketInBlock: false lastByteOffsetInBlock: 6386688
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=130, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=8451072, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 130
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=131, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=8451072
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 50 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1981897 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=131, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=8515584, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 131
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=132, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=8515584
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 51 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1963081 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=132, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=8580096, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 132
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=133, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=8580096
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 52 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1981502 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 99 offsetInBlock: 6386688 lastPacketInBlock: false lastByteOffsetInBlock: 6451200
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=133, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=8644608, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 133
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=134, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=8644608
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 53 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2035091 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=134, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=8709120, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 134
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=135, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=8709120
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 54 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2018083 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=135, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=8773632, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 100 offsetInBlock: 6451200 lastPacketInBlock: false lastByteOffsetInBlock: 6515712
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 55 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2056816 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 135
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=136, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=8773632
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 56 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2038744 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=136, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=8838144, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 136
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=137, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=8838144
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 57 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2021408 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=137, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=8902656, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 137
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=138, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=8902656
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 58 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2059084 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=138, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=8967168, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 138
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=139, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=8967168
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 59 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2031469 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=139, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=9031680, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 139
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=140, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=9031680
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 60 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2050456 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 101 offsetInBlock: 6515712 lastPacketInBlock: false lastByteOffsetInBlock: 6580224
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=140, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=9096192, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 140
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=141, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=9096192
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 61 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2075662 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=141, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=9160704, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 141
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=142, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=9160704
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 62 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2052885 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=142, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=9225216, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 142
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 102 offsetInBlock: 6580224 lastPacketInBlock: false lastByteOffsetInBlock: 6644736
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=143, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=9225216
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 63 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2094011 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=143, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=9289728, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 143
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=144, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=9289728
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 64 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2019502 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=144, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=9354240, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 144
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=145, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=9354240
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 65 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2070679 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 66 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2045403 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=145, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=9418752, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 145
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=146, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=9418752
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 67 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2066075 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 68 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2068419 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=146, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=9483264, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 146
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=147, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=9483264
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 69 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2020074 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 70 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2043883 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=147, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=9547776, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 147
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=148, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=9547776
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 71 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2057376 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 72 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2065699 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=148, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=9612288, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 148
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 73 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2088820 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=149, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=9612288
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 74 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2108474 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=149, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=9676800, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 149
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=150, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=9676800
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 75 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2093626 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=150, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=9741312, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 150
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 76 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2072696 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=151, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=9741312
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 77 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1984907 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=151, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=9805824, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 151
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=152, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=9805824
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 78 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1975555 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 79 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2053882 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=152, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=9870336, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 152
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=153, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=9870336
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 80 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1590895 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 81 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1788668 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=153, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=9934848, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 153
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=154, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=9934848
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 82 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1468631 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 83 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1858026 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=154, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=9999360, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 154
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=155, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=9999360
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 84 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1914853 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=155, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=10063872, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 155
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=156, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10063872
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 85 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1824117 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 86 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1833953 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=156, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=10128384, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 156
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=157, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10128384
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 87 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1608499 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 88 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1437238 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=157, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=10192896, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 157
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=158, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10192896
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 89 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1842119 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 90 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1963686 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=158, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=10257408, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 158
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=159, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10257408
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 91 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1840621 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=159, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=10321920, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 159
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=160, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10321920
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 92 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1919757 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 93 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1977898 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=160, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=10386432, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 160
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=161, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10386432
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 94 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1895768 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 95 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1830058 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=161, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=10450944, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 161
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 96 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1831111 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=162, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10450944
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 97 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1929976 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=162, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=10515456, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 162
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=163, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10515456
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=163, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=10579968, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 163
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=164, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10579968
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 103 offsetInBlock: 6644736 lastPacketInBlock: false lastByteOffsetInBlock: 6709248
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=164, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=10644480, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 164
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 104 offsetInBlock: 6709248 lastPacketInBlock: false lastByteOffsetInBlock: 6773760
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=165, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10644480
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 105 offsetInBlock: 6773760 lastPacketInBlock: false lastByteOffsetInBlock: 6838272
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 106 offsetInBlock: 6838272 lastPacketInBlock: false lastByteOffsetInBlock: 6902784
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=165, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=10708992, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 165
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=166, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10708992
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=166, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=10773504, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 166
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 98 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1941938 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=167, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10773504
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 99 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1889048 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=167, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=10838016, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 167
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=168, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10838016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=168, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=10902528, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 168
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=169, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10902528
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=169, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=10967040, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 169
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=170, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=10967040
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=170, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=11031552, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 170
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=171, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=11031552
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=171, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=11096064, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 171
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=172, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=11096064
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=172, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=11160576, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 172
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=173, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=11160576
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=173, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=11225088, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 173
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=174, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=11225088
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=174, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=11289600, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 174
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=175, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=11289600
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=175, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=11354112, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 175
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=176, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=11354112
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=176, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=11418624, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 176
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=177, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=11418624
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=177, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=11483136, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 177
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=178, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=11483136
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=178, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=11547648, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 178
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=179, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=11547648
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=179, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=11612160, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 179
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=180, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=11612160
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=180, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=11676672, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 180
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=181, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=11676672
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=181, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=11741184, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 100 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1978446 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 101 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1545269 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 181
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=182, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=11741184
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=182, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=11805696, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 182
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=183, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=11805696
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=183, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=11870208, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 107 offsetInBlock: 6902784 lastPacketInBlock: false lastByteOffsetInBlock: 6967296
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 108 offsetInBlock: 6967296 lastPacketInBlock: false lastByteOffsetInBlock: 7031808
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 109 offsetInBlock: 7031808 lastPacketInBlock: false lastByteOffsetInBlock: 7096320
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 110 offsetInBlock: 7096320 lastPacketInBlock: false lastByteOffsetInBlock: 7160832
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 102 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1874656 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 183
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=184, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=11870208
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=184, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=11934720, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 111 offsetInBlock: 7160832 lastPacketInBlock: false lastByteOffsetInBlock: 7225344
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 103 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2140518 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 104 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1956125 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 184
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=185, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=11934720
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 112 offsetInBlock: 7225344 lastPacketInBlock: false lastByteOffsetInBlock: 7289856
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=185, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=11999232, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 185
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=186, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=11999232
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 113 offsetInBlock: 7289856 lastPacketInBlock: false lastByteOffsetInBlock: 7354368
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=186, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=12063744, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 105 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2042364 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 186
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=187, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=12063744
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=187, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=12128256, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 106 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2039022 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 114 offsetInBlock: 7354368 lastPacketInBlock: false lastByteOffsetInBlock: 7418880
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 115 offsetInBlock: 7418880 lastPacketInBlock: false lastByteOffsetInBlock: 7483392
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 187
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=188, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=12128256
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=188, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=12192768, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 107 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2100572 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 108 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1955138 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 188
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=189, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=12192768
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=189, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=12257280, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 189
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=190, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=12257280
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=190, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=12321792, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 116 offsetInBlock: 7483392 lastPacketInBlock: false lastByteOffsetInBlock: 7547904
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 117 offsetInBlock: 7547904 lastPacketInBlock: false lastByteOffsetInBlock: 7612416
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 118 offsetInBlock: 7612416 lastPacketInBlock: false lastByteOffsetInBlock: 7676928
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 109 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1988128 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 190
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=191, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=12321792
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 110 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2051085 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=191, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=12386304, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 191
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=192, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=12386304
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=192, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=12450816, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 111 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2052897 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 192
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=193, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=12450816
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=193, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=12515328, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 112 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1952337 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 193
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=194, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=12515328
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=194, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=12579840, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 119 offsetInBlock: 7676928 lastPacketInBlock: false lastByteOffsetInBlock: 7741440
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 120 offsetInBlock: 7741440 lastPacketInBlock: false lastByteOffsetInBlock: 7805952
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 121 offsetInBlock: 7805952 lastPacketInBlock: false lastByteOffsetInBlock: 7870464
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 113 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2012849 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 194
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=195, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=12579840
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=195, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=12644352, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 114 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2089135 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 195
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=196, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=12644352
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=196, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=12708864, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 122 offsetInBlock: 7870464 lastPacketInBlock: false lastByteOffsetInBlock: 7934976
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 123 offsetInBlock: 7934976 lastPacketInBlock: false lastByteOffsetInBlock: 7999488
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 115 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1855760 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 196
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=197, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=12708864
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=197, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=12773376, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 124 offsetInBlock: 7999488 lastPacketInBlock: false lastByteOffsetInBlock: 8064000
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 116 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1903568 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 125 offsetInBlock: 8064000 lastPacketInBlock: false lastByteOffsetInBlock: 8128512
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 117 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1825758 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 126 offsetInBlock: 8128512 lastPacketInBlock: false lastByteOffsetInBlock: 8193024
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 197
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=198, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=12773376
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=198, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=12837888, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 127 offsetInBlock: 8193024 lastPacketInBlock: false lastByteOffsetInBlock: 8257536
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 128 offsetInBlock: 8257536 lastPacketInBlock: false lastByteOffsetInBlock: 8322048
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 129 offsetInBlock: 8322048 lastPacketInBlock: false lastByteOffsetInBlock: 8386560
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 130 offsetInBlock: 8386560 lastPacketInBlock: false lastByteOffsetInBlock: 8451072
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 131 offsetInBlock: 8451072 lastPacketInBlock: false lastByteOffsetInBlock: 8515584
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 198
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=199, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=12837888
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=199, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=12902400, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 132 offsetInBlock: 8515584 lastPacketInBlock: false lastByteOffsetInBlock: 8580096
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 133 offsetInBlock: 8580096 lastPacketInBlock: false lastByteOffsetInBlock: 8644608
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 134 offsetInBlock: 8644608 lastPacketInBlock: false lastByteOffsetInBlock: 8709120
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 118 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1865233 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 199
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=200, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=12902400
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 119 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1930911 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=200, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=12966912, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 120 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1861691 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 200
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=201, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=12966912
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 121 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1889158 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=201, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=13031424, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 201
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=202, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=13031424
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 122 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1487579 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=202, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=13095936, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 202
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=203, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=13095936
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 123 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1914031 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=203, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=13160448, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 203
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 124 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1999971 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=204, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=13160448
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 125 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1841230 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=204, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=13224960, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 204
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=205, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=13224960
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=205, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=13289472, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 126 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1954084 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 205
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=206, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=13289472
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=206, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=13353984, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 206
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=207, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=13353984
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 127 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1987522 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=207, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=13418496, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 207
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=208, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=13418496
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=208, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=13483008, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 208
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=209, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=13483008
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=209, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=13547520, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 135 offsetInBlock: 8709120 lastPacketInBlock: false lastByteOffsetInBlock: 8773632
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 128 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1958404 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 136 offsetInBlock: 8773632 lastPacketInBlock: false lastByteOffsetInBlock: 8838144
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 137 offsetInBlock: 8838144 lastPacketInBlock: false lastByteOffsetInBlock: 8902656
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 209
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=210, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=13547520
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=210, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=13612032, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 129 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1908912 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 210
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=211, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=13612032
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=211, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=13676544, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 130 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1854116 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 211
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=212, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=13676544
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=212, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=13741056, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 138 offsetInBlock: 8902656 lastPacketInBlock: false lastByteOffsetInBlock: 8967168
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 131 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1921722 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 139 offsetInBlock: 8967168 lastPacketInBlock: false lastByteOffsetInBlock: 9031680
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 212
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=213, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=13741056
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=213, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=13805568, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 132 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1960616 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 213
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=214, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=13805568
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 133 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1954634 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=214, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=13870080, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 214
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=215, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=13870080
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=215, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=13934592, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 140 offsetInBlock: 9031680 lastPacketInBlock: false lastByteOffsetInBlock: 9096192
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 141 offsetInBlock: 9096192 lastPacketInBlock: false lastByteOffsetInBlock: 9160704
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 142 offsetInBlock: 9160704 lastPacketInBlock: false lastByteOffsetInBlock: 9225216
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 134 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1913254 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 215
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=216, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=13934592
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 135 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1824664 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=216, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=13999104, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 216
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=217, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=13999104
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=217, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=14063616, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 143 offsetInBlock: 9225216 lastPacketInBlock: false lastByteOffsetInBlock: 9289728
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 136 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1936832 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 144 offsetInBlock: 9289728 lastPacketInBlock: false lastByteOffsetInBlock: 9354240
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 217
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=218, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=14063616
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=218, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=14128128, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 137 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1914185 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 218
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=219, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=14128128
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=219, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=14192640, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 145 offsetInBlock: 9354240 lastPacketInBlock: false lastByteOffsetInBlock: 9418752
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 138 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1924893 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 146 offsetInBlock: 9418752 lastPacketInBlock: false lastByteOffsetInBlock: 9483264
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 219
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=220, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=14192640
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=220, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=14257152, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 139 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1933708 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 220
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=221, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=14257152
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=221, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=14321664, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 140 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1914816 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 221
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=222, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=14321664
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 147 offsetInBlock: 9483264 lastPacketInBlock: false lastByteOffsetInBlock: 9547776
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=222, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=14386176, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 148 offsetInBlock: 9547776 lastPacketInBlock: false lastByteOffsetInBlock: 9612288
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 149 offsetInBlock: 9612288 lastPacketInBlock: false lastByteOffsetInBlock: 9676800
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 141 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1901029 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 222
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=223, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=14386176
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=223, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=14450688, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 142 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1930116 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 223
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=224, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=14450688
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=224, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=14515200, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 150 offsetInBlock: 9676800 lastPacketInBlock: false lastByteOffsetInBlock: 9741312
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 143 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1931644 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 151 offsetInBlock: 9741312 lastPacketInBlock: false lastByteOffsetInBlock: 9805824
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 144 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1880884 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 152 offsetInBlock: 9805824 lastPacketInBlock: false lastByteOffsetInBlock: 9870336
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 224
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=225, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=14515200
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=225, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=14579712, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 225
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=226, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=14579712
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=226, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=14644224, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 145 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1893833 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 226
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=227, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=14644224
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=227, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=14708736, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 146 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1897094 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 153 offsetInBlock: 9870336 lastPacketInBlock: false lastByteOffsetInBlock: 9934848
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 154 offsetInBlock: 9934848 lastPacketInBlock: false lastByteOffsetInBlock: 9999360
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 155 offsetInBlock: 9999360 lastPacketInBlock: false lastByteOffsetInBlock: 10063872
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 227
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=228, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=14708736
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=228, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=14773248, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 147 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1918111 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 228
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=229, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=14773248
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=229, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=14837760, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 148 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1966077 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 229
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=230, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=14837760
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=230, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=14902272, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 156 offsetInBlock: 10063872 lastPacketInBlock: false lastByteOffsetInBlock: 10128384
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 157 offsetInBlock: 10128384 lastPacketInBlock: false lastByteOffsetInBlock: 10192896
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 149 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1883901 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 230
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=231, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=14902272
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=231, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=14966784, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 150 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1905957 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 231
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=232, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=14966784
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=232, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=15031296, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 158 offsetInBlock: 10192896 lastPacketInBlock: false lastByteOffsetInBlock: 10257408
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 159 offsetInBlock: 10257408 lastPacketInBlock: false lastByteOffsetInBlock: 10321920
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 151 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1912531 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 152 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1898084 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 160 offsetInBlock: 10321920 lastPacketInBlock: false lastByteOffsetInBlock: 10386432
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 153 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1826529 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 161 offsetInBlock: 10386432 lastPacketInBlock: false lastByteOffsetInBlock: 10450944
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 154 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1961945 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 162 offsetInBlock: 10450944 lastPacketInBlock: false lastByteOffsetInBlock: 10515456
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 155 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1981215 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 163 offsetInBlock: 10515456 lastPacketInBlock: false lastByteOffsetInBlock: 10579968
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 164 offsetInBlock: 10579968 lastPacketInBlock: false lastByteOffsetInBlock: 10644480
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 156 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1956856 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 157 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1923932 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 165 offsetInBlock: 10644480 lastPacketInBlock: false lastByteOffsetInBlock: 10708992
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 158 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1900092 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 166 offsetInBlock: 10708992 lastPacketInBlock: false lastByteOffsetInBlock: 10773504
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 232
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=233, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=15031296
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=233, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=15095808, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 233
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=234, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=15095808
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=234, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=15160320, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 234
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=235, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=15160320
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=235, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=15224832, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 235
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=236, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=15224832
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=236, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=15289344, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 236
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=237, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=15289344
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 159 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1898175 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=237, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=15353856, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 237
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=238, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=15353856
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=238, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=15418368, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 238
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=239, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=15418368
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=239, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=15482880, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 239
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=240, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=15482880
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=240, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=15547392, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 240
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=241, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=15547392
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=241, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=15611904, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 167 offsetInBlock: 10773504 lastPacketInBlock: false lastByteOffsetInBlock: 10838016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 168 offsetInBlock: 10838016 lastPacketInBlock: false lastByteOffsetInBlock: 10902528
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 160 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1922966 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 241
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=242, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=15611904
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=242, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=15676416, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 161 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1929276 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 242
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=243, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=15676416
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=243, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=15740928, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 169 offsetInBlock: 10902528 lastPacketInBlock: false lastByteOffsetInBlock: 10967040
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 162 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1971114 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 170 offsetInBlock: 10967040 lastPacketInBlock: false lastByteOffsetInBlock: 11031552
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 171 offsetInBlock: 11031552 lastPacketInBlock: false lastByteOffsetInBlock: 11096064
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 243
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=244, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=15740928
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=244, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=15805440, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 163 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1933736 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 244
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=245, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=15805440
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=245, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=15869952, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 164 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1950406 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 245
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=246, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=15869952
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 172 offsetInBlock: 11096064 lastPacketInBlock: false lastByteOffsetInBlock: 11160576
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 165 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1906254 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 173 offsetInBlock: 11160576 lastPacketInBlock: false lastByteOffsetInBlock: 11225088
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=246, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=15934464, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 246
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=247, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=15934464
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=247, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=15998976, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 166 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1929876 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 247
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=248, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=15998976
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=248, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=16063488, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 174 offsetInBlock: 11225088 lastPacketInBlock: false lastByteOffsetInBlock: 11289600
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 167 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1949570 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 175 offsetInBlock: 11289600 lastPacketInBlock: false lastByteOffsetInBlock: 11354112
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 176 offsetInBlock: 11354112 lastPacketInBlock: false lastByteOffsetInBlock: 11418624
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 248
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=249, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=16063488
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=249, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=16128000, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 168 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1927811 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 249
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=250, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=16128000
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=250, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=16192512, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 169 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1867312 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 250
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=251, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=16192512
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=251, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=16257024, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 177 offsetInBlock: 11418624 lastPacketInBlock: false lastByteOffsetInBlock: 11483136
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 170 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1912629 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 178 offsetInBlock: 11483136 lastPacketInBlock: false lastByteOffsetInBlock: 11547648
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 251
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 179 offsetInBlock: 11547648 lastPacketInBlock: false lastByteOffsetInBlock: 11612160
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=252, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=16257024
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 180 offsetInBlock: 11612160 lastPacketInBlock: false lastByteOffsetInBlock: 11676672
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=252, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=16321536, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 171 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1899996 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 252
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=253, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=16321536
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=253, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=16386048, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 172 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1892216 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 253
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=254, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=16386048
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=254, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=16450560, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 181 offsetInBlock: 11676672 lastPacketInBlock: false lastByteOffsetInBlock: 11741184
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 173 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2012494 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 182 offsetInBlock: 11741184 lastPacketInBlock: false lastByteOffsetInBlock: 11805696
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 254
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=255, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=16450560
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=255, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=16515072, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 174 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1879085 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 255
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=256, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=16515072
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=256, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=16579584, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 175 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2007513 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 256
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=257, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=16579584
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=257, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=16644096, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 183 offsetInBlock: 11805696 lastPacketInBlock: false lastByteOffsetInBlock: 11870208
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 176 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1980081 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 184 offsetInBlock: 11870208 lastPacketInBlock: false lastByteOffsetInBlock: 11934720
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 185 offsetInBlock: 11934720 lastPacketInBlock: false lastByteOffsetInBlock: 11999232
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 257
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=258, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=16644096
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=258, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=16708608, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 177 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1944457 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 258
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=259, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=16708608
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=259, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=16773120, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 178 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1969832 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 259
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=260, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=16773120
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=260, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=16837632, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 186 offsetInBlock: 11999232 lastPacketInBlock: false lastByteOffsetInBlock: 12063744
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 179 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1967707 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 187 offsetInBlock: 12063744 lastPacketInBlock: false lastByteOffsetInBlock: 12128256
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 260
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 188 offsetInBlock: 12128256 lastPacketInBlock: false lastByteOffsetInBlock: 12192768
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=261, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=16837632
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=261, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=16902144, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 180 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1985031 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 261
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=262, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=16902144
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=262, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=16966656, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 181 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1998023 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 262
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=263, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=16966656
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=263, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=17031168, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 189 offsetInBlock: 12192768 lastPacketInBlock: false lastByteOffsetInBlock: 12257280
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 190 offsetInBlock: 12257280 lastPacketInBlock: false lastByteOffsetInBlock: 12321792
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 182 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1903368 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 263
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=264, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=17031168
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=264, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=17095680, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 183 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1926045 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 264
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=265, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=17095680
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=265, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=17160192, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 191 offsetInBlock: 12321792 lastPacketInBlock: false lastByteOffsetInBlock: 12386304
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 184 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1928671 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 192 offsetInBlock: 12386304 lastPacketInBlock: false lastByteOffsetInBlock: 12450816
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 265
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=266, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=17160192
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=266, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=17224704, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 185 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1906489 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 266
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=267, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=17224704
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=267, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=17289216, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 193 offsetInBlock: 12450816 lastPacketInBlock: false lastByteOffsetInBlock: 12515328
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 194 offsetInBlock: 12515328 lastPacketInBlock: false lastByteOffsetInBlock: 12579840
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 195 offsetInBlock: 12579840 lastPacketInBlock: false lastByteOffsetInBlock: 12644352
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 186 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1956100 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 187 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1873615 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 267
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=268, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=17289216
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=268, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=17353728, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 268
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=269, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=17353728
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=269, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=17418240, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 188 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1928091 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 269
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=270, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=17418240
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=270, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=17482752, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 196 offsetInBlock: 12644352 lastPacketInBlock: false lastByteOffsetInBlock: 12708864
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 189 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1878406 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 270
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=271, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=17482752
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 197 offsetInBlock: 12708864 lastPacketInBlock: false lastByteOffsetInBlock: 12773376
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=271, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=17547264, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 190 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1838574 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 271
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=272, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=17547264
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=272, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=17611776, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 198 offsetInBlock: 12773376 lastPacketInBlock: false lastByteOffsetInBlock: 12837888
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 191 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1848069 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 199 offsetInBlock: 12837888 lastPacketInBlock: false lastByteOffsetInBlock: 12902400
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 272
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=273, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=17611776
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=273, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=17676288, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 192 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1852489 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 273
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=274, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=17676288
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=274, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=17740800, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 200 offsetInBlock: 12902400 lastPacketInBlock: false lastByteOffsetInBlock: 12966912
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 193 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1953196 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 201 offsetInBlock: 12966912 lastPacketInBlock: false lastByteOffsetInBlock: 13031424
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 274
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=275, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=17740800
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=275, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=17805312, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 194 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1824880 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 275
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=276, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=17805312
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=276, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=17869824, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 202 offsetInBlock: 13031424 lastPacketInBlock: false lastByteOffsetInBlock: 13095936
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 195 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1833992 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 276
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=277, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=17869824
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 203 offsetInBlock: 13095936 lastPacketInBlock: false lastByteOffsetInBlock: 13160448
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=277, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=17934336, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 196 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1913642 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 277
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=278, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=17934336
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=278, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=17998848, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 204 offsetInBlock: 13160448 lastPacketInBlock: false lastByteOffsetInBlock: 13224960
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 197 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1881473 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 205 offsetInBlock: 13224960 lastPacketInBlock: false lastByteOffsetInBlock: 13289472
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 278
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=279, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=17998848
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=279, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=18063360, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 198 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1938071 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 279
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=280, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=18063360
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=280, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=18127872, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 206 offsetInBlock: 13289472 lastPacketInBlock: false lastByteOffsetInBlock: 13353984
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 207 offsetInBlock: 13353984 lastPacketInBlock: false lastByteOffsetInBlock: 13418496
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 199 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1959273 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 208 offsetInBlock: 13418496 lastPacketInBlock: false lastByteOffsetInBlock: 13483008
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 280
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=281, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=18127872
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=281, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=18192384, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 200 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1965930 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 281
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=282, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=18192384
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=282, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=18256896, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 201 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1846772 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 282
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=283, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=18256896
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=283, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=18321408, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 209 offsetInBlock: 13483008 lastPacketInBlock: false lastByteOffsetInBlock: 13547520
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 202 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1957138 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 283
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 210 offsetInBlock: 13547520 lastPacketInBlock: false lastByteOffsetInBlock: 13612032
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=284, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=18321408
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=284, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=18385920, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 203 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1919355 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 284
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=285, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=18385920
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=285, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=18450432, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 211 offsetInBlock: 13612032 lastPacketInBlock: false lastByteOffsetInBlock: 13676544
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 204 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1912232 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 212 offsetInBlock: 13676544 lastPacketInBlock: false lastByteOffsetInBlock: 13741056
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 205 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1946119 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 213 offsetInBlock: 13741056 lastPacketInBlock: false lastByteOffsetInBlock: 13805568
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 206 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1956776 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 214 offsetInBlock: 13805568 lastPacketInBlock: false lastByteOffsetInBlock: 13870080
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 215 offsetInBlock: 13870080 lastPacketInBlock: false lastByteOffsetInBlock: 13934592
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 207 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1907840 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 208 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1882363 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 216 offsetInBlock: 13934592 lastPacketInBlock: false lastByteOffsetInBlock: 13999104
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 217 offsetInBlock: 13999104 lastPacketInBlock: false lastByteOffsetInBlock: 14063616
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 209 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1965079 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 285
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=286, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=18450432
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=286, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=18514944, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 286
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=287, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=18514944
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=287, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=18579456, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 287
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=288, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=18579456
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 210 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1934078 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=288, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=18643968, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 288
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=289, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=18643968
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=289, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=18708480, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 289
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=290, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=18708480
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=290, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=18772992, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 290
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=291, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=18772992
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=291, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=18837504, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 291
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=292, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=18837504
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=292, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=18902016, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 211 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1963407 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 292
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 212 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1824082 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=293, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=18902016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=293, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=18966528, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 293
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 213 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1903292 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=294, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=18966528
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 214 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1915236 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=294, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=19031040, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 294
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=295, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=19031040
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 215 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2012331 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=295, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=19095552, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 295
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 216 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1534972 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=296, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=19095552
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 218 offsetInBlock: 14063616 lastPacketInBlock: false lastByteOffsetInBlock: 14128128
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=296, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=19160064, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 296
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=297, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=19160064
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=297, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=19224576, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 297
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 219 offsetInBlock: 14128128 lastPacketInBlock: false lastByteOffsetInBlock: 14192640
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=298, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=19224576
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 220 offsetInBlock: 14192640 lastPacketInBlock: false lastByteOffsetInBlock: 14257152
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=298, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=19289088, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 221 offsetInBlock: 14257152 lastPacketInBlock: false lastByteOffsetInBlock: 14321664
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 222 offsetInBlock: 14321664 lastPacketInBlock: false lastByteOffsetInBlock: 14386176
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 223 offsetInBlock: 14386176 lastPacketInBlock: false lastByteOffsetInBlock: 14450688
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 224 offsetInBlock: 14450688 lastPacketInBlock: false lastByteOffsetInBlock: 14515200
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 217 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1438885 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 298
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=299, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=19289088
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=299, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=19353600, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 225 offsetInBlock: 14515200 lastPacketInBlock: false lastByteOffsetInBlock: 14579712
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 226 offsetInBlock: 14579712 lastPacketInBlock: false lastByteOffsetInBlock: 14644224
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 218 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2148307 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 299
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=300, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=19353600
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=300, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=19418112, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 227 offsetInBlock: 14644224 lastPacketInBlock: false lastByteOffsetInBlock: 14708736
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 219 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1942037 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 228 offsetInBlock: 14708736 lastPacketInBlock: false lastByteOffsetInBlock: 14773248
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 300
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=301, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=19418112
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=301, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=19482624, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 220 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1968084 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 301
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=302, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=19482624
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=302, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=19547136, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 229 offsetInBlock: 14773248 lastPacketInBlock: false lastByteOffsetInBlock: 14837760
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 221 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1880973 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 302
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 230 offsetInBlock: 14837760 lastPacketInBlock: false lastByteOffsetInBlock: 14902272
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=303, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=19547136
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=303, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=19611648, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 222 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1951614 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 303
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=304, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=19611648
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=304, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=19676160, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 223 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1913729 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 304
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=305, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=19676160
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=305, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=19740672, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 231 offsetInBlock: 14902272 lastPacketInBlock: false lastByteOffsetInBlock: 14966784
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 232 offsetInBlock: 14966784 lastPacketInBlock: false lastByteOffsetInBlock: 15031296
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 224 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1921228 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 305
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=306, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=19740672
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=306, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=19805184, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 225 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1973991 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 233 offsetInBlock: 15031296 lastPacketInBlock: false lastByteOffsetInBlock: 15095808
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 306
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=307, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=19805184
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 234 offsetInBlock: 15095808 lastPacketInBlock: false lastByteOffsetInBlock: 15160320
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=307, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=19869696, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 226 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1930501 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 307
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=308, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=19869696
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=308, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=19934208, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 227 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1906215 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 308
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=309, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=19934208
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=309, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=19998720, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 235 offsetInBlock: 15160320 lastPacketInBlock: false lastByteOffsetInBlock: 15224832
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 236 offsetInBlock: 15224832 lastPacketInBlock: false lastByteOffsetInBlock: 15289344
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 228 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1957777 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 309
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=310, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=19998720
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=310, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=20063232, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 229 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1877548 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 310
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=311, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=20063232
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=311, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=20127744, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 237 offsetInBlock: 15289344 lastPacketInBlock: false lastByteOffsetInBlock: 15353856
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 238 offsetInBlock: 15353856 lastPacketInBlock: false lastByteOffsetInBlock: 15418368
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 230 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1931379 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 311
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=312, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=20127744
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=312, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=20192256, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 239 offsetInBlock: 15418368 lastPacketInBlock: false lastByteOffsetInBlock: 15482880
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 231 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1943042 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 240 offsetInBlock: 15482880 lastPacketInBlock: false lastByteOffsetInBlock: 15547392
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 312
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=313, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=20192256
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=313, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=20256768, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 232 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1948567 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 313
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=314, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=20256768
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=314, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=20321280, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 233 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1945379 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 241 offsetInBlock: 15547392 lastPacketInBlock: false lastByteOffsetInBlock: 15611904
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 242 offsetInBlock: 15611904 lastPacketInBlock: false lastByteOffsetInBlock: 15676416
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 314
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=315, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=20321280
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=315, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=20385792, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 234 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1869383 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 315
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=316, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=20385792
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=316, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=20450304, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 235 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1963282 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 243 offsetInBlock: 15676416 lastPacketInBlock: false lastByteOffsetInBlock: 15740928
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 244 offsetInBlock: 15740928 lastPacketInBlock: false lastByteOffsetInBlock: 15805440
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 316
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=317, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=20450304
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 236 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1884548 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=317, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=20514816, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 317
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=318, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=20514816
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=318, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=20579328, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 237 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1901747 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 245 offsetInBlock: 15805440 lastPacketInBlock: false lastByteOffsetInBlock: 15869952
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 246 offsetInBlock: 15869952 lastPacketInBlock: false lastByteOffsetInBlock: 15934464
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 238 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1887188 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 239 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1956729 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 247 offsetInBlock: 15934464 lastPacketInBlock: false lastByteOffsetInBlock: 15998976
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 248 offsetInBlock: 15998976 lastPacketInBlock: false lastByteOffsetInBlock: 16063488
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 240 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1885610 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 318
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=319, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=20579328
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=319, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=20643840, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 319
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=320, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=20643840
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=320, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=20708352, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 320
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=321, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=20708352
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=321, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=20772864, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 321
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=322, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=20772864
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=322, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=20837376, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 241 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2014865 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 322
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 242 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1835793 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=323, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=20837376
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 249 offsetInBlock: 16063488 lastPacketInBlock: false lastByteOffsetInBlock: 16128000
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=323, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=20901888, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 323
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=324, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=20901888
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 250 offsetInBlock: 16128000 lastPacketInBlock: false lastByteOffsetInBlock: 16192512
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=324, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=20966400, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 243 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1915500 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 324
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=325, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=20966400
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=325, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=21030912, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 244 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1906456 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 251 offsetInBlock: 16192512 lastPacketInBlock: false lastByteOffsetInBlock: 16257024
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 325
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=326, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=21030912
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 252 offsetInBlock: 16257024 lastPacketInBlock: false lastByteOffsetInBlock: 16321536
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=326, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=21095424, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 245 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1926422 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 326
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=327, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=21095424
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=327, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=21159936, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 253 offsetInBlock: 16321536 lastPacketInBlock: false lastByteOffsetInBlock: 16386048
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 246 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1932412 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 327
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 254 offsetInBlock: 16386048 lastPacketInBlock: false lastByteOffsetInBlock: 16450560
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=328, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=21159936
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 255 offsetInBlock: 16450560 lastPacketInBlock: false lastByteOffsetInBlock: 16515072
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=328, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=21224448, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 247 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1880926 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 328
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=329, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=21224448
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=329, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=21288960, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 248 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1905039 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 329
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=330, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=21288960
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=330, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=21353472, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 256 offsetInBlock: 16515072 lastPacketInBlock: false lastByteOffsetInBlock: 16579584
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 249 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1916081 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 330
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=331, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=21353472
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 257 offsetInBlock: 16579584 lastPacketInBlock: false lastByteOffsetInBlock: 16644096
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=331, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=21417984, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 250 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1988862 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 331
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=332, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=21417984
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=332, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=21482496, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 251 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1941533 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 258 offsetInBlock: 16644096 lastPacketInBlock: false lastByteOffsetInBlock: 16708608
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 332
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=333, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=21482496
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=333, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=21547008, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 259 offsetInBlock: 16708608 lastPacketInBlock: false lastByteOffsetInBlock: 16773120
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 252 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1947145 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 333
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=334, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=21547008
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=334, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=21611520, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 260 offsetInBlock: 16773120 lastPacketInBlock: false lastByteOffsetInBlock: 16837632
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 253 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1946754 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 261 offsetInBlock: 16837632 lastPacketInBlock: false lastByteOffsetInBlock: 16902144
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 334
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 262 offsetInBlock: 16902144 lastPacketInBlock: false lastByteOffsetInBlock: 16966656
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=335, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=21611520
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=335, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=21676032, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 254 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1878726 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 335
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=336, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=21676032
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=336, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=21740544, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 255 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1888792 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 336
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=337, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=21740544
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=337, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=21805056, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 263 offsetInBlock: 16966656 lastPacketInBlock: false lastByteOffsetInBlock: 17031168
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 256 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1899274 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 337
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=338, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=21805056
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 264 offsetInBlock: 17031168 lastPacketInBlock: false lastByteOffsetInBlock: 17095680
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=338, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=21869568, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 257 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1908957 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 338
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=339, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=21869568
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=339, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=21934080, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 265 offsetInBlock: 17095680 lastPacketInBlock: false lastByteOffsetInBlock: 17160192
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 258 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1971321 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 339
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=340, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=21934080
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=340, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=21998592, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 266 offsetInBlock: 17160192 lastPacketInBlock: false lastByteOffsetInBlock: 17224704
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 267 offsetInBlock: 17224704 lastPacketInBlock: false lastByteOffsetInBlock: 17289216
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 259 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1919307 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 340
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=341, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=21998592
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=341, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=22063104, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 260 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1888164 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 341
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=342, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=22063104
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=342, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=22127616, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 261 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1971617 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 268 offsetInBlock: 17289216 lastPacketInBlock: false lastByteOffsetInBlock: 17353728
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 342
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=343, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=22127616
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 269 offsetInBlock: 17353728 lastPacketInBlock: false lastByteOffsetInBlock: 17418240
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=343, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=22192128, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 270 offsetInBlock: 17418240 lastPacketInBlock: false lastByteOffsetInBlock: 17482752
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 262 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1964818 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 343
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=344, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=22192128
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=344, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=22256640, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 263 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1909952 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 344
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=345, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=22256640
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=345, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=22321152, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 271 offsetInBlock: 17482752 lastPacketInBlock: false lastByteOffsetInBlock: 17547264
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 264 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1896113 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 272 offsetInBlock: 17547264 lastPacketInBlock: false lastByteOffsetInBlock: 17611776
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 345
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=346, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=22321152
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=346, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=22385664, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 265 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1928317 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 346
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=347, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=22385664
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=347, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=22450176, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 273 offsetInBlock: 17611776 lastPacketInBlock: false lastByteOffsetInBlock: 17676288
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 266 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1946691 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 347
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 274 offsetInBlock: 17676288 lastPacketInBlock: false lastByteOffsetInBlock: 17740800
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=348, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=22450176
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=348, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=22514688, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 267 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1926460 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 348
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=349, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=22514688
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=349, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=22579200, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 275 offsetInBlock: 17740800 lastPacketInBlock: false lastByteOffsetInBlock: 17805312
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 268 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1894267 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 349
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 276 offsetInBlock: 17805312 lastPacketInBlock: false lastByteOffsetInBlock: 17869824
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=350, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=22579200
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=350, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=22643712, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 269 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1834686 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 350
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=351, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=22643712
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=351, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=22708224, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 277 offsetInBlock: 17869824 lastPacketInBlock: false lastByteOffsetInBlock: 17934336
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 270 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1851417 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 278 offsetInBlock: 17934336 lastPacketInBlock: false lastByteOffsetInBlock: 17998848
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 351
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=352, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=22708224
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=352, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=22772736, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 271 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1962049 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 272 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1977770 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 273 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1939901 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 352
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=353, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=22772736
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=353, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=22837248, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 353
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=354, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=22837248
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=354, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=22901760, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 354
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=355, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=22901760
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=355, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=22966272, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 279 offsetInBlock: 17998848 lastPacketInBlock: false lastByteOffsetInBlock: 18063360
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 274 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1926131 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 280 offsetInBlock: 18063360 lastPacketInBlock: false lastByteOffsetInBlock: 18127872
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 281 offsetInBlock: 18127872 lastPacketInBlock: false lastByteOffsetInBlock: 18192384
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 282 offsetInBlock: 18192384 lastPacketInBlock: false lastByteOffsetInBlock: 18256896
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 283 offsetInBlock: 18256896 lastPacketInBlock: false lastByteOffsetInBlock: 18321408
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 355
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=356, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=22966272
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=356, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=23030784, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 275 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1900641 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 356
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=357, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=23030784
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=357, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=23095296, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 276 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1866043 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 357
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=358, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=23095296
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=358, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=23159808, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 284 offsetInBlock: 18321408 lastPacketInBlock: false lastByteOffsetInBlock: 18385920
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 285 offsetInBlock: 18385920 lastPacketInBlock: false lastByteOffsetInBlock: 18450432
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 277 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1887081 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 358
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=359, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=23159808
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=359, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=23224320, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 278 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1955559 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 359
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=360, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=23224320
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=360, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=23288832, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 286 offsetInBlock: 18450432 lastPacketInBlock: false lastByteOffsetInBlock: 18514944
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 279 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1955224 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 287 offsetInBlock: 18514944 lastPacketInBlock: false lastByteOffsetInBlock: 18579456
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 360
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=361, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=23288832
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 288 offsetInBlock: 18579456 lastPacketInBlock: false lastByteOffsetInBlock: 18643968
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=361, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=23353344, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 280 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1913025 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 361
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=362, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=23353344
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=362, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=23417856, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 281 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1892267 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 362
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=363, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=23417856
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=363, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=23482368, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 289 offsetInBlock: 18643968 lastPacketInBlock: false lastByteOffsetInBlock: 18708480
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 282 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1913382 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 363
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 290 offsetInBlock: 18708480 lastPacketInBlock: false lastByteOffsetInBlock: 18772992
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=364, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=23482368
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=364, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=23546880, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 291 offsetInBlock: 18772992 lastPacketInBlock: false lastByteOffsetInBlock: 18837504
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 292 offsetInBlock: 18837504 lastPacketInBlock: false lastByteOffsetInBlock: 18902016
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 283 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1852054 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 364
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=365, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=23546880
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=365, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=23611392, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 284 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1940657 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 365
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=366, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=23611392
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=366, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=23675904, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 285 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1873778 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 293 offsetInBlock: 18902016 lastPacketInBlock: false lastByteOffsetInBlock: 18966528
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 366
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=367, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=23675904
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=367, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=23740416, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 286 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1830901 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 367
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=368, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=23740416
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=368, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=23804928, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 294 offsetInBlock: 18966528 lastPacketInBlock: false lastByteOffsetInBlock: 19031040
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 287 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2034786 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 295 offsetInBlock: 19031040 lastPacketInBlock: false lastByteOffsetInBlock: 19095552
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 368
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=369, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=23804928
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 296 offsetInBlock: 19095552 lastPacketInBlock: false lastByteOffsetInBlock: 19160064
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=369, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=23869440, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 288 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1909759 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 369
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=370, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=23869440
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=370, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=23933952, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 289 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1891489 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 370
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=371, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=23933952
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=371, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=23998464, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 290 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1888418 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 297 offsetInBlock: 19160064 lastPacketInBlock: false lastByteOffsetInBlock: 19224576
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 371
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=372, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=23998464
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 298 offsetInBlock: 19224576 lastPacketInBlock: false lastByteOffsetInBlock: 19289088
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=372, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=24062976, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 291 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1877093 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 372
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=373, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=24062976
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=373, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=24127488, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 299 offsetInBlock: 19289088 lastPacketInBlock: false lastByteOffsetInBlock: 19353600
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 292 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1954230 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 300 offsetInBlock: 19353600 lastPacketInBlock: false lastByteOffsetInBlock: 19418112
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 373
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=374, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=24127488
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 301 offsetInBlock: 19418112 lastPacketInBlock: false lastByteOffsetInBlock: 19482624
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=374, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=24192000, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 293 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1934831 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 374
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=375, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=24192000
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=375, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=24256512, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 294 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1930348 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 375
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=376, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=24256512
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=376, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=24321024, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 302 offsetInBlock: 19482624 lastPacketInBlock: false lastByteOffsetInBlock: 19547136
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 295 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1947840 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 376
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=377, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=24321024
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 303 offsetInBlock: 19547136 lastPacketInBlock: false lastByteOffsetInBlock: 19611648
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=377, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=24385536, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 304 offsetInBlock: 19611648 lastPacketInBlock: false lastByteOffsetInBlock: 19676160
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 296 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1960887 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 377
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=378, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=24385536
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=378, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=24450048, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 297 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1964327 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 378
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=379, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=24450048
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=379, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=24514560, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 305 offsetInBlock: 19676160 lastPacketInBlock: false lastByteOffsetInBlock: 19740672
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 298 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1969703 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 379
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=380, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=24514560
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 306 offsetInBlock: 19740672 lastPacketInBlock: false lastByteOffsetInBlock: 19805184
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=380, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=24579072, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 307 offsetInBlock: 19805184 lastPacketInBlock: false lastByteOffsetInBlock: 19869696
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 299 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1981672 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 380
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=381, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=24579072
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=381, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=24643584, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 300 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1960085 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 381
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=382, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=24643584
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=382, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=24708096, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 308 offsetInBlock: 19869696 lastPacketInBlock: false lastByteOffsetInBlock: 19934208
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 301 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1958580 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 309 offsetInBlock: 19934208 lastPacketInBlock: false lastByteOffsetInBlock: 19998720
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 310 offsetInBlock: 19998720 lastPacketInBlock: false lastByteOffsetInBlock: 20063232
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 302 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1914363 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 382
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=383, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=24708096
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=383, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=24772608, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 383
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 303 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1920969 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=384, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=24772608
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=384, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=24837120, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 384
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=385, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=24837120
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=385, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=24901632, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 311 offsetInBlock: 20063232 lastPacketInBlock: false lastByteOffsetInBlock: 20127744
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 304 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1909052 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 312 offsetInBlock: 20127744 lastPacketInBlock: false lastByteOffsetInBlock: 20192256
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 305 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1906089 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 306 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1957104 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 385
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 313 offsetInBlock: 20192256 lastPacketInBlock: false lastByteOffsetInBlock: 20256768
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=386, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=24901632
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 314 offsetInBlock: 20256768 lastPacketInBlock: false lastByteOffsetInBlock: 20321280
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=386, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=24966144, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 386
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=387, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=24966144
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=387, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=25030656, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 387
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=388, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=25030656
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=388, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=25095168, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 307 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1831582 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 388
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=389, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=25095168
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=389, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=25159680, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 308 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1938649 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 315 offsetInBlock: 20321280 lastPacketInBlock: false lastByteOffsetInBlock: 20385792
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 389
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=390, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=25159680
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 316 offsetInBlock: 20385792 lastPacketInBlock: false lastByteOffsetInBlock: 20450304
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=390, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=25224192, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 309 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1960147 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 390
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=391, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=25224192
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=391, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=25288704, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 310 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1899024 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 317 offsetInBlock: 20450304 lastPacketInBlock: false lastByteOffsetInBlock: 20514816
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 391
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=392, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=25288704
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 318 offsetInBlock: 20514816 lastPacketInBlock: false lastByteOffsetInBlock: 20579328
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=392, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=25353216, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 311 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1905831 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 392
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=393, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=25353216
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=393, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=25417728, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 319 offsetInBlock: 20579328 lastPacketInBlock: false lastByteOffsetInBlock: 20643840
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 312 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1866362 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 393
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 320 offsetInBlock: 20643840 lastPacketInBlock: false lastByteOffsetInBlock: 20708352
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=394, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=25417728
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=394, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=25482240, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 313 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1881997 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 394
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=395, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=25482240
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=395, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=25546752, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 314 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1919280 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 321 offsetInBlock: 20708352 lastPacketInBlock: false lastByteOffsetInBlock: 20772864
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 322 offsetInBlock: 20772864 lastPacketInBlock: false lastByteOffsetInBlock: 20837376
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 395
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=396, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=25546752
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=396, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=25611264, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 315 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1889232 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 396
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=397, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=25611264
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=397, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=25675776, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 323 offsetInBlock: 20837376 lastPacketInBlock: false lastByteOffsetInBlock: 20901888
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 324 offsetInBlock: 20901888 lastPacketInBlock: false lastByteOffsetInBlock: 20966400
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 316 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1893196 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 397
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=398, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=25675776
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=398, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=25740288, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 317 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1895841 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 398
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=399, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=25740288
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=399, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=25804800, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 325 offsetInBlock: 20966400 lastPacketInBlock: false lastByteOffsetInBlock: 21030912
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 326 offsetInBlock: 21030912 lastPacketInBlock: false lastByteOffsetInBlock: 21095424
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 318 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1911109 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 399
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=400, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=25804800
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=400, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=25869312, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 319 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1821727 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 400
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=401, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=25869312
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=401, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=25933824, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 327 offsetInBlock: 21095424 lastPacketInBlock: false lastByteOffsetInBlock: 21159936
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 328 offsetInBlock: 21159936 lastPacketInBlock: false lastByteOffsetInBlock: 21224448
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 320 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1957319 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 401
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=402, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=25933824
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=402, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=25998336, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 321 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1826902 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 402
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=403, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=25998336
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=403, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=26062848, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 329 offsetInBlock: 21224448 lastPacketInBlock: false lastByteOffsetInBlock: 21288960
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 330 offsetInBlock: 21288960 lastPacketInBlock: false lastByteOffsetInBlock: 21353472
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 322 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2014284 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 403
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=404, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=26062848
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=404, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=26127360, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 323 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1932766 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 404
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=405, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=26127360
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=405, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=26191872, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 331 offsetInBlock: 21353472 lastPacketInBlock: false lastByteOffsetInBlock: 21417984
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 332 offsetInBlock: 21417984 lastPacketInBlock: false lastByteOffsetInBlock: 21482496
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 324 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1913563 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 405
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=406, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=26191872
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=406, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=26256384, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 325 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1909079 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 406
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=407, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=26256384
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=407, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=26320896, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 333 offsetInBlock: 21482496 lastPacketInBlock: false lastByteOffsetInBlock: 21547008
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 334 offsetInBlock: 21547008 lastPacketInBlock: false lastByteOffsetInBlock: 21611520
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 326 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1914909 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 407
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=408, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=26320896
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=408, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=26385408, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 327 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1893177 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 408
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=409, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=26385408
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=409, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=26449920, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 335 offsetInBlock: 21611520 lastPacketInBlock: false lastByteOffsetInBlock: 21676032
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 336 offsetInBlock: 21676032 lastPacketInBlock: false lastByteOffsetInBlock: 21740544
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 337 offsetInBlock: 21740544 lastPacketInBlock: false lastByteOffsetInBlock: 21805056
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 328 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1838131 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 409
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=410, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=26449920
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=410, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=26514432, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 329 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1907384 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 410
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=411, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=26514432
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=411, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=26578944, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 330 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1904366 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 411
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=412, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=26578944
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=412, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=26643456, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 338 offsetInBlock: 21805056 lastPacketInBlock: false lastByteOffsetInBlock: 21869568
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 339 offsetInBlock: 21869568 lastPacketInBlock: false lastByteOffsetInBlock: 21934080
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 331 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1813380 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 412
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=413, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=26643456
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=413, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=26707968, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 332 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1884767 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 413
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=414, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=26707968
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=414, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=26772480, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 340 offsetInBlock: 21934080 lastPacketInBlock: false lastByteOffsetInBlock: 21998592
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 333 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1901165 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 341 offsetInBlock: 21998592 lastPacketInBlock: false lastByteOffsetInBlock: 22063104
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 334 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1952187 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 342 offsetInBlock: 22063104 lastPacketInBlock: false lastByteOffsetInBlock: 22127616
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 343 offsetInBlock: 22127616 lastPacketInBlock: false lastByteOffsetInBlock: 22192128
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 335 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1896486 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 414
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=415, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=26772480
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=415, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=26836992, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 415
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=416, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=26836992
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=416, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=26901504, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 416
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=417, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=26901504
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=417, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=26966016, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 336 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1909966 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 417
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=418, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=26966016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=418, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=27030528, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 344 offsetInBlock: 22192128 lastPacketInBlock: false lastByteOffsetInBlock: 22256640
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 337 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1884057 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 418
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 345 offsetInBlock: 22256640 lastPacketInBlock: false lastByteOffsetInBlock: 22321152
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=419, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=27030528
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=419, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=27095040, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 338 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1912899 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 419
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=420, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=27095040
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=420, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=27159552, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 339 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1910821 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 346 offsetInBlock: 22321152 lastPacketInBlock: false lastByteOffsetInBlock: 22385664
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 347 offsetInBlock: 22385664 lastPacketInBlock: false lastByteOffsetInBlock: 22450176
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 420
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=421, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=27159552
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=421, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=27224064, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 340 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1883229 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 421
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=422, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=27224064
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=422, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=27288576, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 348 offsetInBlock: 22450176 lastPacketInBlock: false lastByteOffsetInBlock: 22514688
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 349 offsetInBlock: 22514688 lastPacketInBlock: false lastByteOffsetInBlock: 22579200
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 341 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1896167 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 342 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1901964 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 422
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=423, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=27288576
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=423, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=27353088, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 423
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=424, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=27353088
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=424, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=27417600, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 350 offsetInBlock: 22579200 lastPacketInBlock: false lastByteOffsetInBlock: 22643712
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 351 offsetInBlock: 22643712 lastPacketInBlock: false lastByteOffsetInBlock: 22708224
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 343 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1983178 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 424
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=425, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=27417600
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=425, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=27482112, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 344 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1820344 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 425
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=426, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=27482112
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=426, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=27546624, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 352 offsetInBlock: 22708224 lastPacketInBlock: false lastByteOffsetInBlock: 22772736
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 353 offsetInBlock: 22772736 lastPacketInBlock: false lastByteOffsetInBlock: 22837248
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 345 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1958477 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 426
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=427, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=27546624
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=427, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=27611136, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 346 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1924364 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 427
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=428, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=27611136
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=428, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=27675648, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 354 offsetInBlock: 22837248 lastPacketInBlock: false lastByteOffsetInBlock: 22901760
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 355 offsetInBlock: 22901760 lastPacketInBlock: false lastByteOffsetInBlock: 22966272
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 347 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1897909 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 428
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=429, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=27675648
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=429, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=27740160, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 348 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1904356 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 429
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=430, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=27740160
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=430, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=27804672, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 356 offsetInBlock: 22966272 lastPacketInBlock: false lastByteOffsetInBlock: 23030784
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 357 offsetInBlock: 23030784 lastPacketInBlock: false lastByteOffsetInBlock: 23095296
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 349 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1919734 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 430
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=431, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=27804672
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=431, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=27869184, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 350 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1920205 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 431
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=432, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=27869184
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=432, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=27933696, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 358 offsetInBlock: 23095296 lastPacketInBlock: false lastByteOffsetInBlock: 23159808
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 359 offsetInBlock: 23159808 lastPacketInBlock: false lastByteOffsetInBlock: 23224320
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 351 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1890987 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 432
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=433, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=27933696
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=433, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=27998208, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 352 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1887445 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 433
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=434, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=27998208
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=434, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=28062720, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 360 offsetInBlock: 23224320 lastPacketInBlock: false lastByteOffsetInBlock: 23288832
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 361 offsetInBlock: 23288832 lastPacketInBlock: false lastByteOffsetInBlock: 23353344
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 353 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1898750 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 434
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=435, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=28062720
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=435, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=28127232, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 354 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1962159 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 362 offsetInBlock: 23353344 lastPacketInBlock: false lastByteOffsetInBlock: 23417856
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 435
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=436, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=28127232
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 363 offsetInBlock: 23417856 lastPacketInBlock: false lastByteOffsetInBlock: 23482368
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=436, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=28191744, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 355 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1960829 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 436
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=437, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=28191744
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=437, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=28256256, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 356 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2011330 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 437
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=438, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=28256256
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=438, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=28320768, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 357 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1822574 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 364 offsetInBlock: 23482368 lastPacketInBlock: false lastByteOffsetInBlock: 23546880
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 438
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=439, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=28320768
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 365 offsetInBlock: 23546880 lastPacketInBlock: false lastByteOffsetInBlock: 23611392
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=439, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=28385280, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 358 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1868304 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 439
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=440, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=28385280
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=440, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=28449792, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 366 offsetInBlock: 23611392 lastPacketInBlock: false lastByteOffsetInBlock: 23675904
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 359 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1931047 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 440
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 367 offsetInBlock: 23675904 lastPacketInBlock: false lastByteOffsetInBlock: 23740416
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=441, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=28449792
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=441, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=28514304, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 360 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1885920 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 441
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=442, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=28514304
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=442, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=28578816, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 361 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1891704 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 368 offsetInBlock: 23740416 lastPacketInBlock: false lastByteOffsetInBlock: 23804928
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 442
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=443, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=28578816
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 369 offsetInBlock: 23804928 lastPacketInBlock: false lastByteOffsetInBlock: 23869440
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=443, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=28643328, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 362 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1902810 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 443
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=444, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=28643328
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=444, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=28707840, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 370 offsetInBlock: 23869440 lastPacketInBlock: false lastByteOffsetInBlock: 23933952
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 363 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1938630 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 371 offsetInBlock: 23933952 lastPacketInBlock: false lastByteOffsetInBlock: 23998464
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 372 offsetInBlock: 23998464 lastPacketInBlock: false lastByteOffsetInBlock: 24062976
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 444
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=445, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=28707840
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=445, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=28772352, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 364 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1945480 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 445
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=446, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=28772352
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=446, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=28836864, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 365 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1947863 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 446
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=447, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=28836864
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=447, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=28901376, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 373 offsetInBlock: 24062976 lastPacketInBlock: false lastByteOffsetInBlock: 24127488
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 366 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1962275 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 447
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=448, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=28901376
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 374 offsetInBlock: 24127488 lastPacketInBlock: false lastByteOffsetInBlock: 24192000
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=448, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=28965888, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 375 offsetInBlock: 24192000 lastPacketInBlock: false lastByteOffsetInBlock: 24256512
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 367 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1915635 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 448
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=449, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=28965888
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=449, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=29030400, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 368 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1987494 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 449
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=450, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=29030400
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=450, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=29094912, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 376 offsetInBlock: 24256512 lastPacketInBlock: false lastByteOffsetInBlock: 24321024
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 369 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1964111 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 450
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 377 offsetInBlock: 24321024 lastPacketInBlock: false lastByteOffsetInBlock: 24385536
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=451, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=29094912
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 378 offsetInBlock: 24385536 lastPacketInBlock: false lastByteOffsetInBlock: 24450048
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=451, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=29159424, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 370 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1916604 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 451
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=452, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=29159424
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=452, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=29223936, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 371 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1976503 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 452
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=453, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=29223936
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=453, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=29288448, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 379 offsetInBlock: 24450048 lastPacketInBlock: false lastByteOffsetInBlock: 24514560
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 372 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1952273 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 380 offsetInBlock: 24514560 lastPacketInBlock: false lastByteOffsetInBlock: 24579072
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 453
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=454, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=29288448
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 381 offsetInBlock: 24579072 lastPacketInBlock: false lastByteOffsetInBlock: 24643584
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=454, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=29352960, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 373 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1893460 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 454
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=455, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=29352960
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=455, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=29417472, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 374 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1898235 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 455
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=456, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=29417472
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=456, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=29481984, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 375 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1962016 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 382 offsetInBlock: 24643584 lastPacketInBlock: false lastByteOffsetInBlock: 24708096
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 456
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=457, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=29481984
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=457, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=29546496, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 376 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1965191 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 457
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=458, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=29546496
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=458, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=29611008, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 383 offsetInBlock: 24708096 lastPacketInBlock: false lastByteOffsetInBlock: 24772608
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 384 offsetInBlock: 24772608 lastPacketInBlock: false lastByteOffsetInBlock: 24837120
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 377 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1990895 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 385 offsetInBlock: 24837120 lastPacketInBlock: false lastByteOffsetInBlock: 24901632
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 458
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 386 offsetInBlock: 24901632 lastPacketInBlock: false lastByteOffsetInBlock: 24966144
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=459, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=29611008
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=459, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=29675520, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 378 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1954205 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 459
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=460, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=29675520
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=460, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=29740032, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 379 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1956532 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 460
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=461, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=29740032
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=461, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=29804544, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 380 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2007800 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 461
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=462, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=29804544
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=462, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=29869056, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 387 offsetInBlock: 24966144 lastPacketInBlock: false lastByteOffsetInBlock: 25030656
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 388 offsetInBlock: 25030656 lastPacketInBlock: false lastByteOffsetInBlock: 25095168
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 389 offsetInBlock: 25095168 lastPacketInBlock: false lastByteOffsetInBlock: 25159680
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 381 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1829590 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 462
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=463, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=29869056
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=463, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=29933568, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 382 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1943728 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 463
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=464, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=29933568
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=464, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=29998080, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 383 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1848028 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 464
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=465, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=29998080
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=465, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=30062592, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 390 offsetInBlock: 25159680 lastPacketInBlock: false lastByteOffsetInBlock: 25224192
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 391 offsetInBlock: 25224192 lastPacketInBlock: false lastByteOffsetInBlock: 25288704
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 392 offsetInBlock: 25288704 lastPacketInBlock: false lastByteOffsetInBlock: 25353216
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 384 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1869805 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 465
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=466, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=30062592
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=466, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=30127104, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 385 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1812610 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 466
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=467, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=30127104
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=467, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=30191616, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 393 offsetInBlock: 25353216 lastPacketInBlock: false lastByteOffsetInBlock: 25417728
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 386 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2007780 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 467
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 394 offsetInBlock: 25417728 lastPacketInBlock: false lastByteOffsetInBlock: 25482240
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=468, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=30191616
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 395 offsetInBlock: 25482240 lastPacketInBlock: false lastByteOffsetInBlock: 25546752
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=468, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=30256128, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 387 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1946434 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 468
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=469, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=30256128
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=469, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=30320640, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 388 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1969445 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 469
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=470, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=30320640
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=470, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=30385152, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 396 offsetInBlock: 25546752 lastPacketInBlock: false lastByteOffsetInBlock: 25611264
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 389 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1913505 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 470
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=471, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=30385152
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 397 offsetInBlock: 25611264 lastPacketInBlock: false lastByteOffsetInBlock: 25675776
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=471, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=30449664, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 390 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1918160 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 471
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=472, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=30449664
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=472, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=30514176, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 398 offsetInBlock: 25675776 lastPacketInBlock: false lastByteOffsetInBlock: 25740288
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 391 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1976465 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 472
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=473, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=30514176
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 399 offsetInBlock: 25740288 lastPacketInBlock: false lastByteOffsetInBlock: 25804800
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 400 offsetInBlock: 25804800 lastPacketInBlock: false lastByteOffsetInBlock: 25869312
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=473, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=30578688, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 392 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1899088 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 473
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=474, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=30578688
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=474, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=30643200, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 393 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1974884 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 474
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=475, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=30643200
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=475, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=30707712, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 401 offsetInBlock: 25869312 lastPacketInBlock: false lastByteOffsetInBlock: 25933824
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 394 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1971251 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 475
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=476, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=30707712
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=476, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=30772224, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 402 offsetInBlock: 25933824 lastPacketInBlock: false lastByteOffsetInBlock: 25998336
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 403 offsetInBlock: 25998336 lastPacketInBlock: false lastByteOffsetInBlock: 26062848
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 395 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1928829 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 476
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=477, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=30772224
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=477, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=30836736, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 396 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1964190 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 477
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=478, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=30836736
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=478, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=30901248, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 404 offsetInBlock: 26062848 lastPacketInBlock: false lastByteOffsetInBlock: 26127360
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 397 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1907222 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 478
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 405 offsetInBlock: 26127360 lastPacketInBlock: false lastByteOffsetInBlock: 26191872
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=479, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=30901248
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=479, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=30965760, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 398 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1964831 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 479
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=480, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=30965760
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=480, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=31030272, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 406 offsetInBlock: 26191872 lastPacketInBlock: false lastByteOffsetInBlock: 26256384
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 399 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1937203 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 407 offsetInBlock: 26256384 lastPacketInBlock: false lastByteOffsetInBlock: 26320896
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 480
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=481, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=31030272
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=481, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=31094784, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 400 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1955425 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 481
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=482, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=31094784
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=482, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=31159296, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 401 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1912882 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 482
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 408 offsetInBlock: 26320896 lastPacketInBlock: false lastByteOffsetInBlock: 26385408
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=483, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=31159296
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 409 offsetInBlock: 26385408 lastPacketInBlock: false lastByteOffsetInBlock: 26449920
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=483, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=31223808, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 402 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1922063 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 483
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=484, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=31223808
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=484, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=31288320, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 410 offsetInBlock: 26449920 lastPacketInBlock: false lastByteOffsetInBlock: 26514432
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 403 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1890499 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 484
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 411 offsetInBlock: 26514432 lastPacketInBlock: false lastByteOffsetInBlock: 26578944
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=485, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=31288320
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=485, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=31352832, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 404 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1900744 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 485
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=486, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=31352832
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=486, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=31417344, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 405 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1901522 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 412 offsetInBlock: 26578944 lastPacketInBlock: false lastByteOffsetInBlock: 26643456
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 486
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=487, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=31417344
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 413 offsetInBlock: 26643456 lastPacketInBlock: false lastByteOffsetInBlock: 26707968
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=487, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=31481856, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 406 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1926976 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 487
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=488, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=31481856
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=488, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=31546368, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 414 offsetInBlock: 26707968 lastPacketInBlock: false lastByteOffsetInBlock: 26772480
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 415 offsetInBlock: 26772480 lastPacketInBlock: false lastByteOffsetInBlock: 26836992
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 407 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1886239 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 488
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=489, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=31546368
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=489, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=31610880, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 408 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1951922 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 489
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=490, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=31610880
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 416 offsetInBlock: 26836992 lastPacketInBlock: false lastByteOffsetInBlock: 26901504
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=490, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=31675392, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 417 offsetInBlock: 26901504 lastPacketInBlock: false lastByteOffsetInBlock: 26966016
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 409 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1891575 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 490
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=491, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=31675392
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=491, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=31739904, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 410 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1872687 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 491
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=492, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=31739904
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=492, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=31804416, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 418 offsetInBlock: 26966016 lastPacketInBlock: false lastByteOffsetInBlock: 27030528
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 419 offsetInBlock: 27030528 lastPacketInBlock: false lastByteOffsetInBlock: 27095040
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 411 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2008774 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 492
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=493, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=31804416
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=493, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=31868928, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 412 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1820321 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 493
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=494, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=31868928
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=494, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=31933440, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 420 offsetInBlock: 27095040 lastPacketInBlock: false lastByteOffsetInBlock: 27159552
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 421 offsetInBlock: 27159552 lastPacketInBlock: false lastByteOffsetInBlock: 27224064
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 413 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1928717 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 494
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=495, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=31933440
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=495, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=31997952, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 414 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1905080 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 495
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=496, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=31997952
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=496, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=32062464, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 422 offsetInBlock: 27224064 lastPacketInBlock: false lastByteOffsetInBlock: 27288576
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 423 offsetInBlock: 27288576 lastPacketInBlock: false lastByteOffsetInBlock: 27353088
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 415 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1977618 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 496
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=497, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=32062464
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=497, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=32126976, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 424 offsetInBlock: 27353088 lastPacketInBlock: false lastByteOffsetInBlock: 27417600
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 416 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1976960 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 497
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=498, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=32126976
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 425 offsetInBlock: 27417600 lastPacketInBlock: false lastByteOffsetInBlock: 27482112
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=498, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=32191488, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 417 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1868161 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 498
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=499, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=32191488
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=499, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=32256000, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 426 offsetInBlock: 27482112 lastPacketInBlock: false lastByteOffsetInBlock: 27546624
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 418 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1914326 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 499
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 427 offsetInBlock: 27546624 lastPacketInBlock: false lastByteOffsetInBlock: 27611136
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=500, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=32256000
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=500, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=32320512, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 419 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1897670 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 500
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=501, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=32320512
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk packet full seqno=501, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, bytesCurBlock=32385024, blockSize=134217728, appendChunk=false
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 428 offsetInBlock: 27611136 lastPacketInBlock: false lastByteOffsetInBlock: 27675648
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 420 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1962552 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 501
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: computePacketChunkSize: src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, chunkSize=516, chunksPerPacket=126, packetSize=65016
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 429 offsetInBlock: 27675648 lastPacketInBlock: false lastByteOffsetInBlock: 27740160
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=502, src=/tmp/hive/spiderdt/_spark_session_dir/e01100e1-b79e-4464-8efe-03fba9a96ced/hive-exec-2.1.0.jar, packetSize=65016, chunksPerPacket=126, bytesCurBlock=32385024
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 421 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1882722 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 502
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Queued packet 503
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: Waiting for ack for: 503
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 430 offsetInBlock: 27740160 lastPacketInBlock: false lastByteOffsetInBlock: 27804672
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 422 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1955485 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 431 offsetInBlock: 27804672 lastPacketInBlock: false lastByteOffsetInBlock: 27869184
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 423 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1948113 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 424 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1917672 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 432 offsetInBlock: 27869184 lastPacketInBlock: false lastByteOffsetInBlock: 27933696
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 433 offsetInBlock: 27933696 lastPacketInBlock: false lastByteOffsetInBlock: 27998208
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 425 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1895176 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 426 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1943946 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 434 offsetInBlock: 27998208 lastPacketInBlock: false lastByteOffsetInBlock: 28062720
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 435 offsetInBlock: 28062720 lastPacketInBlock: false lastByteOffsetInBlock: 28127232
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 427 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1869959 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 428 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2007623 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 436 offsetInBlock: 28127232 lastPacketInBlock: false lastByteOffsetInBlock: 28191744
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 429 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1982816 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 437 offsetInBlock: 28191744 lastPacketInBlock: false lastByteOffsetInBlock: 28256256
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 430 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1893273 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 438 offsetInBlock: 28256256 lastPacketInBlock: false lastByteOffsetInBlock: 28320768
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 439 offsetInBlock: 28320768 lastPacketInBlock: false lastByteOffsetInBlock: 28385280
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 431 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1891895 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 432 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1965257 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 433 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1962544 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 440 offsetInBlock: 28385280 lastPacketInBlock: false lastByteOffsetInBlock: 28449792
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 441 offsetInBlock: 28449792 lastPacketInBlock: false lastByteOffsetInBlock: 28514304
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 442 offsetInBlock: 28514304 lastPacketInBlock: false lastByteOffsetInBlock: 28578816
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 434 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1887187 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 435 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1958391 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 443 offsetInBlock: 28578816 lastPacketInBlock: false lastByteOffsetInBlock: 28643328
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 436 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1959577 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 444 offsetInBlock: 28643328 lastPacketInBlock: false lastByteOffsetInBlock: 28707840
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 445 offsetInBlock: 28707840 lastPacketInBlock: false lastByteOffsetInBlock: 28772352
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 437 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1921582 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 438 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1996076 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 439 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1964307 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 446 offsetInBlock: 28772352 lastPacketInBlock: false lastByteOffsetInBlock: 28836864
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 447 offsetInBlock: 28836864 lastPacketInBlock: false lastByteOffsetInBlock: 28901376
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 448 offsetInBlock: 28901376 lastPacketInBlock: false lastByteOffsetInBlock: 28965888
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 440 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1915782 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 441 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1930784 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 442 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1972948 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 449 offsetInBlock: 28965888 lastPacketInBlock: false lastByteOffsetInBlock: 29030400
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 450 offsetInBlock: 29030400 lastPacketInBlock: false lastByteOffsetInBlock: 29094912
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 451 offsetInBlock: 29094912 lastPacketInBlock: false lastByteOffsetInBlock: 29159424
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 452 offsetInBlock: 29159424 lastPacketInBlock: false lastByteOffsetInBlock: 29223936
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 443 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1905496 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 444 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1962435 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 445 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2010214 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 453 offsetInBlock: 29223936 lastPacketInBlock: false lastByteOffsetInBlock: 29288448
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 446 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1942718 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 447 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1946909 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 454 offsetInBlock: 29288448 lastPacketInBlock: false lastByteOffsetInBlock: 29352960
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 455 offsetInBlock: 29352960 lastPacketInBlock: false lastByteOffsetInBlock: 29417472
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 456 offsetInBlock: 29417472 lastPacketInBlock: false lastByteOffsetInBlock: 29481984
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 448 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1983770 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 449 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1966622 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 450 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1901639 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 457 offsetInBlock: 29481984 lastPacketInBlock: false lastByteOffsetInBlock: 29546496
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 458 offsetInBlock: 29546496 lastPacketInBlock: false lastByteOffsetInBlock: 29611008
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 451 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1965053 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 452 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1880753 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 459 offsetInBlock: 29611008 lastPacketInBlock: false lastByteOffsetInBlock: 29675520
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 460 offsetInBlock: 29675520 lastPacketInBlock: false lastByteOffsetInBlock: 29740032
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 453 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1878814 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 461 offsetInBlock: 29740032 lastPacketInBlock: false lastByteOffsetInBlock: 29804544
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 462 offsetInBlock: 29804544 lastPacketInBlock: false lastByteOffsetInBlock: 29869056
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 454 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1948116 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 455 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2043485 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 456 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2015788 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 463 offsetInBlock: 29869056 lastPacketInBlock: false lastByteOffsetInBlock: 29933568
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 464 offsetInBlock: 29933568 lastPacketInBlock: false lastByteOffsetInBlock: 29998080
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 457 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1952955 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 465 offsetInBlock: 29998080 lastPacketInBlock: false lastByteOffsetInBlock: 30062592
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 458 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2015227 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 466 offsetInBlock: 30062592 lastPacketInBlock: false lastByteOffsetInBlock: 30127104
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 467 offsetInBlock: 30127104 lastPacketInBlock: false lastByteOffsetInBlock: 30191616
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 459 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1979618 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 460 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2065004 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 461 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2047955 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 468 offsetInBlock: 30191616 lastPacketInBlock: false lastByteOffsetInBlock: 30256128
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 469 offsetInBlock: 30256128 lastPacketInBlock: false lastByteOffsetInBlock: 30320640
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 462 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1882319 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 463 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1833796 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 470 offsetInBlock: 30320640 lastPacketInBlock: false lastByteOffsetInBlock: 30385152
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 471 offsetInBlock: 30385152 lastPacketInBlock: false lastByteOffsetInBlock: 30449664
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 464 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1882508 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 465 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1884281 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 472 offsetInBlock: 30449664 lastPacketInBlock: false lastByteOffsetInBlock: 30514176
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 473 offsetInBlock: 30514176 lastPacketInBlock: false lastByteOffsetInBlock: 30578688
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 474 offsetInBlock: 30578688 lastPacketInBlock: false lastByteOffsetInBlock: 30643200
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 466 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1984442 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 467 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1970796 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 475 offsetInBlock: 30643200 lastPacketInBlock: false lastByteOffsetInBlock: 30707712
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 468 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1907280 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 476 offsetInBlock: 30707712 lastPacketInBlock: false lastByteOffsetInBlock: 30772224
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 469 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1904093 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 470 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1907550 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 477 offsetInBlock: 30772224 lastPacketInBlock: false lastByteOffsetInBlock: 30836736
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 478 offsetInBlock: 30836736 lastPacketInBlock: false lastByteOffsetInBlock: 30901248
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 471 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1890692 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 472 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1984372 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 479 offsetInBlock: 30901248 lastPacketInBlock: false lastByteOffsetInBlock: 30965760
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 480 offsetInBlock: 30965760 lastPacketInBlock: false lastByteOffsetInBlock: 31030272
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 481 offsetInBlock: 31030272 lastPacketInBlock: false lastByteOffsetInBlock: 31094784
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 473 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1939250 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 474 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1966605 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 475 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1980429 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 482 offsetInBlock: 31094784 lastPacketInBlock: false lastByteOffsetInBlock: 31159296
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 483 offsetInBlock: 31159296 lastPacketInBlock: false lastByteOffsetInBlock: 31223808
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 484 offsetInBlock: 31223808 lastPacketInBlock: false lastByteOffsetInBlock: 31288320
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 485 offsetInBlock: 31288320 lastPacketInBlock: false lastByteOffsetInBlock: 31352832
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 476 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2054108 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 477 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1951108 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 478 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1928404 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 486 offsetInBlock: 31352832 lastPacketInBlock: false lastByteOffsetInBlock: 31417344
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 479 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1985266 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 487 offsetInBlock: 31417344 lastPacketInBlock: false lastByteOffsetInBlock: 31481856
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 480 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2134431 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 488 offsetInBlock: 31481856 lastPacketInBlock: false lastByteOffsetInBlock: 31546368
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 489 offsetInBlock: 31546368 lastPacketInBlock: false lastByteOffsetInBlock: 31610880
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 481 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2135890 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 482 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2073796 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 483 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2104442 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 490 offsetInBlock: 31610880 lastPacketInBlock: false lastByteOffsetInBlock: 31675392
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 491 offsetInBlock: 31675392 lastPacketInBlock: false lastByteOffsetInBlock: 31739904
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 492 offsetInBlock: 31739904 lastPacketInBlock: false lastByteOffsetInBlock: 31804416
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 484 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2119363 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 485 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2119776 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 486 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2073746 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 493 offsetInBlock: 31804416 lastPacketInBlock: false lastByteOffsetInBlock: 31868928
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 494 offsetInBlock: 31868928 lastPacketInBlock: false lastByteOffsetInBlock: 31933440
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 487 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2095091 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 488 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2054201 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 495 offsetInBlock: 31933440 lastPacketInBlock: false lastByteOffsetInBlock: 31997952
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 496 offsetInBlock: 31997952 lastPacketInBlock: false lastByteOffsetInBlock: 32062464
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 489 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2101989 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 497 offsetInBlock: 32062464 lastPacketInBlock: false lastByteOffsetInBlock: 32126976
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 490 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2064308 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 498 offsetInBlock: 32126976 lastPacketInBlock: false lastByteOffsetInBlock: 32191488
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 491 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2119761 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 492 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2078180 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 499 offsetInBlock: 32191488 lastPacketInBlock: false lastByteOffsetInBlock: 32256000
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 500 offsetInBlock: 32256000 lastPacketInBlock: false lastByteOffsetInBlock: 32320512
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 501 offsetInBlock: 32320512 lastPacketInBlock: false lastByteOffsetInBlock: 32385024
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 493 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2082325 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 494 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2102519 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 502 offsetInBlock: 32385024 lastPacketInBlock: false lastByteOffsetInBlock: 32414403
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 495 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2100859 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 496 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2077391 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 497 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2083068 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 498 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1982664 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 499 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1999035 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 500 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1985587 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 501 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1679023 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 502 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1498716 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: DataStreamer block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751 sending packet packet seqno: 503 offsetInBlock: 32414403 lastPacketInBlock: true lastByteOffsetInBlock: 32414403
16/08/16 09:55:31 [ResponseProcessor for block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751]: DEBUG hdfs.DFSClient: DFSClient seqno: 503 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 1158823 flag: 0 flag: 0 flag: 0
16/08/16 09:55:31 [Thread-17]: DEBUG hdfs.DFSClient: Closing old block BP-1049577869-192.168.1.3-1469088316483:blk_1073911553_170751
16/08/16 09:55:31 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #34
16/08/16 09:55:31 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #34
16/08/16 09:55:31 [main]: DEBUG ipc.ProtobufRpcEngine: Call: complete took 9ms
16/08/16 09:55:31 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #35
16/08/16 09:55:31 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #35
16/08/16 09:55:31 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 1ms
16/08/16 09:55:31 [main]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Registered outstanding rpc 0 (org.apache.hive.spark.client.BaseProtocol$SyncJobRequest).
16/08/16 09:55:31 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:31 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.BaseProtocol$SyncJobRequest (236 bytes)
16/08/16 09:55:31 [main]: INFO ql.Context: New scratch dir is hdfs://192.168.1.3:9000/tmp/hive/spiderdt/51225d5e-db54-49c7-ac07-21870a695009/hive_2016-08-16_09-55-22_736_9092508509176823623-1
16/08/16 09:55:31 [main]: DEBUG hdfs.DFSClient: /tmp/hive/spiderdt/51225d5e-db54-49c7-ac07-21870a695009/hive_2016-08-16_09-55-22_736_9092508509176823623-1/-mr-10004: masked=rwxr-xr-x
16/08/16 09:55:31 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #36
16/08/16 09:55:31 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #36
16/08/16 09:55:31 [main]: DEBUG ipc.ProtobufRpcEngine: Call: mkdirs took 8ms
16/08/16 09:55:31 [main]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Registered outstanding rpc 1 (org.apache.hive.spark.client.BaseProtocol$JobRequest).
16/08/16 09:55:31 [main]: DEBUG client.SparkClientImpl: Send JobRequest[52d71925-751f-4a4d-9368-9fedb55e82f1].
16/08/16 09:55:31 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:31 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.BaseProtocol$JobRequest (210249 bytes)
Starting Spark Job = 52d71925-751f-4a4d-9368-9fedb55e82f1
16/08/16 09:55:31 [main]: INFO spark.SparkTask: Starting Spark Job = 52d71925-751f-4a4d-9368-9fedb55e82f1
state = SENT
16/08/16 09:55:31 [main]: INFO status.SparkJobMonitor: state = SENT
state = SENT
16/08/16 09:55:32 [main]: INFO status.SparkJobMonitor: state = SENT
state = SENT
16/08/16 09:55:33 [main]: INFO status.SparkJobMonitor: state = SENT
state = SENT
16/08/16 09:55:34 [main]: INFO status.SparkJobMonitor: state = SENT
state = SENT
16/08/16 09:55:35 [main]: INFO status.SparkJobMonitor: state = SENT
state = SENT
16/08/16 09:55:36 [main]: INFO status.SparkJobMonitor: state = SENT
state = SENT
16/08/16 09:55:37 [main]: INFO status.SparkJobMonitor: state = SENT
state = SENT
16/08/16 09:55:38 [main]: INFO status.SparkJobMonitor: state = SENT
state = SENT
16/08/16 09:55:39 [main]: INFO status.SparkJobMonitor: state = SENT
state = SENT
16/08/16 09:55:40 [main]: INFO status.SparkJobMonitor: state = SENT
16/08/16 09:55:41 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt: closed
16/08/16 09:55:41 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt: stopped, remaining connections 0
state = SENT
16/08/16 09:55:41 [main]: INFO status.SparkJobMonitor: state = SENT
state = SENT
16/08/16 09:55:42 [main]: INFO status.SparkJobMonitor: state = SENT
state = SENT
16/08/16 09:55:43 [main]: INFO status.SparkJobMonitor: state = SENT
16/08/16 09:55:43 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:43 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$NullMessage (2 bytes)
16/08/16 09:55:43 [RPC-Handler-3]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Received RPC message: type=REPLY id=0 payload=org.apache.hive.spark.client.rpc.Rpc$NullMessage
16/08/16 09:55:43 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:43 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$NullMessage (2 bytes)
16/08/16 09:55:43 [RPC-Handler-3]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Received RPC message: type=REPLY id=1 payload=org.apache.hive.spark.client.rpc.Rpc$NullMessage
16/08/16 09:55:43 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:44 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.BaseProtocol$JobStarted (92 bytes)
16/08/16 09:55:44 [RPC-Handler-3]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Received RPC message: type=CALL id=0 payload=org.apache.hive.spark.client.BaseProtocol$JobStarted
16/08/16 09:55:44 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:44 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$NullMessage (2 bytes)
state = STARTED
16/08/16 09:55:44 [main]: INFO status.SparkJobMonitor: state = STARTED
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.BaseProtocol$JobSubmitted (95 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Received RPC message: type=CALL id=1 payload=org.apache.hive.spark.client.BaseProtocol$JobSubmitted
16/08/16 09:55:45 [RPC-Handler-3]: INFO client.SparkClientImpl: Received spark job ID: 0 for 52d71925-751f-4a4d-9368-9fedb55e82f1
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$NullMessage (2 bytes)
state = STARTED
16/08/16 09:55:45 [main]: INFO status.SparkJobMonitor: state = STARTED
16/08/16 09:55:45 [main]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Registered outstanding rpc 2 (org.apache.hive.spark.client.BaseProtocol$SyncJobRequest).
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.BaseProtocol$SyncJobRequest (185 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.spark.SparkJobInfoImpl (43 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Received RPC message: type=REPLY id=2 payload=org.apache.spark.SparkJobInfoImpl
16/08/16 09:55:45 [main]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Registered outstanding rpc 3 (org.apache.hive.spark.client.BaseProtocol$SyncJobRequest).
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.BaseProtocol$SyncJobRequest (185 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.spark.SparkJobInfoImpl (43 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Received RPC message: type=REPLY id=3 payload=org.apache.spark.SparkJobInfoImpl
16/08/16 09:55:45 [main]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Registered outstanding rpc 4 (org.apache.hive.spark.client.BaseProtocol$SyncJobRequest).
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.BaseProtocol$SyncJobRequest (150 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.spark.SparkStageInfoImpl (89 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Received RPC message: type=REPLY id=4 payload=org.apache.spark.SparkStageInfoImpl
16/08/16 09:55:45 [main]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Registered outstanding rpc 5 (org.apache.hive.spark.client.BaseProtocol$SyncJobRequest).
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.BaseProtocol$SyncJobRequest (150 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.spark.SparkStageInfoImpl (92 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Received RPC message: type=REPLY id=5 payload=org.apache.spark.SparkStageInfoImpl
16/08/16 09:55:45 [main]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Registered outstanding rpc 6 (org.apache.hive.spark.client.BaseProtocol$SyncJobRequest).
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.BaseProtocol$SyncJobRequest (145 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type java.lang.String (32 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Received RPC message: type=REPLY id=6 payload=java.lang.String
Running with YARN Application = application_1470896084881_0048
16/08/16 09:55:45 [main]: INFO status.SparkJobMonitor: Running with YARN Application = application_1470896084881_0048
Kill Command = /home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/bin/yarn application -kill application_1470896084881_0048
16/08/16 09:55:45 [main]: INFO status.SparkJobMonitor: Kill Command = /home/spiderdt/work/git/spiderdt-env/cluster/tarball/hadoop/bin/yarn application -kill application_1470896084881_0048

Query Hive on Spark job[0] stages:
16/08/16 09:55:45 [main]: INFO status.SparkJobMonitor: 
Query Hive on Spark job[0] stages:
16/08/16 09:55:45 [main]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Registered outstanding rpc 7 (org.apache.hive.spark.client.BaseProtocol$SyncJobRequest).
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.BaseProtocol$SyncJobRequest (185 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.spark.SparkJobInfoImpl (43 bytes)
16/08/16 09:55:45 [RPC-Handler-3]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Received RPC message: type=REPLY id=7 payload=org.apache.spark.SparkJobInfoImpl
0
1

Status: Running (Hive on Spark job[0])
16/08/16 09:55:45 [main]: INFO status.SparkJobMonitor: 0
Job Progress Format
CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
16/08/16 09:55:45 [main]: INFO status.SparkJobMonitor: 1
16/08/16 09:55:45 [main]: INFO status.SparkJobMonitor: 
Status: Running (Hive on Spark job[0])
16/08/16 09:55:45 [main]: INFO status.SparkJobMonitor: Job Progress Format
CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
2016-08-16 09:55:45,484	Stage-0_0: 0(+1)/1	Stage-1_0: 0/1	
16/08/16 09:55:45 [main]: INFO status.SparkJobMonitor: 2016-08-16 09:55:45,484	Stage-0_0: 0(+1)/1	Stage-1_0: 0/1	
state = STARTED
16/08/16 09:55:46 [main]: INFO status.SparkJobMonitor: state = STARTED
16/08/16 09:55:46 [main]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Registered outstanding rpc 8 (org.apache.hive.spark.client.BaseProtocol$SyncJobRequest).
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.BaseProtocol$SyncJobRequest (185 bytes)
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.spark.SparkJobInfoImpl (43 bytes)
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Received RPC message: type=REPLY id=8 payload=org.apache.spark.SparkJobInfoImpl
16/08/16 09:55:46 [main]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Registered outstanding rpc 9 (org.apache.hive.spark.client.BaseProtocol$SyncJobRequest).
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.BaseProtocol$SyncJobRequest (185 bytes)
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.spark.SparkJobInfoImpl (43 bytes)
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Received RPC message: type=REPLY id=9 payload=org.apache.spark.SparkJobInfoImpl
16/08/16 09:55:46 [main]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Registered outstanding rpc 10 (org.apache.hive.spark.client.BaseProtocol$SyncJobRequest).
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.BaseProtocol$SyncJobRequest (150 bytes)
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.spark.SparkStageInfoImpl (89 bytes)
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Received RPC message: type=REPLY id=10 payload=org.apache.spark.SparkStageInfoImpl
16/08/16 09:55:46 [main]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Registered outstanding rpc 11 (org.apache.hive.spark.client.BaseProtocol$SyncJobRequest).
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.BaseProtocol$SyncJobRequest (150 bytes)
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.spark.SparkStageInfoImpl (92 bytes)
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Received RPC message: type=REPLY id=11 payload=org.apache.spark.SparkStageInfoImpl
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.BaseProtocol$JobMetrics (274 bytes)
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Received RPC message: type=CALL id=2 payload=org.apache.hive.spark.client.BaseProtocol$JobMetrics
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:46 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$NullMessage (2 bytes)
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.BaseProtocol$JobMetrics (215 bytes)
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Received RPC message: type=CALL id=3 payload=org.apache.hive.spark.client.BaseProtocol$JobMetrics
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$NullMessage (2 bytes)
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.BaseProtocol$JobResult (382 bytes)
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Received RPC message: type=CALL id=4 payload=org.apache.hive.spark.client.BaseProtocol$JobResult
16/08/16 09:55:47 [RPC-Handler-3]: INFO client.SparkClientImpl: Received result for 52d71925-751f-4a4d-9368-9fedb55e82f1
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$NullMessage (2 bytes)
state = SUCCEEDED
16/08/16 09:55:47 [main]: INFO status.SparkJobMonitor: state = SUCCEEDED
16/08/16 09:55:47 [main]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Registered outstanding rpc 12 (org.apache.hive.spark.client.BaseProtocol$SyncJobRequest).
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.BaseProtocol$SyncJobRequest (185 bytes)
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.spark.SparkJobInfoImpl (43 bytes)
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Received RPC message: type=REPLY id=12 payload=org.apache.spark.SparkJobInfoImpl
16/08/16 09:55:47 [main]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Registered outstanding rpc 13 (org.apache.hive.spark.client.BaseProtocol$SyncJobRequest).
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.BaseProtocol$SyncJobRequest (150 bytes)
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.spark.SparkStageInfoImpl (89 bytes)
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Received RPC message: type=REPLY id=13 payload=org.apache.spark.SparkStageInfoImpl
16/08/16 09:55:47 [main]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Registered outstanding rpc 14 (org.apache.hive.spark.client.BaseProtocol$SyncJobRequest).
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Encoded message of type org.apache.hive.spark.client.BaseProtocol$SyncJobRequest (150 bytes)
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.hive.spark.client.rpc.Rpc$MessageHeader (5 bytes)
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.KryoMessageCodec: Decoded message of type org.apache.spark.SparkStageInfoImpl (97 bytes)
16/08/16 09:55:47 [RPC-Handler-3]: DEBUG rpc.RpcDispatcher: [ClientProtocol] Received RPC message: type=REPLY id=14 payload=org.apache.spark.SparkStageInfoImpl
2016-08-16 09:55:47,508	Stage-0_0: 1/1 Finished	Stage-1_0: 1/1 Finished	
16/08/16 09:55:47 [main]: INFO status.SparkJobMonitor: 2016-08-16 09:55:47,508	Stage-0_0: 1/1 Finished	Stage-1_0: 1/1 Finished	
Status: Finished successfully in 16.06 seconds
16/08/16 09:55:47 [main]: INFO status.SparkJobMonitor: Status: Finished successfully in 16.06 seconds
16/08/16 09:55:47 [main]: INFO spark.SparkTask: =====Spark Job[52d71925-751f-4a4d-9368-9fedb55e82f1] statistics=====
16/08/16 09:55:47 [main]: INFO spark.SparkTask: HIVE
16/08/16 09:55:47 [main]: INFO spark.SparkTask: 	CREATED_FILES: 1
16/08/16 09:55:47 [main]: INFO spark.SparkTask: 	DESERIALIZE_ERRORS: 0
16/08/16 09:55:47 [main]: INFO spark.SparkTask: 	RECORDS_OUT_INTERMEDIATE: 1
16/08/16 09:55:47 [main]: INFO spark.SparkTask: 	RECORDS_IN: 664
16/08/16 09:55:47 [main]: INFO spark.SparkTask: 	RECORDS_OUT_0: 1
16/08/16 09:55:47 [main]: INFO spark.SparkTask: Spark Job[52d71925-751f-4a4d-9368-9fedb55e82f1] Metrics
16/08/16 09:55:47 [main]: INFO spark.SparkTask: 	ExecutorDeserializeTime: 982
16/08/16 09:55:47 [main]: INFO spark.SparkTask: 	ExecutorRunTime: 631
16/08/16 09:55:47 [main]: INFO spark.SparkTask: 	ResultSize: 3487
16/08/16 09:55:47 [main]: INFO spark.SparkTask: 	JvmGCTime: 35
16/08/16 09:55:47 [main]: INFO spark.SparkTask: 	ResultSerializationTime: 0
16/08/16 09:55:47 [main]: INFO spark.SparkTask: 	MemoryBytesSpilled: 0
16/08/16 09:55:47 [main]: INFO spark.SparkTask: 	DiskBytesSpilled: 0
16/08/16 09:55:47 [main]: INFO spark.SparkTask: 	BytesRead: 128648
16/08/16 09:55:47 [main]: INFO spark.SparkTask: 	RemoteBlocksFetched: 0
16/08/16 09:55:47 [main]: INFO spark.SparkTask: 	LocalBlocksFetched: 1
16/08/16 09:55:47 [main]: INFO spark.SparkTask: 	TotalBlocksFetched: 1
16/08/16 09:55:47 [main]: INFO spark.SparkTask: 	FetchWaitTime: 0
16/08/16 09:55:47 [main]: INFO spark.SparkTask: 	RemoteBytesRead: 0
16/08/16 09:55:47 [main]: INFO spark.SparkTask: 	ShuffleBytesWritten: 41
16/08/16 09:55:47 [main]: INFO spark.SparkTask: 	ShuffleWriteTime: 3458993
16/08/16 09:55:47 [main]: INFO spark.SparkTask: Execution completed successfully
16/08/16 09:55:47 [main]: DEBUG ipc.Client: The ping interval is 60000 ms.
16/08/16 09:55:47 [main]: DEBUG ipc.Client: Connecting to /192.168.1.3:9000
16/08/16 09:55:47 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt: starting, having connections 1
16/08/16 09:55:47 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #37
16/08/16 09:55:47 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #37
16/08/16 09:55:47 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 4ms
16/08/16 09:55:47 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #38
16/08/16 09:55:47 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #38
16/08/16 09:55:47 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getListing took 1ms
16/08/16 09:55:47 [main]: DEBUG exec.Utilities: TaskId for 000000_0 = 000000
16/08/16 09:55:47 [main]: INFO exec.FileSinkOperator: Moving tmp dir: hdfs://192.168.1.3:9000/tmp/hive/spiderdt/51225d5e-db54-49c7-ac07-21870a695009/hive_2016-08-16_09-55-22_736_9092508509176823623-1/-mr-10001/.hive-staging_hive_2016-08-16_09-55-22_736_9092508509176823623-1/_tmp.-ext-10002 to: hdfs://192.168.1.3:9000/tmp/hive/spiderdt/51225d5e-db54-49c7-ac07-21870a695009/hive_2016-08-16_09-55-22_736_9092508509176823623-1/-mr-10001/.hive-staging_hive_2016-08-16_09-55-22_736_9092508509176823623-1/-ext-10002
16/08/16 09:55:47 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #39
16/08/16 09:55:47 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #39
16/08/16 09:55:47 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 1ms
16/08/16 09:55:47 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #40
16/08/16 09:55:47 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #40
16/08/16 09:55:47 [main]: DEBUG ipc.ProtobufRpcEngine: Call: rename took 6ms
16/08/16 09:55:47 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #41
16/08/16 09:55:47 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #41
16/08/16 09:55:47 [main]: DEBUG ipc.ProtobufRpcEngine: Call: delete took 10ms
16/08/16 09:55:47 [main]: INFO metadata.Hive: Dumping metastore api call timing information for : execution phase
16/08/16 09:55:47 [main]: DEBUG metadata.Hive: Total time spent in each metastore function (ms): {}
16/08/16 09:55:47 [main]: INFO ql.Driver: Completed executing command(queryId=spiderdt_20160816095522_18717c8b-3f00-49a6-8b7f-a80488d76090); Time taken: 22.87 seconds
OK
16/08/16 09:55:47 [main]: INFO ql.Driver: OK
16/08/16 09:55:47 [main]: DEBUG ql.Driver: Shutting down query select count(*) from ods.d_sample_data where p_date = '2012-09-18' 
16/08/16 09:55:47 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #42
16/08/16 09:55:47 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #42
16/08/16 09:55:47 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 0ms
16/08/16 09:55:47 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #43
16/08/16 09:55:47 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #43
16/08/16 09:55:47 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getListing took 1ms
16/08/16 09:55:47 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #44
16/08/16 09:55:47 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #44
16/08/16 09:55:47 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getListing took 1ms
16/08/16 09:55:47 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #45
16/08/16 09:55:47 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #45
16/08/16 09:55:47 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 1ms
16/08/16 09:55:47 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #46
16/08/16 09:55:47 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #46
16/08/16 09:55:47 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getListing took 1ms
16/08/16 09:55:47 [main]: DEBUG mapred.FileInputFormat: Time taken to get FileStatuses: 7
16/08/16 09:55:47 [main]: INFO mapred.FileInputFormat: Total input paths to process : 1
16/08/16 09:55:47 [main]: DEBUG mapred.FileInputFormat: Total # of splits generated by getSplits: 1, TimeTaken: 15
16/08/16 09:55:47 [main]: DEBUG exec.FetchOperator: Creating fetchTask with deserializer typeinfo: struct<_col0:bigint>
16/08/16 09:55:47 [main]: DEBUG exec.FetchOperator: deserializer properties:
table properties: {columns=_col0, serialization.escape.crlf=true, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, hive.serialization.extend.additional.nesting.levels=true, serialization.format=1, columns.types=bigint, escape.delim=\}
partition properties: {columns=_col0, serialization.escape.crlf=true, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, hive.serialization.extend.additional.nesting.levels=true, serialization.format=1, columns.types=bigint, escape.delim=\}
16/08/16 09:55:47 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #47
16/08/16 09:55:47 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #47
16/08/16 09:55:47 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getFileInfo took 1ms
16/08/16 09:55:47 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #48
16/08/16 09:55:47 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #48
16/08/16 09:55:47 [main]: DEBUG ipc.ProtobufRpcEngine: Call: getBlockLocations took 1ms
16/08/16 09:55:47 [main]: DEBUG hdfs.DFSClient: newInfo = LocatedBlocks{
  fileLength=103
  underConstruction=false
  blocks=[LocatedBlock{BP-1049577869-192.168.1.3-1469088316483:blk_1073911556_170754; getBlockSize()=103; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[192.168.1.4:50010,DS-fa1be52f-46b3-423f-b1b0-ba4f0120b49f,DISK], DatanodeInfoWithStorage[192.168.1.6:50010,DS-b4c589a8-e20b-4d20-a321-df244c876bef,DISK], DatanodeInfoWithStorage[192.168.1.7:50010,DS-a0694e28-6249-430d-92ca-b5a0da1d08b1,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1049577869-192.168.1.3-1469088316483:blk_1073911556_170754; getBlockSize()=103; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[192.168.1.4:50010,DS-fa1be52f-46b3-423f-b1b0-ba4f0120b49f,DISK], DatanodeInfoWithStorage[192.168.1.7:50010,DS-a0694e28-6249-430d-92ca-b5a0da1d08b1,DISK], DatanodeInfoWithStorage[192.168.1.6:50010,DS-b4c589a8-e20b-4d20-a321-df244c876bef,DISK]]}
  isLastBlockComplete=true}
16/08/16 09:55:47 [main]: DEBUG hdfs.DFSClient: Connecting to datanode 192.168.1.4:50010
16/08/16 09:55:47 [main]: DEBUG sasl.SaslDataTransferClient: SASL client skipping handshake in unsecured configuration for addr = /192.168.1.4, datanodeId = DatanodeInfoWithStorage[192.168.1.4:50010,DS-fa1be52f-46b3-423f-b1b0-ba4f0120b49f,DISK]
66416/08/16 09:55:47 [main]: DEBUG exec.ListSinkOperator: 9 finished. closing... 

16/08/16 09:55:47 [main]: DEBUG exec.ListSinkOperator: 9 Close done
16/08/16 09:55:47 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #49
16/08/16 09:55:47 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #49
16/08/16 09:55:47 [main]: DEBUG ipc.ProtobufRpcEngine: Call: delete took 4ms
16/08/16 09:55:47 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #50
16/08/16 09:55:47 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #50
16/08/16 09:55:47 [main]: DEBUG ipc.ProtobufRpcEngine: Call: delete took 1ms
16/08/16 09:55:47 [IPC Parameter Sending Thread #1]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt sending #51
16/08/16 09:55:47 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt got value #51
16/08/16 09:55:47 [main]: DEBUG ipc.ProtobufRpcEngine: Call: delete took 7ms
Time taken: 24.869 seconds, Fetched: 1 row(s)
16/08/16 09:55:47 [main]: INFO CliDriver: Time taken: 24.869 seconds, Fetched: 1 row(s)
hive> 16/08/16 09:55:57 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt: closed
16/08/16 10:05:16 [IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt]: DEBUG ipc.Client: IPC Client (1063801186) connection to /192.168.1.3:9000 from spiderdt: stopped, remaining connections 0
